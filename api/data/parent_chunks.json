{
  "parent_650dfc6c5f2444c9a691484cc3993338": {
    "id": "parent_650dfc6c5f2444c9a691484cc3993338",
    "metadata": {
      "content": "The  following  students  have  been  shortlisted  for  the  interview.  Interview  Date:  25th  October   Time:  2:15  pm  onwards   Khew  Singh  Rajpurohit  1SI24AD021  Ayush  Raj  4SI25CS113  Sagnik  Pareck  1SI24AD040  Aryan  Shandilya  4SI25CS127  Jinka  Varshitha  Padmasali  1SI24CI023  Prerana  S  P  4SI25CS136  Aadil  Majeed  1SI24CS001  Jashwanth  Reddy  P  4SI25CS149  Anuraj  A  1SI24CS019  Roshan  Arjun  Mallik  4SI25CS150  Charan  B.S  1SI24CS037  Prathyush  Cr  4SI25CS153  H  Y  Shivani  1SI24CS063  Arpit  Roy  4SI25CS180  Saroj  Ghos  1SI24CS115  Nikunsh  Singh  4SI25CS194  Nitin  Sharma  1SI24CS118  Sagar  Verma  4SI25CS195  Rahul  Reddy  1SI24CS141  Ayush  Ranjan  4SI25CS196  Tejesh  C  1SI24CS189  Lalak  Jain  4SI25CS202  Jeet  Thakar  1SI24EC048  Tanisha  Majumder  4SI25CS208  Sounak  Ghosh  1SI24EC105  Pragati  Singh  Chandel  4SI25CS212  Vikas  M  H  1SI24EE059  Anant  4SI25CS217  Durga  Prasad  P  1SI24ET014  Ankit  Kumar  4SI25CS280  Hemanth  S  1SI24IS040",
      "title": "AIB_phase1"
    }
  },
  "parent_765307c4c463469aab004735006b2387": {
    "id": "parent_765307c4c463469aab004735006b2387",
    "metadata": {
      "content": "Anant  4SI25CS217  Durga  Prasad  P  1SI24ET014  Ankit  Kumar  4SI25CS280  Hemanth  S  1SI24IS040  Kushal  Bharadwaj  M  N  4SI25CS403  Priyanshu  Raj  1SI24IS071  Halaganesh  Kudiganur  4SI25EC004  Samridh  Shaurya  Singh  1SI24IS090  Harsh  Sharma  4SI25EC065  Yash  Chaudhary  1SI24IS125  Aayushi  4SI25EC080  Md  Adib  Hussain  4SI25CI049  Hitarth  Kadam  4SI25EC093  Mohammed  Mukhtar  Aziz  4SI25CI403  Madhumitha  C  4SI25EI027  UMANG  4SI25CIO48  Rushali.H  4SI25ET009  Preetham  C  G  4SI25CS003  Anjali  Mallur  4SI25ET043  Vedanth  C  R  4SI25CS017  Paras  Jadhav  4SI25ET058  Sanathoi  Soubam  4SI25CS019  Jeevan  Kumar  B  4SI25IS039  Nandini  M  4SI25CS032  Soundarya  4SI25IS043  Sanjay  M  4SI25CS036  Abhinandhan  Kj  4SI25IS072  Pradhan  N  Prabhu  4SI25CS081  Arnav  Lall  4SI25IS081  Shreyan  L  Anand  4SI25CS092  Sumukh  N  4SI25IS094  Saawan  Rao  4SI25CS111  Poojitha  S  4SI25IS103  \n   Note  Shortlisting  is  still  in  progress  additional  shortlisted  students  will",
      "title": "AIB_phase1"
    }
  },
  "parent_e4a07c9d5e6c4fe18f3a7608020bd451": {
    "id": "parent_e4a07c9d5e6c4fe18f3a7608020bd451",
    "metadata": {
      "content": "I25IS103  \n   Note  Shortlisting  is  still  in  progress  additional  shortlisted  students  will  be  \nannounced\n \nlater.\n   \n        \nAI  Brewery  Student  Club                                                                               Founder  &  Lead:  Pavan  J  Siddaganga  Institute  of  Technology,  Tumkur                    Faculty  Coordinator:  Dr.  Kiran  Kumar  T  M",
      "title": "AIB_phase1"
    }
  },
  "parent_a4e8029e548e4d0da003e3690a922e40": {
    "id": "parent_a4e8029e548e4d0da003e3690a922e40",
    "metadata": {
      "content": "Dr. J P Ganjigatti, Professor, IEM, SIT \n1 | P a g e \n \nRESEARCH METHODOLOGY AND IPR (SHS04) \nUnit-I \nResearch methodology  objectives and motivation of research -Types of research, research \napproaches, research methods verses methodology, research and research methodology, scientific \nmethod, Importance of   research methodology, approaches of Investigation of solutions for research \nproblem, data collection, analysis of interpretation, necessary instrumentations, criteria of good \nresearch. Defining the research problem, definition of research problem, problem formulation, \nnecessity of defining the problem, technique involved in defining a problem. \n6-hours \nMeaning of research \nResearch is a derivative of French word \"Researche\u201d means quest, pursuit and search for truth. The term \nresearch consists of two words; \nResearch = Re + Search, Re means again and again and search means to find out something. \n The following is the process  \nPerson    observes             phenomena",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_9df67bc6ce4f440a840d4aaa6455899e": {
    "id": "parent_9df67bc6ce4f440a840d4aaa6455899e",
    "metadata": {
      "content": "s to find out something. \n The following is the process  \nPerson    observes             phenomena    collection of data     Conclusions \nagain and again                             analysis of data \n \nTherefore research means to observe the phenomena again and again from different dimension s, \nCollection of data, analysis of data and make conclusions. \n\u2022 The dictionary meaning of research is \u201ccareful  investigation or inquiry especially through \nsearch for new facts in branch of knowledge\u201d \n \n\u2022  Research can also be defined as \"a Scientific and systematic search for pertinent information \non a specific topic\". In-fact research is an art of scientific investigation. \n \n\u2022 The research comprises defining and redefining a problem, formulating the h ypothesis or \nsuggested solution s, collecting , organizing and evaluating data making deductions and \nreaching conclusions and at-last carefully testing the conclusions to determine whether they \nfit the formulating hypothesis. \n \nResearch is",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_d8c5cef38df043ee8cd7921cdc7f7651": {
    "id": "parent_d8c5cef38df043ee8cd7921cdc7f7651",
    "metadata": {
      "content": "ly testing the conclusions to determine whether they \nfit the formulating hypothesis. \n \nResearch is not confined to science and technology only, there are vast areas of research \nin other disciplines such as languages, literature, history and sociology.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n2 | P a g e \n \n \nWhatever might be the subject, research has to be an active, diligent and systematic \nprocess of inquiry in order to discover, interpret or revise facts, events, behaviors and theories. \nApplying the outc ome of research for refinement of  Knowledge in other subject or in \nenhancing the quality of human life. Also becomes a kind of research and development. \n \nObjectives of research  \n \nThe main aim of research is to find out the truth which is hidden and which has not been \ndiscovered till today. Each research study has its own specific purpose.  \nThe following are the research objectives. \n \n1. To gain familiarity with a phenomenon or to achieve new insight into it (stud",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_35ada74c15774161aa41059f68810c2c": {
    "id": "parent_35ada74c15774161aa41059f68810c2c",
    "metadata": {
      "content": "arch objectives. \n \n1. To gain familiarity with a phenomenon or to achieve new insight into it (studies with this \nobject in view are termed as exploratory or formulative research studies) \n2. To portray accurately the characteristics of a particular indiv idual, situation or a group \n(Studies with this object in view are descriptive research studies) \n3. To determine the frequency with which something occurs or with which it is associated \nwith something else (Studies with this object in view are diagnostic - research studies) \n4. To test a hypothesis of Causal relationship between variables. (such studies are hypothesis \ntesting research studies) \n \nMotivation in Research \nWhat makes people to undertake research? This is a fundamental question of importance. The \npossible motives for doing research may be either one or more of the following. \n1. Desire to get a research degree with a consequential benefits. \n2. Desire to face the Challenge in solving the unsolved problems, i.e., conc",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_807a3dd019324a60918b5d85435f8109": {
    "id": "parent_807a3dd019324a60918b5d85435f8109",
    "metadata": {
      "content": "onsequential benefits. \n2. Desire to face the Challenge in solving the unsolved problems, i.e., concern over practical \nproblems initiates research \n3. Desire to get intellectual joy of doing some creative work \n4. Desire to be of service to society. \n5. Desire to get respectability. \nIn addition to above factors, many more factors such as directives of government, employment \nconditions, curiosity about new things, desire to understand causal relationships, social thinking \nmay motivate researchers to perform research operations.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n3 | P a g e \n \n \nImportance of Research or Significance of research \n\u201cAll progress is born of inquiry, Doubt is often better than overconfidence, for it leads to inquiry \nand inquiry leads to inv ention\" is a famous Hud son maxim in context of which the  significance \nof research can be well understood. \n\u2022 Research inculcates scientific and inductive Thinking and promotes the development of \nlogical habits of thi",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_ae232d97b53640af94191d3ebadbd962": {
    "id": "parent_ae232d97b53640af94191d3ebadbd962",
    "metadata": {
      "content": "inculcates scientific and inductive Thinking and promotes the development of \nlogical habits of thinking and organization. \n\u2022 The role of research in several fields of applied economies, whether it is related to business \nor to the economy as a whole, has greatly  increased in modern times. The Increasingly \ncomplex nature of business and govern ment has focused attention on the use of research \nin solving Operational problems \nResearch proves the basis for really all government policies in our economic system e,g \ngovernment budget rest in part on an analysis of the needs and desires of the people and on \nthe availability of revenues to meet such desires \nResearch has its special significance in solving Various Operational and planning probl ems \nof business and industry. (OR and market research) \nResearch is  equally important for social scientists in studying social relationships and in \nseeking answers to various social problems. \nIn addition to the above, the significance of rese",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_3c5ab669d66b4c60b7eb38cc27636c87": {
    "id": "parent_3c5ab669d66b4c60b7eb38cc27636c87",
    "metadata": {
      "content": "in \nseeking answers to various social problems. \nIn addition to the above, the significance of research \n1. To those students who are to write Ph.D. thesis research may mean a way to attain \nhigh position in the social structure. \n2. To professionals in research methodology, research may mean a source of lively hood. \n3. To philosophers and thinkers, research may mean outlet for new ideas and insights \n4. To literary men, research may mean to the development of new styles and creative \nwork \n5. To analysts and intellectual, research may mean the development of new styles and \ncreative work. \n \n \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n4 | P a g e \n \nTypes of Research \nThe basic types of research are as follows. \n\u2022 Descriptive vs Analytical \n\u2022 Applied vs Fundamental \n\u2022 Quantitative vs Qualitative \n\u2022 Conceptual vs Empirical \n\u2022 Some other types of research. \n \n1. Descriptive vs Analytical \n\u2022 Descriptive research includes surveys a nd fact finding enquiries of different kinds. The",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_9fff3fb39bf64626b0c5b7f32d1cde75": {
    "id": "parent_9fff3fb39bf64626b0c5b7f32d1cde75",
    "metadata": {
      "content": "lytical \n\u2022 Descriptive research includes surveys a nd fact finding enquiries of different kinds. The \nmajor purpose of the descriptive research is description of the state of affairs as it exists \nat present \n\u2022 The main characteristic of this method is that the researcher has no control over its \nvariables, he can only report what has happened or what is happening. \n\u2022 Most ex  post facto research projects are used for descriptive research in which the \nresearcher seeks to measure items such as, for example, frequenting of sh opping, \npreference of people etc \n\u2022 The method used are survey methods of all kinds \n \n \nAnalytical research:-In analytical research, researcher has to u se facts or information \nalready available. The researcher attempts to analyze and explain why or how something \nis happening. \n \n2. Applied vs fundamental \nApplied research aims at finding a solution for on immediate problem facing a Society or \nan Industry/business organization. It is to identify social, econom",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_2fe5f85c88a748cc9d924fc74e42f0e5": {
    "id": "parent_2fe5f85c88a748cc9d924fc74e42f0e5",
    "metadata": {
      "content": "ate problem facing a Society or \nan Industry/business organization. It is to identify social, economic or political trends. The \nCentral aim of applied research is to discover a solution for some practical problem. (Used \nin business, medicine and education)  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n5 | P a g e \n \n\u2022 Fundamental research: -This research is mainly concerned with generalization and with \nthe formation of a theory. Gathering knowledge for knowledge\u2019s sake is termed as \"pure \nor basic research\u201d. \nExample: - Research concerning some natural phenomenon or relating to pure \nmathematics. \n\u2022 Studies concerning human behavior. \n \n3. Quantitative vs Qualitative:  \nQuantitative research is based on the measurement of quantity or amount. It is applicable to \nphenomena that can be expressed in term of quantity. It is more concerned with questions about \nhow much? how many? how often? to what extent etc. It is used not only in physical sciences \nbut also in economics, social scie",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_ca1abae93bbd4c83b11b62edb25e16da": {
    "id": "parent_ca1abae93bbd4c83b11b62edb25e16da",
    "metadata": {
      "content": "en? to what extent etc. It is used not only in physical sciences \nbut also in economics, social science and biology. \nQualitative research is concerned with q ualitative phenomena involving quality o r kind. For \ninstance, when we are Interested in investigating the reasons for human behavior i.e., why people \nthink or do  certain things. We talk of motivation research as an important type of Qualitative \nresearch \nIt is undertaken to gain in sights concerning to attitudes to behave in a particular manner. \n \n4. Conceptual vs Empirical \nConceptual research is related to some abstract idea or theory. It is used by philosophers and \nthinkers to develop new concepts or to interpret existing ones . It is preferred in social sciences \nand philosophy. Here, the researcher tackle  the problem s part by pa rt. He breaks down the \nconcept into smaller, simpler parts to understand it better. \nEmpirical research: - This research relies on experience or observation alone. It is data -based \nresear",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_7482f8edc58c4a3caa08ebe87d6b88bf": {
    "id": "parent_7482f8edc58c4a3caa08ebe87d6b88bf",
    "metadata": {
      "content": "rical research: - This research relies on experience or observation alone. It is data -based \nresearch, coming up with conclusions which are capable of being verified by observations or \nexperiment. It is also known as experimental type of research. \nIt is appropriate when proof is s ought that certain variables affect other variables in some way. \nEvidence gathered through experiments are empirical studies  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n6 | P a g e \n \nSome other types of research: All other types of research are variations of one or more of the \nabove stated approaches \nThey are based on either the purpose of research or time required to accomplish the research. \n1. One Time Research or Longitudinal Research \n\u2022 Research is confined to a single time period  \n\u2022 In case of longitudinal research, the   research is carried out on over several time periods \n \n2. Clinical or Diagnostic Research \n   Such researches follow case study methods. Such studies go deep into the Cause",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_bec65701f2c74d2694ff5a95e3b3b9b0": {
    "id": "parent_bec65701f2c74d2694ff5a95e3b3b9b0",
    "metadata": {
      "content": "agnostic Research \n   Such researches follow case study methods. Such studies go deep into the Causes of things or \nevents. E.g. Small samples and deep probing \n \n3. Formalized research: - these studies are those with substantial Structure and with specific \nhypothesis to be tested. \n \n4. Historical research: It utilizes historical documents , remains etc to study events or ideas of \npast. \n \n5. Conclusion oriented and decision Oriented \n\u2022 While doing conclusion-oriented research, a researcher is free to pick up a problem, design the \nenquiry as he proceeds and is prepared to conceptualize as he wishes \n\u2022 Decision oriented research is always for the need of a decision maker and the researcher in this \ncase is not free to embark upon research according to his own inclination. \ne.g. Operations Research \nResearch method vs methodology \nResearch methods there are methods/ Techniques that are used for conduction of research. The \nresearch method can put into following 3 groups \n1. This grou",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_3dc37c6221a343b2b31380259ce13453": {
    "id": "parent_3dc37c6221a343b2b31380259ce13453",
    "metadata": {
      "content": "used for conduction of research. The \nresearch method can put into following 3 groups \n1. This group include those methods which are concerned with its collection of data. These \nmethods will be used where the data already available are not sufficient to arrive at the required \nsolution  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n7 | P a g e \n \n2. This group includes those statistical techniques which are used for establishing relationship \nbetween the data and its unknowns \n3. This group cons ists of those methods which are used to evaluate its accuracy of the results \nobtained \nResearch methods are various procedures, schemes and algorithm used in research. They include \ntheoretical procedures, experimental Studies, numerical schemes, statistical approaches etc. \nResearch methodology \nIt is a systematic way to solve a problem. It has many di mensions and research methods. So  \nresearch method constitutes a part of research methodology. The scope of research methodology \nis wider",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_09e59820132f40019920ecf20c190fa8": {
    "id": "parent_09e59820132f40019920ecf20c190fa8",
    "metadata": {
      "content": "arch method constitutes a part of research methodology. The scope of research methodology \nis wider than that of research methods. \nIt is a science of studying now research is to be carried out \nIt is also defined as study of methods by which knowledge in gained . It plans to give the work \nplan of the research. \nResearch process (various stages of research) Research process consists of series of actions or \nsteps necessary to effectively carried out research. The following are the various steps of research \nprocess; \n1. Formulating the research problem \n2. Extensive literature survey \n3. Developing a hypothesis \n4 Preparing the research design \n5 Determining the sample design \n6 Collecting the data \n7  Execution of the project \n8  Analysis of data \n9 Hypothesis testing \n10 Generalization and interpretation \n11 Preparation of the report or presentation of  the results i .e., formal write -up of the \nconclusions researched.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n8 | P a g e",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_5c99e953a90848f6985f09e78a87931f": {
    "id": "parent_5c99e953a90848f6985f09e78a87931f",
    "metadata": {
      "content": "-up of the \nconclusions researched.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n8 | P a g e \n \n \n1. Formulating the research problem \n \n\u2022 The first step in the research process is to identify a problem or develop research question. \nThere are 2 types of research problems Viz-related to  \ni) States of nature \nii) Relationship between Variable, \n\u2022 Researcher must decide the general area of interest or aspect of a subject matter to study. \n\u2022 Essentially 2 steps are involved in formulating the problem is  \n(i) Understanding the problem thoroughly  \n(ii) Rephrasing the same into a meaningful term from an analytical point of view. \n\u2022 The best way of understanding the problem is to discuss with one's own colleagues or with \nsome expertise in the matter or guide. \n \n \n \n \n \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n9 | P a g e \n \n2. Extensive literature survey \n\u2022 Once the problem is formulated, a brief summary of it should be prepared. It is compulsory \nfor a researcher writing a thesis",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_79a146ba2f4845868ac10b546eb6afb0": {
    "id": "parent_79a146ba2f4845868ac10b546eb6afb0",
    "metadata": {
      "content": "lated, a brief summary of it should be prepared. It is compulsory \nfor a researcher writing a thesis for Ph.D. degree synopsis of the topic and submit it to the \nnecessary committee or the research board for approval. \n\u2022 To do this, the researcher must review the literature related to the pro blem. This step \nprovides fundamental knowledge about the problem area. \n\u2022 The review of literature also educates the researcher about what s tudies have been \nconducted in the  past, how then studies were conducted and conclusion in the problem \narea. \n \n3. Developing the hypothesis \nAfter extensive literature survey, researcher should state in clear terms the working hypothesis or \nhypotheses. It plays an important role. Working hypothesis is a tentative assumption made in order \nto draw out and test its logical or empirical consequences.  \nWorking hypothesis can be developed by using the following approach. \n\u2022 Discussions with colleague, and experts about the problems \n\u2022 Examination of data and",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_6dd77c558e8e42268ed69d929ed08b82": {
    "id": "parent_6dd77c558e8e42268ed69d929ed08b82",
    "metadata": {
      "content": "g approach. \n\u2022 Discussions with colleague, and experts about the problems \n\u2022 Examination of data and records, if available \n\u2022 Review of Similar studies \n\u2022 Exploratory personal investigation which involves original field interviews on limited \nscale with a View to secure greater insight into to practical aspects of the problem. \n \n4. Preparing the research design:  \nThe researcher is required to prepare a research design i.e., he will state the conceptual structure \nwithin which research would be conducted. There are several research designs such as \nexperimental and non-experimental hypothesis testing. \n \n \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n10 | P a g e \n \nThe research design appropriate for a particular research problem, involves the consideration of \nthe following. \n\u2022 The means of obtaining information \n\u2022 The availability and skills of the researcher and his staff (if any) \n\u2022 Explanation of the way in which selected means of obtained Information will be organized \nand t",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_0921765de9d74a878266f0260338df62": {
    "id": "parent_0921765de9d74a878266f0260338df62",
    "metadata": {
      "content": ") \n\u2022 Explanation of the way in which selected means of obtained Information will be organized \nand the reasoning leading to the solution. \n\u2022 The time available for research  \n\u2022 Cost factor relating to research i.e., finance available for the purpose \n5. Determining sample design : the way of selecting a sample is  popularly known as research \ndesign. A brief mention of the important sample design is as follows. \n\u2170) Deliberate Sampling: It is also known as purposive or non-probability. This method involves \npurposive or deliberate Selection of particular units of the Universe. \n\u2171) Simple random sampling this type of sampling is known as chance sampling or  probability \nsampling. In this case each & every item in the population has an equal Chance of being inclusion \nin the sample. \n e.g. If we have to select a sample  of 300 items from a universe of 15,000 items, we can put the \nnames or numbers for all 15,000 items on slips of paper and conduct a lottery. \n(iii) Systematic sampling: In",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_d86b4a0347c143d4a6e0a5970fb900c6": {
    "id": "parent_d86b4a0347c143d4a6e0a5970fb900c6",
    "metadata": {
      "content": "numbers for all 15,000 items on slips of paper and conduct a lottery. \n(iii) Systematic sampling: In some instances the most practical way of sampling to select every \n15th name on a list, every 10th house on one side of a street and so on. \niv) Stratified sampling: It is important that sample includes representative groups of study units \nwith specific Characteristic Eg. Residents from urban and rural areas. Sampling frame must be \ndivided into groups or states according to their characteristics. Samples of predetermined size will \nthen will have to be obtained from each group. \nv) Quota sampling: the actual selection of items for the sample is left to interviewers judgement  \nvi) Cluster sampling and area sampling \nIt involves grouping to population. Then group or clusters are selected rather than individual for \ninclusion in the sample.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n11 | P a g e \n \nE.g. Suppose a departmental store wishes to sample its Credit Card holders. It has is",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_a6d3452b0cd94eeeb47fa19ec6cb701d": {
    "id": "parent_a6d3452b0cd94eeeb47fa19ec6cb701d",
    "metadata": {
      "content": "1 | P a g e \n \nE.g. Suppose a departmental store wishes to sample its Credit Card holders. It has issued its Cards \nto 15,000 customers. The sample size is say 450. Among 15,000 customer 100 clusters are formed, \neach cluster consists of 150 card holders. 3 clusters are selected for sample randomly. \nUnder area sampling the total area is to be divided into a number of smaller non- over lapping \narea. These are known as geographical clusters. Then a number of these smaller areas randomly \nselected to form a sample.  \nvii) Multistage sampling. In this first stage may be select large primary sampling units such as \nstates, then districts, then town and finally certain families with in towns. If the technique of \nrandom. Sampling is applied at all stages,  the sampling procedure is described as multistage \nrandom sampling. \nViii) Sequential sampling: This design is usually adopted under acceptance sampling plan in the \ncontext of statistical quality control \n \n6) Collection of data: \nThere",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_1d283816a93d497090fa2022cfbaf340": {
    "id": "parent_1d283816a93d497090fa2022cfbaf340",
    "metadata": {
      "content": "ptance sampling plan in the \ncontext of statistical quality control \n \n6) Collection of data: \nThere are several ways of collecting the appropriate data. They are different in context of money \ncosts, time and other resources of research. \nPrimary data can be collected either through experiment or through surveys . T he researcher \nconducts experiment and observes some quantitative measurement of data. \nIn case of a survey, data can be collected by one or more of the following. \n\u2022 By observation \n\u2022 Through personal interviews \n\u2022 Through telephone interviews  \n\u2022 By mailing of Questionnaires \n \n7. Execution of project: This step is very important in research process. The data to be collected \nwould be adequate and dependable. The project should be executed in a systematic manner and \nin-time.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n12 | P a g e \n \n8. Analysis of data. After collection of data the next task is the analysis of data. The analysis of \ndata requires a number of closely",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_de9dba47a1354a0a82d44a2305df2ff3": {
    "id": "parent_de9dba47a1354a0a82d44a2305df2ff3",
    "metadata": {
      "content": "on of data the next task is the analysis of data. The analysis of \ndata requires a number of closely related Operation such as establishment of categories of raw \ndata through Coding tabulation and then drawing statistical inferences. \nAnalysis work is based on the computation of various percentages, coefficients etc \n9. Hypothesis testing various tests, such as chi-square test, t-test, F-test, have been developed by \nthe statisticians for the purpose. There tests depend upon the nature and objective of research. \nHypothesis testing will result in either accepting the hypothesis or in rejecting it. \n10. Generalizations and interpretation when hypothesis is tested several times, it is possible to \narrive at generalizations i.e., to build a theory. When there is no hypothesis to start with, findings \ncan be explained on the basis of same theory. It is known as interpretation. \n11. Preparation of the report or the thesis finally, the researcher has to prepare the report of  \nwhat has been",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_bb98d3d855a443d59475c80855a61076": {
    "id": "parent_bb98d3d855a443d59475c80855a61076",
    "metadata": {
      "content": "ion of the report or the thesis finally, the researcher has to prepare the report of  \nwhat has been done by him . Writing repor t must be done with great care keeping view the \nfollowing \nThe layout report should be as follows \n1) The preliminary pages 2) Main text 3) The end matter. \nIn its preliminary pages to report should carry \n\u2022 Title and date \n\u2022 Acknowledgements and forward  \n\u2022 Table of contents, list of tables, and graphs etc \nThe main text of lo report should have the following parts \nIntroduction: It should contain a clear statement of the objectives research and an explanation \nof the methodology adopted in accomplishing to research. The scope of let\u2019s study along with \nvarious limitation should be stated in this part \n Summary of findings: After introduction there would appear a statement of findings and \nrecommendations in non-technical language.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n13 | P a g e \n \n\u2022 Main par t: the main body of the report should be presented in",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_070bfcd4fdf149b496f9588bae22e66c": {
    "id": "parent_070bfcd4fdf149b496f9588bae22e66c",
    "metadata": {
      "content": "rofessor, IEM, SIT \n13 | P a g e \n \n\u2022 Main par t: the main body of the report should be presented in logical sequence and broken \ndown into readily identifiable sections. \n\u2022 Conclusions towards the end of main text, researcher should again putdown the results of his \nresearch clearly and precisely. In fact, it is the final summing up. \nAt the end of the report, appendices should be enlisted in respect of all technical data. \nBibliography is list    of books, journals, reports should also be given in the end. \nResearch and scientific method \nResearch and scientific method are clo sely related. Research can be termed as  \"an inquiry into \nthe nature of, to reasons for, and it consequences of any particular set of circumstance, where \nthese circumstances are experimentally controlled or recorded just as they occur. Further research \nimplies the  researcher is interested in mor e than particula r results, he is interested in the \nrepeatability of results and in their extension to more comp",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_394943288a124f8c89997952aa8fe3f3": {
    "id": "parent_394943288a124f8c89997952aa8fe3f3",
    "metadata": {
      "content": "ula r results, he is interested in the \nrepeatability of results and in their extension to more complicated and general situations\" \nThe scientific method is one and same in all branches (of science) and that method is the method \nof all logically trained minds ... the unity of all sciences cons ists alone in its methods, not its \nmaterial, the man who classifies facts of any kind whatever, who sees their mutual relations and \ndescribes their sequences, is applying the scientific method and is a man of science \n Research differs from scientific method only in view point and philosophy. The scientific method \nis based on certain basic postulates which can be stated as under. \n\u2022 It relies on empirical evidence. \n\u2022 It utilizes relevant concept \n\u2022 It is committed to only objective considerations \n\u2022 It presupposes ethical neutrality  \n\u2022 It results into probabilistic predictions \n\u2022 Its methodology is made known to all concerned \nScientific method encourages a rigorous Impersonal mode of proc",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_58dd481dffe0480ea66027f10ab704b5": {
    "id": "parent_58dd481dffe0480ea66027f10ab704b5",
    "metadata": {
      "content": "logy is made known to all concerned \nScientific method encourages a rigorous Impersonal mode of procedure dictated by the demand \nlogic and objective procedures \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n14 | P a g e \n \nResearch approaches \nThere are two basic approaches to research \n1. Quantitative approach \n2. Qualitative approach. \n \n\u2022 The quantitative approach involves the generation of data in quantitative form which can \nbe subjected to rigorous quantitative analysis in a formal and rigid fashion. This approach \ncan be further sub  classified to inferential, experimental and simulation approaches to \nresearch. \n \n\u2022 The purpose of inferential approach to research is to form a data base from which to inter \nrelationship o f population. Normally this is s urvey research where the sample of \npopulation is studied to determine its characteristics and it is then inferred that population \nhas the same characteristics  \n \n\u2022 Experimental approach is characterized by much greater con",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_8bf27cf0f64c4e4fad88376753ecebfa": {
    "id": "parent_8bf27cf0f64c4e4fad88376753ecebfa",
    "metadata": {
      "content": "ation \nhas the same characteristics  \n \n\u2022 Experimental approach is characterized by much greater control over the researc h \nenvironment and in this care s ome variables are manipulated to observe their effect on \nother variables. \n \n\u2022 Simulation approach involves the cre ation of an artif icial environment within which the  \nrelevant information and data can be generated. This permits to an observation of dynamic \nbehavior of a system under controlled conditions. \n \nQualitative approach to research is concerned with subjective assessment of \nattitude, opinions and behavior. Research i n such a situation is function of  researcher's \ninsights and impressions. Such an approach to research generates result either in non - \nquantitative form or in the form of which are not subjected to rigorous quantitative \nanalysis. \n \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n15 | P a g e \n \nCriteria of good research \nWhatever may be the type of research and studies, one thing is important is tha",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_96d20d667dde48389a1a34ec1b2e6eed": {
    "id": "parent_96d20d667dde48389a1a34ec1b2e6eed",
    "metadata": {
      "content": "ia of good research \nWhatever may be the type of research and studies, one thing is important is that they all meet on \nthe common ground of scientific method employed by them.  \nOne expects scientific research to satisfy the following criteria. \n1. The purpose of research should be clearly defined and common concept be used. \n2. The research procedure used  should be described in sufficient detail to permit another \nresearcher to repeat the research for further advancement, keeping in continuity of what \nhas already been attained. \n3. The procedural design of the research should be carefully planned to yield results that are \nas objective as possible \n4. The researcher should report with complete frankness, flaws in the procedural design and \nestimate their effects upon the findings. \n5. The analysis of data should be sufficiently adequate to reveal its significance. The methods \nof analysis used should be appropriate. The validity and reliability of the data should be \nchecked carefu",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_4a7fcf02e26f4ae597e386dc61057b9b": {
    "id": "parent_4a7fcf02e26f4ae597e386dc61057b9b",
    "metadata": {
      "content": "lysis used should be appropriate. The validity and reliability of the data should be \nchecked carefully. \n6. Conclusions should be confined to those justified by the data of the research and limited \nto those for which the data to provide an adequate basis  \n7. Greater confidences in research is warranted if the researcher  is experienced, has a good \nreputation in research and is a person of integrity.  \n \nIn other words, we can state the quality of a good research as under. \n1. Good research is  systematic: It mean that the research is structured wi th specific \nsteps to be taken in a specified sequence in accordance with the well defined set of \nrules. \n2. Good research is  logical: It means t hat research is guided by the ru les of logical \nreasoning and the logical process of induction and deduction are a great value in \ncarrying out research. \n3. Good research is empirical : It implies that research is related basically to one or \nmore aspects of a real situation and deals with c",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_6ef790b95eb44c46b46cb78f15cb95c3": {
    "id": "parent_6ef790b95eb44c46b46cb78f15cb95c3",
    "metadata": {
      "content": "lies that research is related basically to one or \nmore aspects of a real situation and deals with concrete data that provides a basis for \nexternal Validity research results  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n16 | P a g e \n \n4. Good result is replicable:  This characteristic allows research results  to be verified \nby replicating the study and thereby building a sound basis for decisions.  \n \nResearch problem \nWhat is research problem? \nResearch problem refers to some difficulty which a researcher experiences in the context of either \na Theoretical or Practical situation or wants to obtain solution for the same.  \nThe components of research problem are \n1) There must be an individual or group which has some difficulty or the problem \n2) There must be some objective(s) to be attained at. \n3) There must be alternative means or (Course of action) for obtaining the Objective(s) \none wishes to attain. \n4) There must remain some doubt in the mind of a researcher with regard to t",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_046a14a773404efdb45c0f18e9ff68b7": {
    "id": "parent_046a14a773404efdb45c0f18e9ff68b7",
    "metadata": {
      "content": "one wishes to attain. \n4) There must remain some doubt in the mind of a researcher with regard to the selection \nof alternatives. \n5) There must be some environment(s) to which the difficulty pertains. \nThus, a research problem is one which requires the researcher to find out the best solution for the \ngiven problem i.e., to find out which course of action the objective can be attained optimally in \nthe context of a given environment. \nNecessity of defining the problem \nWe all hear that a problem clearly  stated is a problem half solved. This statement signifies  the \nneed for defining a research problem. The problem to be investigated must be defined clearly. \nThis will help to discriminate relevant data from the irrelevant ones. A proper definition of the \nresearch problem will enable it researcher to be on track where are ill defined problem may create \nhurdles. Questions like w hat data are to be collected? W hat characteristics of data are relevant \nand need to be studied? What r",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_dcdaeabcd3d246b89cfae0bda041ac21": {
    "id": "parent_dcdaeabcd3d246b89cfae0bda041ac21",
    "metadata": {
      "content": "data are to be collected? W hat characteristics of data are relevant \nand need to be studied? What relations to be explored? What techniques are to be used for the \npurposes? and similar other questions crop up in the mind of a researcher who can w ell plan his \nstrategy and find answers to all such questions only when to research problem has been well \ndefined. Thus, defining research problem properly is a prerequisite for any study and is a step of  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n17 | P a g e \n \nthe highest importance. It is only on careful detailing to research problem that we can work out \nthe research design and can smoothly carry on all the consequential steps involved while doing \nresearch. \nTechnique involved in defining a problem \nThe research problem should be defined in a systematic manner. The technique for the purpose \ninvolves to following steps generally one after the other; \n\u2022 Statement of the problems in general way  \n\u2022 Understanding the nature of the pr",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_2f29aa59bdc34dd4b365d2ad4d597c75": {
    "id": "parent_2f29aa59bdc34dd4b365d2ad4d597c75",
    "metadata": {
      "content": "after the other; \n\u2022 Statement of the problems in general way  \n\u2022 Understanding the nature of the problem \n\u2022 Surveying the available literature \n\u2022 Developing the ideas through discussion  \n\u2022 Rephrasing the research problem into a working proposition. \nStatement of the problem in general way \n The problem should be stated in broad general way Keeping in view practical concern or some \nscientific or intellectual interest. In case of a social research, it is advisable to do some field \nobservations and as such the researcher may undertake some sort  of preliminary survey or pilot \nsurvey. \nUnderstanding the nature of the problem \nNext step is to understand its origin and nature clearly. The way of understanding the problem is \nto discuss it with those who first rais ed it in order to find out how the problem originally ca me \nout and with what Objectives in view. If the researcher has stated to problem himself, he should \nconsider once again all those points that induced him to make a gen",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_db31b63239654d7992d9b4f5f080888b": {
    "id": "parent_db31b63239654d7992d9b4f5f080888b",
    "metadata": {
      "content": "d to problem himself, he should \nconsider once again all those points that induced him to make a general statement concerning the \nproblem. \nSurveying to alternative literature. \nAll available literature concerning the problem at hand must be surveyed and examined before a \ndefinition of a research problem is given. This means that researcher mus t be well conversant \nwith relevant theories in the field, report and records. He must devote sufficient time in reviewing \nof research already undertaken on related problems. \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n18 | P a g e \n \nDeveloping the ideas through discussions \nDiscussion concerning it problem often pro duces u seful information. Various new ideas can \ndevelop through such exercise. Therefore, a researcher must discuss his problem with his \ncolleagues, and others who have enough expertise or experience in the same or area. This is quite \noften known as experience survey. \nRephrasing the research problem \nFinally, the resea",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_8680e3b0a5a04375abf51b90b7b4c143": {
    "id": "parent_8680e3b0a5a04375abf51b90b7b4c143",
    "metadata": {
      "content": "his is quite \noften known as experience survey. \nRephrasing the research problem \nFinally, the researcher rephrases the research problem into a working proposition. The research \nproblem is rephrased into analytical or operational terms. \nIn addition to the above, the following points must also be observed while defining a problem. \na. Technical terms and words \nb. Basic assumptions should be clearly defined. \nc. A straightforward statement of the value of the investigation    should be provided \nd. The suitability of the time period and the sources of data available must also be \nconsidered \ne. The scope of the Investigation or limits within which the problem is to be studied.",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_01e444b4af9247d1b89cd281cab5922f": {
    "id": "parent_01e444b4af9247d1b89cd281cab5922f",
    "metadata": {
      "content": "Dr. J P Ganjigatti, Professor, IEM, SIT \n1 | P a g e \n \nRESEARCH METHODOLOGY AND IPR (SHS04) \nUnit-I \nResearch methodology  objectives and motivation of research -Types of research, research \napproaches, research methods verses methodology, research and research methodology, scientific \nmethod, Importance of   research methodology, approaches of Investigation of solutions for research \nproblem, data collection, analysis of interpretation, necessary instrumentations, criteria of good \nresearch. Defining the research problem, definition of research problem, problem formulation, \nnecessity of defining the problem, technique involved in defining a problem. \n6-hours \nMeaning of research \nResearch is a derivative of French word \"Researche\u201d means quest, pursuit and search for truth. The term \nresearch consists of two words; \nResearch = Re + Search, Re means again and again and search means to find out something. \n The following is the process  \nPerson    observes             phenomena",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_b10b5122ce91403e8f4bb326b68cc696": {
    "id": "parent_b10b5122ce91403e8f4bb326b68cc696",
    "metadata": {
      "content": "s to find out something. \n The following is the process  \nPerson    observes             phenomena    collection of data     Conclusions \nagain and again                             analysis of data \n \nTherefore research means to observe the phenomena again and again from different dimension s, \nCollection of data, analysis of data and make conclusions. \n\u2022 The dictionary meaning of research is \u201ccareful  investigation or inquiry especially through \nsearch for new facts in branch of knowledge\u201d \n \n\u2022  Research can also be defined as \"a Scientific and systematic search for pertinent information \non a specific topic\". In-fact research is an art of scientific investigation. \n \n\u2022 The research comprises defining and redefining a problem, formulating the h ypothesis or \nsuggested solution s, collecting , organizing and evaluating data making deductions and \nreaching conclusions and at-last carefully testing the conclusions to determine whether they \nfit the formulating hypothesis. \n \nResearch is",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_81fbe43eff0c46cc80cc0c2230e119a0": {
    "id": "parent_81fbe43eff0c46cc80cc0c2230e119a0",
    "metadata": {
      "content": "ly testing the conclusions to determine whether they \nfit the formulating hypothesis. \n \nResearch is not confined to science and technology only, there are vast areas of research \nin other disciplines such as languages, literature, history and sociology.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n2 | P a g e \n \n \nWhatever might be the subject, research has to be an active, diligent and systematic \nprocess of inquiry in order to discover, interpret or revise facts, events, behaviors and theories. \nApplying the outc ome of research for refinement of  Knowledge in other subject or in \nenhancing the quality of human life. Also becomes a kind of research and development. \n \nObjectives of research  \n \nThe main aim of research is to find out the truth which is hidden and which has not been \ndiscovered till today. Each research study has its own specific purpose.  \nThe following are the research objectives. \n \n1. To gain familiarity with a phenomenon or to achieve new insight into it (stud",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_40ff7e29b21f404d9a3c6508a73f0493": {
    "id": "parent_40ff7e29b21f404d9a3c6508a73f0493",
    "metadata": {
      "content": "arch objectives. \n \n1. To gain familiarity with a phenomenon or to achieve new insight into it (studies with this \nobject in view are termed as exploratory or formulative research studies) \n2. To portray accurately the characteristics of a particular indiv idual, situation or a group \n(Studies with this object in view are descriptive research studies) \n3. To determine the frequency with which something occurs or with which it is associated \nwith something else (Studies with this object in view are diagnostic - research studies) \n4. To test a hypothesis of Causal relationship between variables. (such studies are hypothesis \ntesting research studies) \n \nMotivation in Research \nWhat makes people to undertake research? This is a fundamental question of importance. The \npossible motives for doing research may be either one or more of the following. \n1. Desire to get a research degree with a consequential benefits. \n2. Desire to face the Challenge in solving the unsolved problems, i.e., conc",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_18ed774c8eb54d63a37d8e74ed433fca": {
    "id": "parent_18ed774c8eb54d63a37d8e74ed433fca",
    "metadata": {
      "content": "onsequential benefits. \n2. Desire to face the Challenge in solving the unsolved problems, i.e., concern over practical \nproblems initiates research \n3. Desire to get intellectual joy of doing some creative work \n4. Desire to be of service to society. \n5. Desire to get respectability. \nIn addition to above factors, many more factors such as directives of government, employment \nconditions, curiosity about new things, desire to understand causal relationships, social thinking \nmay motivate researchers to perform research operations.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n3 | P a g e \n \n \nImportance of Research or Significance of research \n\u201cAll progress is born of inquiry, Doubt is often better than overconfidence, for it leads to inquiry \nand inquiry leads to inv ention\" is a famous Hud son maxim in context of which the  significance \nof research can be well understood. \n\u2022 Research inculcates scientific and inductive Thinking and promotes the development of \nlogical habits of thi",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_41045d8ea8c24da19d60d8633555aa0d": {
    "id": "parent_41045d8ea8c24da19d60d8633555aa0d",
    "metadata": {
      "content": "inculcates scientific and inductive Thinking and promotes the development of \nlogical habits of thinking and organization. \n\u2022 The role of research in several fields of applied economies, whether it is related to business \nor to the economy as a whole, has greatly  increased in modern times. The Increasingly \ncomplex nature of business and govern ment has focused attention on the use of research \nin solving Operational problems \nResearch proves the basis for really all government policies in our economic system e,g \ngovernment budget rest in part on an analysis of the needs and desires of the people and on \nthe availability of revenues to meet such desires \nResearch has its special significance in solving Various Operational and planning probl ems \nof business and industry. (OR and market research) \nResearch is  equally important for social scientists in studying social relationships and in \nseeking answers to various social problems. \nIn addition to the above, the significance of rese",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_c3857aab2e3a4af79ba9168a44e9f675": {
    "id": "parent_c3857aab2e3a4af79ba9168a44e9f675",
    "metadata": {
      "content": "in \nseeking answers to various social problems. \nIn addition to the above, the significance of research \n1. To those students who are to write Ph.D. thesis research may mean a way to attain \nhigh position in the social structure. \n2. To professionals in research methodology, research may mean a source of lively hood. \n3. To philosophers and thinkers, research may mean outlet for new ideas and insights \n4. To literary men, research may mean to the development of new styles and creative \nwork \n5. To analysts and intellectual, research may mean the development of new styles and \ncreative work. \n \n \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n4 | P a g e \n \nTypes of Research \nThe basic types of research are as follows. \n\u2022 Descriptive vs Analytical \n\u2022 Applied vs Fundamental \n\u2022 Quantitative vs Qualitative \n\u2022 Conceptual vs Empirical \n\u2022 Some other types of research. \n \n1. Descriptive vs Analytical \n\u2022 Descriptive research includes surveys a nd fact finding enquiries of different kinds. The",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_64bbae76dadd44889dc08f03133d13ad": {
    "id": "parent_64bbae76dadd44889dc08f03133d13ad",
    "metadata": {
      "content": "lytical \n\u2022 Descriptive research includes surveys a nd fact finding enquiries of different kinds. The \nmajor purpose of the descriptive research is description of the state of affairs as it exists \nat present \n\u2022 The main characteristic of this method is that the researcher has no control over its \nvariables, he can only report what has happened or what is happening. \n\u2022 Most ex  post facto research projects are used for descriptive research in which the \nresearcher seeks to measure items such as, for example, frequenting of sh opping, \npreference of people etc \n\u2022 The method used are survey methods of all kinds \n \n \nAnalytical research:-In analytical research, researcher has to u se facts or information \nalready available. The researcher attempts to analyze and explain why or how something \nis happening. \n \n2. Applied vs fundamental \nApplied research aims at finding a solution for on immediate problem facing a Society or \nan Industry/business organization. It is to identify social, econom",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_cd2c0b42fb314f9c8e1272cb810e1cde": {
    "id": "parent_cd2c0b42fb314f9c8e1272cb810e1cde",
    "metadata": {
      "content": "ate problem facing a Society or \nan Industry/business organization. It is to identify social, economic or political trends. The \nCentral aim of applied research is to discover a solution for some practical problem. (Used \nin business, medicine and education)  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n5 | P a g e \n \n\u2022 Fundamental research: -This research is mainly concerned with generalization and with \nthe formation of a theory. Gathering knowledge for knowledge\u2019s sake is termed as \"pure \nor basic research\u201d. \nExample: - Research concerning some natural phenomenon or relating to pure \nmathematics. \n\u2022 Studies concerning human behavior. \n \n3. Quantitative vs Qualitative:  \nQuantitative research is based on the measurement of quantity or amount. It is applicable to \nphenomena that can be expressed in term of quantity. It is more concerned with questions about \nhow much? how many? how often? to what extent etc. It is used not only in physical sciences \nbut also in economics, social scie",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_02f270ac9119469cbb2620d160d207ac": {
    "id": "parent_02f270ac9119469cbb2620d160d207ac",
    "metadata": {
      "content": "en? to what extent etc. It is used not only in physical sciences \nbut also in economics, social science and biology. \nQualitative research is concerned with q ualitative phenomena involving quality o r kind. For \ninstance, when we are Interested in investigating the reasons for human behavior i.e., why people \nthink or do  certain things. We talk of motivation research as an important type of Qualitative \nresearch \nIt is undertaken to gain in sights concerning to attitudes to behave in a particular manner. \n \n4. Conceptual vs Empirical \nConceptual research is related to some abstract idea or theory. It is used by philosophers and \nthinkers to develop new concepts or to interpret existing ones . It is preferred in social sciences \nand philosophy. Here, the researcher tackle  the problem s part by pa rt. He breaks down the \nconcept into smaller, simpler parts to understand it better. \nEmpirical research: - This research relies on experience or observation alone. It is data -based \nresear",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_84705147287d4072a0239068722905a2": {
    "id": "parent_84705147287d4072a0239068722905a2",
    "metadata": {
      "content": "rical research: - This research relies on experience or observation alone. It is data -based \nresearch, coming up with conclusions which are capable of being verified by observations or \nexperiment. It is also known as experimental type of research. \nIt is appropriate when proof is s ought that certain variables affect other variables in some way. \nEvidence gathered through experiments are empirical studies  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n6 | P a g e \n \nSome other types of research: All other types of research are variations of one or more of the \nabove stated approaches \nThey are based on either the purpose of research or time required to accomplish the research. \n1. One Time Research or Longitudinal Research \n\u2022 Research is confined to a single time period  \n\u2022 In case of longitudinal research, the   research is carried out on over several time periods \n \n2. Clinical or Diagnostic Research \n   Such researches follow case study methods. Such studies go deep into the Cause",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_74b8c426a7b8454694966221c5323a4e": {
    "id": "parent_74b8c426a7b8454694966221c5323a4e",
    "metadata": {
      "content": "agnostic Research \n   Such researches follow case study methods. Such studies go deep into the Causes of things or \nevents. E.g. Small samples and deep probing \n \n3. Formalized research: - these studies are those with substantial Structure and with specific \nhypothesis to be tested. \n \n4. Historical research: It utilizes historical documents , remains etc to study events or ideas of \npast. \n \n5. Conclusion oriented and decision Oriented \n\u2022 While doing conclusion-oriented research, a researcher is free to pick up a problem, design the \nenquiry as he proceeds and is prepared to conceptualize as he wishes \n\u2022 Decision oriented research is always for the need of a decision maker and the researcher in this \ncase is not free to embark upon research according to his own inclination. \ne.g. Operations Research \nResearch method vs methodology \nResearch methods there are methods/ Techniques that are used for conduction of research. The \nresearch method can put into following 3 groups \n1. This grou",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_7d484335da5c48fe8c56badf7b206f79": {
    "id": "parent_7d484335da5c48fe8c56badf7b206f79",
    "metadata": {
      "content": "used for conduction of research. The \nresearch method can put into following 3 groups \n1. This group include those methods which are concerned with its collection of data. These \nmethods will be used where the data already available are not sufficient to arrive at the required \nsolution  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n7 | P a g e \n \n2. This group includes those statistical techniques which are used for establishing relationship \nbetween the data and its unknowns \n3. This group cons ists of those methods which are used to evaluate its accuracy of the results \nobtained \nResearch methods are various procedures, schemes and algorithm used in research. They include \ntheoretical procedures, experimental Studies, numerical schemes, statistical approaches etc. \nResearch methodology \nIt is a systematic way to solve a problem. It has many di mensions and research methods. So  \nresearch method constitutes a part of research methodology. The scope of research methodology \nis wider",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_2c819dd751334f9c9a7d0884a2f22ba5": {
    "id": "parent_2c819dd751334f9c9a7d0884a2f22ba5",
    "metadata": {
      "content": "arch method constitutes a part of research methodology. The scope of research methodology \nis wider than that of research methods. \nIt is a science of studying now research is to be carried out \nIt is also defined as study of methods by which knowledge in gained . It plans to give the work \nplan of the research. \nResearch process (various stages of research) Research process consists of series of actions or \nsteps necessary to effectively carried out research. The following are the various steps of research \nprocess; \n1. Formulating the research problem \n2. Extensive literature survey \n3. Developing a hypothesis \n4 Preparing the research design \n5 Determining the sample design \n6 Collecting the data \n7  Execution of the project \n8  Analysis of data \n9 Hypothesis testing \n10 Generalization and interpretation \n11 Preparation of the report or presentation of  the results i .e., formal write -up of the \nconclusions researched.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n8 | P a g e",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_2b2ce2f334924456939443aa243e0e32": {
    "id": "parent_2b2ce2f334924456939443aa243e0e32",
    "metadata": {
      "content": "-up of the \nconclusions researched.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n8 | P a g e \n \n \n1. Formulating the research problem \n \n\u2022 The first step in the research process is to identify a problem or develop research question. \nThere are 2 types of research problems Viz-related to  \ni) States of nature \nii) Relationship between Variable, \n\u2022 Researcher must decide the general area of interest or aspect of a subject matter to study. \n\u2022 Essentially 2 steps are involved in formulating the problem is  \n(i) Understanding the problem thoroughly  \n(ii) Rephrasing the same into a meaningful term from an analytical point of view. \n\u2022 The best way of understanding the problem is to discuss with one's own colleagues or with \nsome expertise in the matter or guide. \n \n \n \n \n \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n9 | P a g e \n \n2. Extensive literature survey \n\u2022 Once the problem is formulated, a brief summary of it should be prepared. It is compulsory \nfor a researcher writing a thesis",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_a4b891952d32499a9f77074d824e8d67": {
    "id": "parent_a4b891952d32499a9f77074d824e8d67",
    "metadata": {
      "content": "lated, a brief summary of it should be prepared. It is compulsory \nfor a researcher writing a thesis for Ph.D. degree synopsis of the topic and submit it to the \nnecessary committee or the research board for approval. \n\u2022 To do this, the researcher must review the literature related to the pro blem. This step \nprovides fundamental knowledge about the problem area. \n\u2022 The review of literature also educates the researcher about what s tudies have been \nconducted in the  past, how then studies were conducted and conclusion in the problem \narea. \n \n3. Developing the hypothesis \nAfter extensive literature survey, researcher should state in clear terms the working hypothesis or \nhypotheses. It plays an important role. Working hypothesis is a tentative assumption made in order \nto draw out and test its logical or empirical consequences.  \nWorking hypothesis can be developed by using the following approach. \n\u2022 Discussions with colleague, and experts about the problems \n\u2022 Examination of data and",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_318c22eac47a495a9cc195003ea4847c": {
    "id": "parent_318c22eac47a495a9cc195003ea4847c",
    "metadata": {
      "content": "g approach. \n\u2022 Discussions with colleague, and experts about the problems \n\u2022 Examination of data and records, if available \n\u2022 Review of Similar studies \n\u2022 Exploratory personal investigation which involves original field interviews on limited \nscale with a View to secure greater insight into to practical aspects of the problem. \n \n4. Preparing the research design:  \nThe researcher is required to prepare a research design i.e., he will state the conceptual structure \nwithin which research would be conducted. There are several research designs such as \nexperimental and non-experimental hypothesis testing. \n \n \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n10 | P a g e \n \nThe research design appropriate for a particular research problem, involves the consideration of \nthe following. \n\u2022 The means of obtaining information \n\u2022 The availability and skills of the researcher and his staff (if any) \n\u2022 Explanation of the way in which selected means of obtained Information will be organized \nand t",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_610be736747b49fa90ecfe1518de39ff": {
    "id": "parent_610be736747b49fa90ecfe1518de39ff",
    "metadata": {
      "content": ") \n\u2022 Explanation of the way in which selected means of obtained Information will be organized \nand the reasoning leading to the solution. \n\u2022 The time available for research  \n\u2022 Cost factor relating to research i.e., finance available for the purpose \n5. Determining sample design : the way of selecting a sample is  popularly known as research \ndesign. A brief mention of the important sample design is as follows. \n\u2170) Deliberate Sampling: It is also known as purposive or non-probability. This method involves \npurposive or deliberate Selection of particular units of the Universe. \n\u2171) Simple random sampling this type of sampling is known as chance sampling or  probability \nsampling. In this case each & every item in the population has an equal Chance of being inclusion \nin the sample. \n e.g. If we have to select a sample  of 300 items from a universe of 15,000 items, we can put the \nnames or numbers for all 15,000 items on slips of paper and conduct a lottery. \n(iii) Systematic sampling: In",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_dd8c54d2d9c44e169d686de967c5b8c6": {
    "id": "parent_dd8c54d2d9c44e169d686de967c5b8c6",
    "metadata": {
      "content": "numbers for all 15,000 items on slips of paper and conduct a lottery. \n(iii) Systematic sampling: In some instances the most practical way of sampling to select every \n15th name on a list, every 10th house on one side of a street and so on. \niv) Stratified sampling: It is important that sample includes representative groups of study units \nwith specific Characteristic Eg. Residents from urban and rural areas. Sampling frame must be \ndivided into groups or states according to their characteristics. Samples of predetermined size will \nthen will have to be obtained from each group. \nv) Quota sampling: the actual selection of items for the sample is left to interviewers judgement  \nvi) Cluster sampling and area sampling \nIt involves grouping to population. Then group or clusters are selected rather than individual for \ninclusion in the sample.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n11 | P a g e \n \nE.g. Suppose a departmental store wishes to sample its Credit Card holders. It has is",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_c8974e3c374849b4be1d1c583b6514d0": {
    "id": "parent_c8974e3c374849b4be1d1c583b6514d0",
    "metadata": {
      "content": "1 | P a g e \n \nE.g. Suppose a departmental store wishes to sample its Credit Card holders. It has issued its Cards \nto 15,000 customers. The sample size is say 450. Among 15,000 customer 100 clusters are formed, \neach cluster consists of 150 card holders. 3 clusters are selected for sample randomly. \nUnder area sampling the total area is to be divided into a number of smaller non- over lapping \narea. These are known as geographical clusters. Then a number of these smaller areas randomly \nselected to form a sample.  \nvii) Multistage sampling. In this first stage may be select large primary sampling units such as \nstates, then districts, then town and finally certain families with in towns. If the technique of \nrandom. Sampling is applied at all stages,  the sampling procedure is described as multistage \nrandom sampling. \nViii) Sequential sampling: This design is usually adopted under acceptance sampling plan in the \ncontext of statistical quality control \n \n6) Collection of data: \nThere",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_e368dfba9b1349808e1cd1dab074bc91": {
    "id": "parent_e368dfba9b1349808e1cd1dab074bc91",
    "metadata": {
      "content": "ptance sampling plan in the \ncontext of statistical quality control \n \n6) Collection of data: \nThere are several ways of collecting the appropriate data. They are different in context of money \ncosts, time and other resources of research. \nPrimary data can be collected either through experiment or through surveys . T he researcher \nconducts experiment and observes some quantitative measurement of data. \nIn case of a survey, data can be collected by one or more of the following. \n\u2022 By observation \n\u2022 Through personal interviews \n\u2022 Through telephone interviews  \n\u2022 By mailing of Questionnaires \n \n7. Execution of project: This step is very important in research process. The data to be collected \nwould be adequate and dependable. The project should be executed in a systematic manner and \nin-time.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n12 | P a g e \n \n8. Analysis of data. After collection of data the next task is the analysis of data. The analysis of \ndata requires a number of closely",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_41f9565981bd48409b8399ccdc4112ee": {
    "id": "parent_41f9565981bd48409b8399ccdc4112ee",
    "metadata": {
      "content": "on of data the next task is the analysis of data. The analysis of \ndata requires a number of closely related Operation such as establishment of categories of raw \ndata through Coding tabulation and then drawing statistical inferences. \nAnalysis work is based on the computation of various percentages, coefficients etc \n9. Hypothesis testing various tests, such as chi-square test, t-test, F-test, have been developed by \nthe statisticians for the purpose. There tests depend upon the nature and objective of research. \nHypothesis testing will result in either accepting the hypothesis or in rejecting it. \n10. Generalizations and interpretation when hypothesis is tested several times, it is possible to \narrive at generalizations i.e., to build a theory. When there is no hypothesis to start with, findings \ncan be explained on the basis of same theory. It is known as interpretation. \n11. Preparation of the report or the thesis finally, the researcher has to prepare the report of  \nwhat has been",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_9f9e5b2758d04e7cb72103ad893531a6": {
    "id": "parent_9f9e5b2758d04e7cb72103ad893531a6",
    "metadata": {
      "content": "ion of the report or the thesis finally, the researcher has to prepare the report of  \nwhat has been done by him . Writing repor t must be done with great care keeping view the \nfollowing \nThe layout report should be as follows \n1) The preliminary pages 2) Main text 3) The end matter. \nIn its preliminary pages to report should carry \n\u2022 Title and date \n\u2022 Acknowledgements and forward  \n\u2022 Table of contents, list of tables, and graphs etc \nThe main text of lo report should have the following parts \nIntroduction: It should contain a clear statement of the objectives research and an explanation \nof the methodology adopted in accomplishing to research. The scope of let\u2019s study along with \nvarious limitation should be stated in this part \n Summary of findings: After introduction there would appear a statement of findings and \nrecommendations in non-technical language.  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n13 | P a g e \n \n\u2022 Main par t: the main body of the report should be presented in",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_6b4295db4337473482718a4d7e5859da": {
    "id": "parent_6b4295db4337473482718a4d7e5859da",
    "metadata": {
      "content": "rofessor, IEM, SIT \n13 | P a g e \n \n\u2022 Main par t: the main body of the report should be presented in logical sequence and broken \ndown into readily identifiable sections. \n\u2022 Conclusions towards the end of main text, researcher should again putdown the results of his \nresearch clearly and precisely. In fact, it is the final summing up. \nAt the end of the report, appendices should be enlisted in respect of all technical data. \nBibliography is list    of books, journals, reports should also be given in the end. \nResearch and scientific method \nResearch and scientific method are clo sely related. Research can be termed as  \"an inquiry into \nthe nature of, to reasons for, and it consequences of any particular set of circumstance, where \nthese circumstances are experimentally controlled or recorded just as they occur. Further research \nimplies the  researcher is interested in mor e than particula r results, he is interested in the \nrepeatability of results and in their extension to more comp",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_c484e0ed331a4b2588c36cb751c05b7a": {
    "id": "parent_c484e0ed331a4b2588c36cb751c05b7a",
    "metadata": {
      "content": "ula r results, he is interested in the \nrepeatability of results and in their extension to more complicated and general situations\" \nThe scientific method is one and same in all branches (of science) and that method is the method \nof all logically trained minds ... the unity of all sciences cons ists alone in its methods, not its \nmaterial, the man who classifies facts of any kind whatever, who sees their mutual relations and \ndescribes their sequences, is applying the scientific method and is a man of science \n Research differs from scientific method only in view point and philosophy. The scientific method \nis based on certain basic postulates which can be stated as under. \n\u2022 It relies on empirical evidence. \n\u2022 It utilizes relevant concept \n\u2022 It is committed to only objective considerations \n\u2022 It presupposes ethical neutrality  \n\u2022 It results into probabilistic predictions \n\u2022 Its methodology is made known to all concerned \nScientific method encourages a rigorous Impersonal mode of proc",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_41d0190e19e24721becbd90d0ac1bb6a": {
    "id": "parent_41d0190e19e24721becbd90d0ac1bb6a",
    "metadata": {
      "content": "logy is made known to all concerned \nScientific method encourages a rigorous Impersonal mode of procedure dictated by the demand \nlogic and objective procedures \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n14 | P a g e \n \nResearch approaches \nThere are two basic approaches to research \n1. Quantitative approach \n2. Qualitative approach. \n \n\u2022 The quantitative approach involves the generation of data in quantitative form which can \nbe subjected to rigorous quantitative analysis in a formal and rigid fashion. This approach \ncan be further sub  classified to inferential, experimental and simulation approaches to \nresearch. \n \n\u2022 The purpose of inferential approach to research is to form a data base from which to inter \nrelationship o f population. Normally this is s urvey research where the sample of \npopulation is studied to determine its characteristics and it is then inferred that population \nhas the same characteristics  \n \n\u2022 Experimental approach is characterized by much greater con",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_68a37182dc5a40e5aff12b98deebce64": {
    "id": "parent_68a37182dc5a40e5aff12b98deebce64",
    "metadata": {
      "content": "ation \nhas the same characteristics  \n \n\u2022 Experimental approach is characterized by much greater control over the researc h \nenvironment and in this care s ome variables are manipulated to observe their effect on \nother variables. \n \n\u2022 Simulation approach involves the cre ation of an artif icial environment within which the  \nrelevant information and data can be generated. This permits to an observation of dynamic \nbehavior of a system under controlled conditions. \n \nQualitative approach to research is concerned with subjective assessment of \nattitude, opinions and behavior. Research i n such a situation is function of  researcher's \ninsights and impressions. Such an approach to research generates result either in non - \nquantitative form or in the form of which are not subjected to rigorous quantitative \nanalysis. \n \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n15 | P a g e \n \nCriteria of good research \nWhatever may be the type of research and studies, one thing is important is tha",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_370df772fc6b4b31b855ef1bf28cc0bb": {
    "id": "parent_370df772fc6b4b31b855ef1bf28cc0bb",
    "metadata": {
      "content": "ia of good research \nWhatever may be the type of research and studies, one thing is important is that they all meet on \nthe common ground of scientific method employed by them.  \nOne expects scientific research to satisfy the following criteria. \n1. The purpose of research should be clearly defined and common concept be used. \n2. The research procedure used  should be described in sufficient detail to permit another \nresearcher to repeat the research for further advancement, keeping in continuity of what \nhas already been attained. \n3. The procedural design of the research should be carefully planned to yield results that are \nas objective as possible \n4. The researcher should report with complete frankness, flaws in the procedural design and \nestimate their effects upon the findings. \n5. The analysis of data should be sufficiently adequate to reveal its significance. The methods \nof analysis used should be appropriate. The validity and reliability of the data should be \nchecked carefu",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_00a28e6bc18e4952b61aeb2f364dca89": {
    "id": "parent_00a28e6bc18e4952b61aeb2f364dca89",
    "metadata": {
      "content": "lysis used should be appropriate. The validity and reliability of the data should be \nchecked carefully. \n6. Conclusions should be confined to those justified by the data of the research and limited \nto those for which the data to provide an adequate basis  \n7. Greater confidences in research is warranted if the researcher  is experienced, has a good \nreputation in research and is a person of integrity.  \n \nIn other words, we can state the quality of a good research as under. \n1. Good research is  systematic: It mean that the research is structured wi th specific \nsteps to be taken in a specified sequence in accordance with the well defined set of \nrules. \n2. Good research is  logical: It means t hat research is guided by the ru les of logical \nreasoning and the logical process of induction and deduction are a great value in \ncarrying out research. \n3. Good research is empirical : It implies that research is related basically to one or \nmore aspects of a real situation and deals with c",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_2f5533a4cf03439b8be059c7c40ffe54": {
    "id": "parent_2f5533a4cf03439b8be059c7c40ffe54",
    "metadata": {
      "content": "lies that research is related basically to one or \nmore aspects of a real situation and deals with concrete data that provides a basis for \nexternal Validity research results  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n16 | P a g e \n \n4. Good result is replicable:  This characteristic allows research results  to be verified \nby replicating the study and thereby building a sound basis for decisions.  \n \nResearch problem \nWhat is research problem? \nResearch problem refers to some difficulty which a researcher experiences in the context of either \na Theoretical or Practical situation or wants to obtain solution for the same.  \nThe components of research problem are \n1) There must be an individual or group which has some difficulty or the problem \n2) There must be some objective(s) to be attained at. \n3) There must be alternative means or (Course of action) for obtaining the Objective(s) \none wishes to attain. \n4) There must remain some doubt in the mind of a researcher with regard to t",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_fa158550aa53410b8ad5618df39d38b0": {
    "id": "parent_fa158550aa53410b8ad5618df39d38b0",
    "metadata": {
      "content": "one wishes to attain. \n4) There must remain some doubt in the mind of a researcher with regard to the selection \nof alternatives. \n5) There must be some environment(s) to which the difficulty pertains. \nThus, a research problem is one which requires the researcher to find out the best solution for the \ngiven problem i.e., to find out which course of action the objective can be attained optimally in \nthe context of a given environment. \nNecessity of defining the problem \nWe all hear that a problem clearly  stated is a problem half solved. This statement signifies  the \nneed for defining a research problem. The problem to be investigated must be defined clearly. \nThis will help to discriminate relevant data from the irrelevant ones. A proper definition of the \nresearch problem will enable it researcher to be on track where are ill defined problem may create \nhurdles. Questions like w hat data are to be collected? W hat characteristics of data are relevant \nand need to be studied? What r",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_6fff003a1ee8442899ffc4c34c6eecaa": {
    "id": "parent_6fff003a1ee8442899ffc4c34c6eecaa",
    "metadata": {
      "content": "data are to be collected? W hat characteristics of data are relevant \nand need to be studied? What relations to be explored? What techniques are to be used for the \npurposes? and similar other questions crop up in the mind of a researcher who can w ell plan his \nstrategy and find answers to all such questions only when to research problem has been well \ndefined. Thus, defining research problem properly is a prerequisite for any study and is a step of  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n17 | P a g e \n \nthe highest importance. It is only on careful detailing to research problem that we can work out \nthe research design and can smoothly carry on all the consequential steps involved while doing \nresearch. \nTechnique involved in defining a problem \nThe research problem should be defined in a systematic manner. The technique for the purpose \ninvolves to following steps generally one after the other; \n\u2022 Statement of the problems in general way  \n\u2022 Understanding the nature of the pr",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_cbc186f7d3c64142824648a732193123": {
    "id": "parent_cbc186f7d3c64142824648a732193123",
    "metadata": {
      "content": "after the other; \n\u2022 Statement of the problems in general way  \n\u2022 Understanding the nature of the problem \n\u2022 Surveying the available literature \n\u2022 Developing the ideas through discussion  \n\u2022 Rephrasing the research problem into a working proposition. \nStatement of the problem in general way \n The problem should be stated in broad general way Keeping in view practical concern or some \nscientific or intellectual interest. In case of a social research, it is advisable to do some field \nobservations and as such the researcher may undertake some sort  of preliminary survey or pilot \nsurvey. \nUnderstanding the nature of the problem \nNext step is to understand its origin and nature clearly. The way of understanding the problem is \nto discuss it with those who first rais ed it in order to find out how the problem originally ca me \nout and with what Objectives in view. If the researcher has stated to problem himself, he should \nconsider once again all those points that induced him to make a gen",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_5e1f8adfb0da4f899a2cf7329666d7dd": {
    "id": "parent_5e1f8adfb0da4f899a2cf7329666d7dd",
    "metadata": {
      "content": "d to problem himself, he should \nconsider once again all those points that induced him to make a general statement concerning the \nproblem. \nSurveying to alternative literature. \nAll available literature concerning the problem at hand must be surveyed and examined before a \ndefinition of a research problem is given. This means that researcher mus t be well conversant \nwith relevant theories in the field, report and records. He must devote sufficient time in reviewing \nof research already undertaken on related problems. \n  \n \n \nDr. J P Ganjigatti, Professor, IEM, SIT \n18 | P a g e \n \nDeveloping the ideas through discussions \nDiscussion concerning it problem often pro duces u seful information. Various new ideas can \ndevelop through such exercise. Therefore, a researcher must discuss his problem with his \ncolleagues, and others who have enough expertise or experience in the same or area. This is quite \noften known as experience survey. \nRephrasing the research problem \nFinally, the resea",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_68ac658a269842c196e5d535775ee232": {
    "id": "parent_68ac658a269842c196e5d535775ee232",
    "metadata": {
      "content": "his is quite \noften known as experience survey. \nRephrasing the research problem \nFinally, the researcher rephrases the research problem into a working proposition. The research \nproblem is rephrased into analytical or operational terms. \nIn addition to the above, the following points must also be observed while defining a problem. \na. Technical terms and words \nb. Basic assumptions should be clearly defined. \nc. A straightforward statement of the value of the investigation    should be provided \nd. The suitability of the time period and the sources of data available must also be \nconsidered \ne. The scope of the Investigation or limits within which the problem is to be studied.",
      "title": "SH04-RM - IPR-NOTES-UNIT-I"
    }
  },
  "parent_0e8e82a7f5524fcd890acb8112114742": {
    "id": "parent_0e8e82a7f5524fcd890acb8112114742",
    "metadata": {
      "content": "Event Ideas\n\ud83e\udde9 1. \u201cGuess the Logo\u02ee or \u201cInventor\u02bcs Round\u02ee\n\ud83c\udfaf  Objective\nTo test participants\u02bc knowledge of technology companies, inventions, and inventors in a fun and \ncompetitive way.\n\ud83e\udde0 Event Concept\nParticipants (solo or in teams of 2\ue0893\ue082 are shown:\nLogos of tech companies (like NVIDIA, SpaceX, Intel, etc.), or\nPhotos or clues about famous inventors/scientists (like Nikola Tesla, James Watt, Tim \nBerners-Lee, etc.),\nand they must guess the correct name within the time limit.\n\ud83d\udd79  Round Ideas\nRound 1 \u2013 Logo Blitz\nShow 20\ue08925 logos (some slightly blurred or partial).\nEach question is timed (e.g., 10 seconds).\nCorrect answer = \ue09d10 points.\nNo negative marking.\n\ud83e\udde9 Twist Ideas:\n\u201cHalf Logo\u02ee (only a part shown)\n\u201cOld vs. New Logo\u02ee \u2013 identify the brand from its older version\n\u201cMascot Mania\u02ee \u2013 identify the brand by its character (e.g., Android, GitHub Octocat)\nRound 2 \u2013 Inventor\u02bcs Round\nShow a picture, invention, or a clue.\nExample: \u201cInvented the World Wide Web\u02ee \u2192 Tim Berners-Lee\n\u201cCreated the first pro",
      "title": "events"
    }
  },
  "parent_c6bea402f61a42738be4835de721e3a4": {
    "id": "parent_c6bea402f61a42738be4835de721e3a4",
    "metadata": {
      "content": "nvention, or a clue.\nExample: \u201cInvented the World Wide Web\u02ee \u2192 Tim Berners-Lee\n\u201cCreated the first programmable computer\u02ee \u2192 Charles Babbage\n\u201cKnown for Tesla Coil\u02ee \u2192 Nikola Tesla\nCan also include connect-the-dots style questions:\n\u201cPython \ue1d7 Google \ue1d7 TensorFlow \ue1d7 ?\u02ee \ue081Answer: Guido van Rossum / AI field)\nRound 3 \u2013 Rapid Fire (Final Round)\nTop teams face a buzzer round.\nFastest correct answer gets 10 points; wrong answer \ue09e5.\nEv ent Ide as\n1\ud83c\udfc6  Judging Criteria\nAccuracy of answers\nQuickness of response (tie-breaker)\nIn case of a tie \u2014 bonus round (identify logo by tagline or product clue)\n\ud83e\uddf0 Requirements\nLaptop/projector\nPowerPoint / Canva slides for logos\nBuzzer (or online buzzer app like BuzzIn.Live)\nScoreboard\n\ud83d\udd27  2. \u201cBuild It With Junk\u02ee Challenge\n\ud83c\udfaf  Objective\nEncourage participants to apply creativity, basic engineering principles, and teamwork by building \nsomething functional or cool using scrap or waste materials.\n\ud83d\udca1  Event Concept\nTeams are given a set of junk materials (like wires, plasti",
      "title": "events"
    }
  },
  "parent_c65ec42b07ec48a882efa0ccc1c55f01": {
    "id": "parent_c65ec42b07ec48a882efa0ccc1c55f01",
    "metadata": {
      "content": "rap or waste materials.\n\ud83d\udca1  Event Concept\nTeams are given a set of junk materials (like wires, plastic bottles, cardboard, straws, motors, etc.) \nand a theme.\nThey must create a working prototype or model within the time limit.\n\ud83d\udee0  Example Themes\n\u201cEco-friendly Innovation\u02ee \u2013 make a mini windmill or water filter using junk.\n\u201cSmart Engineering\u02ee \u2013 create a simple mechanical tool, pulley system, or robotic arm.\n\u201cCreative Structures\u02ee \u2013 bridges, towers, or vehicles using only scrap.\n\u201cSave the Planet\u02ee \u2013 something that demonstrates recycling or energy saving.\n\u23f0  Format\nTeams of 3\ue0895 members.\nDuration: 60\ue08990 minutes.\nAll materials must be either provided on the spot or brought as scrap from home.\nNo ready-made kits allowed.\n\ud83e\uddc3  Material Examples\nEv ent Ide as\n2Plastic bottles, old CDs, cardboard boxes\nRubber bands, straws, tape, old wires\nIce cream sticks, syringes, balloons, old motors, etc.\n\ud83e\udde9 Judging Criteria\nCr it er ia Descr iption \n\ud83d\udca1  Creativity & Innovation Unique idea and use of materials\n\u2699",
      "title": "events"
    }
  },
  "parent_a797d9980d914c308592570b3b55c3d2": {
    "id": "parent_a797d9980d914c308592570b3b55c3d2",
    "metadata": {
      "content": "g Criteria\nCr it er ia Descr iption \n\ud83d\udca1  Creativity & Innovation Unique idea and use of materials\n\u2699  Functionality How well it works or demonstrates a concept\n\ud83c\udf31  Theme Relevance How it connects with the given theme\n\ud83c\udfa8  Aesthetics Neatness, stability, and overall look\n\ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1  Teamwork & PresentationCoordination and explanation of idea\n\ud83e\uddf0 Requirements\nTables, workspace area\nBasic tools (scissors, tape, glue gun)\nOptional: fans, lights, or battery sources (if needed)\nJudges: Faculty or seniors from mechanical/electrical background\n\ud83c\udfc6  Prizes / Add-ons\nBest Creative Build\nBest Functional Prototype\nGreen Engineer Award (eco-friendly design)\nEv ent Ide as\n3",
      "title": "events"
    }
  },
  "parent_50d67aa638ac400c8e3bfd6a0e2eb4f8": {
    "id": "parent_50d67aa638ac400c8e3bfd6a0e2eb4f8",
    "metadata": {
      "content": "Event Ideas\n\ud83e\udde9 1. \u201cGuess the Logo\u02ee or \u201cInventor\u02bcs Round\u02ee\n\ud83c\udfaf  Objective\nTo test participants\u02bc knowledge of technology companies, inventions, and inventors in a fun and \ncompetitive way.\n\ud83e\udde0 Event Concept\nParticipants (solo or in teams of 2\ue0893\ue082 are shown:\nLogos of tech companies (like NVIDIA, SpaceX, Intel, etc.), or\nPhotos or clues about famous inventors/scientists (like Nikola Tesla, James Watt, Tim \nBerners-Lee, etc.),\nand they must guess the correct name within the time limit.\n\ud83d\udd79  Round Ideas\nRound 1 \u2013 Logo Blitz\nShow 20\ue08925 logos (some slightly blurred or partial).\nEach question is timed (e.g., 10 seconds).\nCorrect answer = \ue09d10 points.\nNo negative marking.\n\ud83e\udde9 Twist Ideas:\n\u201cHalf Logo\u02ee (only a part shown)\n\u201cOld vs. New Logo\u02ee \u2013 identify the brand from its older version\n\u201cMascot Mania\u02ee \u2013 identify the brand by its character (e.g., Android, GitHub Octocat)\nRound 2 \u2013 Inventor\u02bcs Round\nShow a picture, invention, or a clue.\nExample: \u201cInvented the World Wide Web\u02ee \u2192 Tim Berners-Lee\n\u201cCreated the first pro",
      "title": "events"
    }
  },
  "parent_fb6d48463be74a29a893133af341d475": {
    "id": "parent_fb6d48463be74a29a893133af341d475",
    "metadata": {
      "content": "nvention, or a clue.\nExample: \u201cInvented the World Wide Web\u02ee \u2192 Tim Berners-Lee\n\u201cCreated the first programmable computer\u02ee \u2192 Charles Babbage\n\u201cKnown for Tesla Coil\u02ee \u2192 Nikola Tesla\nCan also include connect-the-dots style questions:\n\u201cPython \ue1d7 Google \ue1d7 TensorFlow \ue1d7 ?\u02ee \ue081Answer: Guido van Rossum / AI field)\nRound 3 \u2013 Rapid Fire (Final Round)\nTop teams face a buzzer round.\nFastest correct answer gets 10 points; wrong answer \ue09e5.\nEv ent Ide as\n1\ud83c\udfc6  Judging Criteria\nAccuracy of answers\nQuickness of response (tie-breaker)\nIn case of a tie \u2014 bonus round (identify logo by tagline or product clue)\n\ud83e\uddf0 Requirements\nLaptop/projector\nPowerPoint / Canva slides for logos\nBuzzer (or online buzzer app like BuzzIn.Live)\nScoreboard\n\ud83d\udd27  2. \u201cBuild It With Junk\u02ee Challenge\n\ud83c\udfaf  Objective\nEncourage participants to apply creativity, basic engineering principles, and teamwork by building \nsomething functional or cool using scrap or waste materials.\n\ud83d\udca1  Event Concept\nTeams are given a set of junk materials (like wires, plasti",
      "title": "events"
    }
  },
  "parent_78d55faf2d9449a0a95fd525943bd0d7": {
    "id": "parent_78d55faf2d9449a0a95fd525943bd0d7",
    "metadata": {
      "content": "rap or waste materials.\n\ud83d\udca1  Event Concept\nTeams are given a set of junk materials (like wires, plastic bottles, cardboard, straws, motors, etc.) \nand a theme.\nThey must create a working prototype or model within the time limit.\n\ud83d\udee0  Example Themes\n\u201cEco-friendly Innovation\u02ee \u2013 make a mini windmill or water filter using junk.\n\u201cSmart Engineering\u02ee \u2013 create a simple mechanical tool, pulley system, or robotic arm.\n\u201cCreative Structures\u02ee \u2013 bridges, towers, or vehicles using only scrap.\n\u201cSave the Planet\u02ee \u2013 something that demonstrates recycling or energy saving.\n\u23f0  Format\nTeams of 3\ue0895 members.\nDuration: 60\ue08990 minutes.\nAll materials must be either provided on the spot or brought as scrap from home.\nNo ready-made kits allowed.\n\ud83e\uddc3  Material Examples\nEv ent Ide as\n2Plastic bottles, old CDs, cardboard boxes\nRubber bands, straws, tape, old wires\nIce cream sticks, syringes, balloons, old motors, etc.\n\ud83e\udde9 Judging Criteria\nCr it er ia Descr iption \n\ud83d\udca1  Creativity & Innovation Unique idea and use of materials\n\u2699",
      "title": "events"
    }
  },
  "parent_f94098b646c14a5cbfca40b099cb28f7": {
    "id": "parent_f94098b646c14a5cbfca40b099cb28f7",
    "metadata": {
      "content": "g Criteria\nCr it er ia Descr iption \n\ud83d\udca1  Creativity & Innovation Unique idea and use of materials\n\u2699  Functionality How well it works or demonstrates a concept\n\ud83c\udf31  Theme Relevance How it connects with the given theme\n\ud83c\udfa8  Aesthetics Neatness, stability, and overall look\n\ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1  Teamwork & PresentationCoordination and explanation of idea\n\ud83e\uddf0 Requirements\nTables, workspace area\nBasic tools (scissors, tape, glue gun)\nOptional: fans, lights, or battery sources (if needed)\nJudges: Faculty or seniors from mechanical/electrical background\n\ud83c\udfc6  Prizes / Add-ons\nBest Creative Build\nBest Functional Prototype\nGreen Engineer Award (eco-friendly design)\nEv ent Ide as\n3",
      "title": "events"
    }
  },
  "parent_3d23805a54944c39a718b55e511560b2": {
    "id": "parent_3d23805a54944c39a718b55e511560b2",
    "metadata": {
      "content": "Dr. J P Ganjigatti, Professor, IEM \nPage 1 of 14 \n \nRESEARCH METHODOLOGY AND IPR (SHS04) \nUnit-II \nSURVEY OF LITERATURE \n \nAfter defining a research problem, the researcher has to do literature survey connected with the \nproblem. It is a collection of research publications, books and other documents related to the defined \nproblem. It is very essential to know whether the defined problem has already been solved, status of the \nproblem and other related details one can survey  \n1. The journal which publishes abstract of papers published in various journals. \n2. Review articles related to the topic chosen. \n3. Journals which publishes research articles  \n4. Advanced level books on chosen topic. \n5. Proceeding of conference. \n6. Internet \n7. Reprint collections available with the supervisor and near by experts working on the chosen topic. \n \nIMPORTANCE OF LITERATURE SURVEY  \nOnce the research problem is defined, the next logical step will be survey of background literature. This \nis essen",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_da5725830acb492ca52d89b27d7bac1b": {
    "id": "parent_da5725830acb492ca52d89b27d7bac1b",
    "metadata": {
      "content": "ch problem is defined, the next logical step will be survey of background literature. This \nis essential whether the proposed problem deals only with theoretical or with experimental aspects or \nboth. All available literature uncerning the problem at hand must necessarily be surveyed and examined. \nThe researcher must be well conversant with concerned theories in the field, reports and records and all \nother literature. \nThe literature survey is mainly to find out what material and other data are available for operational \npurposes. If somebody has done experimental study or simulation, he/she might have mentioned the \nproblem and difficulties failed by them in their study, which may be useful for the current study. \nKnowing what data are available aften serves to narrow down the problem itself. \nLiterature survey would also help a researcher to know if there are any gaps in the theories, or whether \nthe existing theories applicable to the problem und er study. All these will enable th",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_c41b40b4c5e1415ab37fa0440963851a": {
    "id": "parent_c41b40b4c5e1415ab37fa0440963851a",
    "metadata": {
      "content": ", or whether \nthe existing theories applicable to the problem und er study. All these will enable the researcher to \nfurther farm the existing. \n \nSOURCES OF INFORMATION \nThe sources of information can be classified as  \n1.PUBLIC SOURCES \nI.Central government departments [defence, energy, science and technology etc.,] \nII.State and local government [highways, pollution control board etc.,] Dr. J P Ganjigatti, Professor, IEM \nPage 2 of 14 \n \nIII.Libraries \nIV.Universities \nV.Internet \n2. PRIV ATE SOURECES  \nI.Nonprofit organizations and services [professional societies, trade unociations, membership \norganization] \nII.Profit \u2013 oriented organization [manufacturers, vendors, catalogues, test data etc, consultants]  \nIII.Induvial [direct conversation or correspondence, personal friends, faculty]  \nDepending upon the nature of the problem under taken for the research study, the researcher has to \nseek the needed information from different sources. However, the major sources of information",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_12b4bbb4b24442a89af918bc89cd9207": {
    "id": "parent_12b4bbb4b24442a89af918bc89cd9207",
    "metadata": {
      "content": "to \nseek the needed information from different sources. However, the major sources of information \nnowadays are library, there is a hierarchy of information sources as given below   \n\u2022 Technical dictionaries  \n\u2022 Encyclopaedias \n\u2022 Handbooks \n\u2022 Indexing and abstract services  \n\u2022 Technical and professional journals  \n\u2022 Translations \n\u2022 Technical reports \n\u2022 Books \n\u2022 Patents \nThe various sources from which information is gathered can also be grouped into  \n1. PRIMARY SOURCES \n2. SECONDARY SOURCES \nPrimary sources: \nThese sources provide original information. They contain raw information e.g., data gather out of an \nexperimental study  \n\u2022 Papers of original authors  \n\u2022 First published documentation of new information \n\u2022 Government documents, patents, photographs, audio recordings, video recordings, films, \nspeeches, published books etc., \nSecondary sources: \nThese are the generalizations, analysis, interpretation and of primary sources.  \ne.g., Documentary about the historical events journal",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_c50f3599bd824d85b2de528f9934e86a": {
    "id": "parent_c50f3599bd824d85b2de528f9934e86a",
    "metadata": {
      "content": "ysis, interpretation and of primary sources.  \ne.g., Documentary about the historical events journal\u2019s articles, dictionaries, books that interpret \nanalyse, political commentary, biographies. \nASSESMENT OF QUALITY OF JOURNALS AND ARTICLES Dr. J P Ganjigatti, Professor, IEM \nPage 3 of 14 \n \nThe quality of a journals can be assessed by using \u201cIMAPCT FACTOR\u201d. The impact  factor of a \njournal is calculated by dividing the references cited in one year by the number of citable articles \npublished in the same journal over the previous 2 years. This ratio is published annually in Thomson \nscientific journal citation reports (JCR). There are many databases or perish. \nThe scientific journals citation report (CJR)impact factors are all based on data from journals indexed \nin web of science, but SCOPUS uses a measure called \u2018h -index\u201d, the \u201ch -index\u201d is an index that \nattempts to measure both the scientific productivity and the  apparent impact of scientists. This is \nbased on the set of the sci",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_ee15d797a0944a4d9a4584104dad9e98": {
    "id": "parent_ee15d797a0944a4d9a4584104dad9e98",
    "metadata": {
      "content": "scientific productivity and the  apparent impact of scientists. This is \nbased on the set of the scientists most cited papers and the number of citations that they have received \nin other people\u2019s publication. \n[the calculation of h -index can be explained as follows. A scientist has index \u2018h\u2019 if \u2018h\u2019 of his papers \nhas at least h citations each and other [N-h] papers have almost h citation each.] \nScience citation index (SCI) is a citation index originally produced by the institute for scientific \ninformation (ISI) in 1960 and now owned by Thomson reuters.  It covers more than 6500 journals \nacross more than 150 disciplines.  \nQuality of its journal is judged by the impact factor of the journal, the quality of an article by the \nnumber of citations, h-index etc.,   \nINFORMATION THROUGH INTERNET [WEB AS A SOURCES] \nFrom the past one decade or so the internet. Internet became an important source of knowledge and an \neffective medium for research. For researchers, it is providing a range",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_81a393d627e64446859befffb6348110": {
    "id": "parent_81a393d627e64446859befffb6348110",
    "metadata": {
      "content": "source of knowledge and an \neffective medium for research. For researchers, it is providing a range of new opportunities for \ncollecting information, networking, conducting research, collecting data and disseminating research \nresults.  \nElectronic mail, e journal, online submission of articles to journals, online focus groups, online video \nconference and online questionary or some of the latest tools opened up by the internet.  \nThe most recent and rapidly growing components of the internet is the world wide web [www]. \nThe popularity of www comes from the fact that it makes distribution and accessing digital \ninformation simple and inexpensive. \nTo search the world wide web, we need a search engine usually refers to a web search engine. There \nare other kind of search engines such as enterprise such engines which searches on intranets, personal \nsearch engines, mobile search engines etc., all search engines will not produce the same result for the \nspecific enquiry. \nThe researcher",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_f148203323314fc5bc547050bc2b40e1": {
    "id": "parent_f148203323314fc5bc547050bc2b40e1",
    "metadata": {
      "content": "tc., all search engines will not produce the same result for the \nspecific enquiry. \nThe researcher should have knowledge of many URLS devoted to engineering topics such as: \n\u2022 NASA technical information service -http://tech reports.Nasa.gov/egi-bin/NTRs  \n\u2022 National technical information service \u2013 http://ntis.gov \n \nSome of the scientific research information available on internet is  Dr. J P Ganjigatti, Professor, IEM \nPage 4 of 14 \n \n\u2756 Titles and other relevant information of articles published in various journals  \n\u2756 Preprit of papers submitted by the researchers in certain websites  \n\u2756 Information about scientific meetings  \n\u2756 Contact details of other researches  \n\u2756 Database of refence materials etc., \n \nEFFECTIVE LITERATURE STUDIES APPROACHES \nEffective literature studies approach in research methods involve a specialized focus on legal, ethical \nand research methodologies. \nSome of the approaches of literature are \n1.UNDERSTANDING THE LEGAL FRAME WORK: \nBegin by studying fundame",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_bf52a5c091c74629a0d2dd3a53f591b9": {
    "id": "parent_bf52a5c091c74629a0d2dd3a53f591b9",
    "metadata": {
      "content": "f the approaches of literature are \n1.UNDERSTANDING THE LEGAL FRAME WORK: \nBegin by studying fundamental legal frame works related to intellectual property rights. This includes \npatents, copyrights, trademarks, and trade secrets understand now the se rights are granted, enforced, \nand protected. \n2.DEFINE THE SCOPE: \nClearly define the scope of your literature study. Determine specific aspects of RM and IPR you want \nto explore, such as research funding, project management, patents laws, copyright issues, etc. \n3.IDENTIFY KEY CONCEPTS AND KEYWORDS: \nDevelop a list of key concepts and keywords related to your researc h. Include terms specific to RM  \n(e.g. patents, copyrights, trademarks). \n4.SEARCH STRATEGY: \nDesign a comprehensive search strategy using Boolean Operators (AND, OR to combine and refine \nyour key words) \n5.USE RELEV ANT DATA BASE: \nUtilize academic database, institutional repositories, and specialized platforms for RM and IPR \nResearch. Examples includes PubM ed, IEE Ex",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_2f7d2692bb99424b89688791fc9ed472": {
    "id": "parent_2f7d2692bb99424b89688791fc9ed472",
    "metadata": {
      "content": "repositories, and specialized platforms for RM and IPR \nResearch. Examples includes PubM ed, IEE Explore, science direct, Google scholar, and legal \ndatabases like west law and Lexis Nexis. \n6.REVIEW KEY JOURNALS AND CONFERENCES: \nIdentify reputable journals and conferences in the fields of RM and IPR. Focus on publications that \nare known for high quality research in these areas. \n7.INCORPORATE GREY LITERATURE: \nInclude grey literature such as reports, thesis, conference proceedings, and working papers. \nThis can provide valuable insights and perspectives not found in traditional academic journals. \n \n Dr. J P Ganjigatti, Professor, IEM \nPage 5 of 14 \n \n8.SYSTEMATIC REVIEW METHODOLOGY: \nConsider using systematic review methodologies, especially if your goal is to synthesize existing \nknowledge comprehensively. This involves a structured and transparent approach to literature \nselection and analysis. \n9.CITATION ANALYSIS: \nAnalyse citations in relevant papers to identify seminal works",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_33a6294e5181466bbab66b7bdce9a8c1": {
    "id": "parent_33a6294e5181466bbab66b7bdce9a8c1",
    "metadata": {
      "content": "and analysis. \n9.CITATION ANALYSIS: \nAnalyse citations in relevant papers to identify seminal works and influential authors. This can help \nyou understand the evolution of ideas and key contribution to the field. \n10.STAY UPDATED: \nSetup alerts and notifications for newly published articles and updates in RM and IPR. Subscribe to \nrelevant journals and newsletters.   \n \n PLAGIARISM: \n \u201cThe process or practice of using another person\u2019s ideas or work and pretending that is your own\u201d. \n\u201cPresenting work or idea from another source as your own with or without consent of the original \nother by incorporating it into your work without full acknowledgement\u201d. \n Plagiarism means using someone else work without giving them proper credit . in academic writing, \nplagiarizing involve using words, ideas or information from a source without citing it correctly. \n Examples: \n\u2022 Copying parts of a textword for word, without quotation marks. \n\u2022 Turning in someone else work as your own. \n\u2022 Copying large pi",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_6dccd125d7c84203891817df6b06d7bf": {
    "id": "parent_6dccd125d7c84203891817df6b06d7bf",
    "metadata": {
      "content": "for word, without quotation marks. \n\u2022 Turning in someone else work as your own. \n\u2022 Copying large pieces of a text from a source without citing that source etc. \n \n Types of plagiarism: \n       Plagiarism comes in various forms, each differing in intent, severity and technique. Some of the \ncommon types are. \n1. Direct plagiarism : Copying someone else work word for word without giving credit or using \nquotation marks. \n2. Self plagiarism : reusing your own previously published work without proper citation or \npermission. This is often happens when a person submits the some paper or project for different \nclasses or publications. \n3. Mosaic plagiarism:(also known as patchwriting): Borrowing phrases or pieces text from \ndifferent sources without proper  attribution blending them with one\u2019s own writing. The structure the \noriginal text might to be changed slightly ,but the language is still essentially same.  \n4. Paraphasing plagiarism: Re-writing someone else\u2019s ideas or text in your own",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_186dea2e8b1a4e80a65f39659c6c8ae8": {
    "id": "parent_186dea2e8b1a4e80a65f39659c6c8ae8",
    "metadata": {
      "content": "l essentially same.  \n4. Paraphasing plagiarism: Re-writing someone else\u2019s ideas or text in your own words without \nciting the original source  Dr. J P Ganjigatti, Professor, IEM \nPage 6 of 14 \n \n5. Accidental plagiarism: Unintentionally failing to cite sources properly due to carelessness.  \n6. Source-based plagiarism: Misrepresenting or fabricating a source . This includes citing incorrect \nor non-existent source or proving details about a source. \n7. Global plagiarism: Submitting an entire work(like an essay or research paper) that is copied from \nanother source such a website or purchasing the another source such a website or purchasing it from a \n3rd party and presenting an one\u2019s own. \n8. Retweet plagiarism: Using an author\u2019s entire  argument or idea in the same sequence or structure \nbut rephrased without citing the original source. \nConsequences of plagiarism  \nPlagiarism  can have serious consequences depending on the context, whether in academia, the work \nplace, or creative f",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_8e6c21db9e204ee796516c3296b2ff61": {
    "id": "parent_8e6c21db9e204ee796516c3296b2ff61",
    "metadata": {
      "content": "e serious consequences depending on the context, whether in academia, the work \nplace, or creative fields. Here are some common consequences. \n1. Academic consequence: \n\u2022 Falling grade  \n\u2022 Disciplinary action  \n\u2022 Revocation of degrees \n\u2022 Damage to academic reputation \n2. Professional consequences: \n\u2022 Job termination  \n\u2022 Damage to career and reputation  \n\u2022 Legal consequences \n3. Legal consequences: \n\u2022 Copyright infrightment  \n\u2022 Financial damages \n4. Reputational damages: \n\u2022 Loss of trust \n\u2022 Public shame \n5. Loss of professional licenses: \n\u2022 In certain fields like journalism or law, plagiarism can lead to relocation of licenses or \ncertifications. \n6. Hindrance to learning and development: \n\u2022 Plagiarism deprives individuals of the learning process, resulting in a lack of skills and knowledge \nthat can hinder future academic or professional growth.  \nResearch ethics: Dr. J P Ganjigatti, Professor, IEM \nPage 7 of 14 \n \nIt refers to the guidelines and principle s that govern the conduct of",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_89814a4d0e114891b9a062c205f03d8f": {
    "id": "parent_89814a4d0e114891b9a062c205f03d8f",
    "metadata": {
      "content": "fessor, IEM \nPage 7 of 14 \n \nIt refers to the guidelines and principle s that govern the conduct of research to ensure that it is \nconducted with integrity, respect and responsibility. \n \nKey principles of research ethics: \n1. Respect the persons:-  \n\u2022 Informed consent: - Researches must enure that participants voluntarily agree to participate in the \nstudy with a full understanding of its purpose procedure, risks and benefits. \n\u2022 Autonomy:- participants should have the right to make their own decisions about participating in \nresearch. \n2. Beneficence:-  \n\u2022 Maximizing benefits, minimizing harm: -Researches should ensure that it potential benefits of its \nresearch outweigh the risk or harm to participants. \n3. Justice:- \n\u2022 Fair treatment: - The benefits and burdens of research should be distributed fairly among all \ngroups. \n\u2022 Equitable selection of participants: - Researcher\u2019s must ensure that participant recruitment is done \nfairly and withot bias. \n4. Confidentiality:- The researche",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_db155ef5111b420f8f5840dcd918887d": {
    "id": "parent_db155ef5111b420f8f5840dcd918887d",
    "metadata": {
      "content": "re that participant recruitment is done \nfairly and withot bias. \n4. Confidentiality:- The researcher must ensure that the participants data is handled confidentially. \n5. Integrity and transparency: -Researcher\u2019s must avoid fabrication, plagiarism, or any form of \nmisconduct. \n           All aspects of the research process from methodology to reporting should be clear and \ntransparent to ensure trust worthiness. \n6. Social responsibility:- Researcher\u2019s should ensure that their work contribute positively to society. \n7. Accountability:- Researcher\u2019s are accountable to their institutions, funding agencies, and the \npublic. \nData \u2013 preparing, exploring, examining and displaying: \n \nData preparation :- \n      Data preparation includes editing ,  coding and data entry and is the activity that ensures the \naccuracy of the data and their conversion from raw form to reduced and classified forms that are more \nappropriate for analysis. Dr. J P Ganjigatti, Professor, IEM \nPage 8 of 14",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_e8e045ba709e468b9d57c7a87cbf1437": {
    "id": "parent_e8e045ba709e468b9d57c7a87cbf1437",
    "metadata": {
      "content": "that are more \nappropriate for analysis. Dr. J P Ganjigatti, Professor, IEM \nPage 8 of 14 \n \n \n           The above figure reflects the steps in  preparing the data in the research process. \nEditing:- First step is to edit the raw data. Editing detects errors and omissions, corrects them when \npossible and certifies that maximum data quality standards are achieved. The editor\u2019s purpose is to \nguarantee that the data are \n\u2022 Accurate  \n\u2022 Uniformly entered \n\u2022 Complete \n\u2022 Arranged to simplicity coding and tabulation. \nCoding:- It involves assigning number or other symbols to answers  so  that the response can be \ngrouped into a limited number of categories. In coding, categories are the partition of a data set of a \ngiven variable. [e.g., If the variable is gender, the partitions are male and female]. \n Categorizations of data sacrifices some data detail but it is necessary for an efficient analysis. \nData entry:- It converts information gathered secondary or primary methods to a medium f",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_609f9d9d1d8c4e688f9941bfdf17dae1": {
    "id": "parent_609f9d9d1d8c4e688f9941bfdf17dae1",
    "metadata": {
      "content": "analysis. \nData entry:- It converts information gathered secondary or primary methods to a medium for viewing \nand manipulation. Keyboarding is mainly used to create data  file and store it in a minimal space on a \nvariety of media. Researcher have profited from more efficient ways of speeding up research process, \nlike barcoding and optical character and mark recognition. \nExploratory data analysis (EDA) \nDr. J P Ganjigatti, Professor, IEM \nPage 9 of 14 \n \n \nIt provides a perspective and set of tools of search for clues and patterns in the data in addition to \nnumerical summaries of location, spread and shape. EDA emphasizes on visual representation and \ngraphical techniques to provide a complete and accurate impression of distributions and variable \nrelationships.  \n Confirmatory data analysis is an analytical process guided by classical statical inference in its use of \nsignificance testing and confidence                      \nEDA is like police defective searching for clues as it",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_9d4ee0331d7d471c94dd14beebba94ed": {
    "id": "parent_9d4ee0331d7d471c94dd14beebba94ed",
    "metadata": {
      "content": "testing and confidence                      \nEDA is like police defective searching for clues as it gathers evidence needed for confirmatory data \nanalysis, uses classical statistics to test significance and confidence. \nConfirmatory data analysis to an analytical process guided by classical statistical inference in its use \nof significance testing and confidence. \nExploratory data analysis is the first step in search for evidence, without which confirmatory analysis \nhas nothing to evaluate.  \n \nTechniques for displaying data \n(i) A Frequency Table (Minimum Age for Social Networking) \nDr. J P Ganjigatti, Professor, IEM \nPage 10 of 14 \n \n \nFrequency tables They array data from lowest to highest values with counts and percentages. They are \nmost useful for inspecting the range of responses and their repeated occurrence. Ex: Figure shows a \nfrequency table of the perceived minimum age for owning a social networking account.  \n(ii) Bar charts and pie charts  \nThey are suitable for relativ",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_b321975f1ea1405ba17e799bc5e93fb3": {
    "id": "parent_b321975f1ea1405ba17e799bc5e93fb3",
    "metadata": {
      "content": "owning a social networking account.  \n(ii) Bar charts and pie charts  \nThey are suitable for relative comparisons of nominal data. Ex: The same data of minimum age for \nsocial networking are presented in figure   using a pie chart and a bar chart. The values and \npercentages are more readily understood in this graphic format. \n \nPie chart \n \n \nBar chart \n \n \n(iii) Histograms  \nThey are used with continuous variables when it is possible to group the variable\u2019s values into \nintervals. They are useful for (1) displaying all intervals in a distribution, even those without observed \nvalues, and (2) examining the shape of the distribution for skewness, kurtosis, and the modal pattern. \nHistograms can help answer the questions: Is there a single mode? Are subgroups identifiable when \nmultiple modes are present? Are straggling data values (Outliers) detached from the central \nconcentration?  \nDr. J P Ganjigatti, Professor, IEM \nPage 11 of 14 \n \nNote: A histogram cannot be used for a nominal va",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_c5631cf4a1514a8a868d4c20b2eb9351": {
    "id": "parent_c5631cf4a1514a8a868d4c20b2eb9351",
    "metadata": {
      "content": ". J P Ganjigatti, Professor, IEM \nPage 11 of 14 \n \nNote: A histogram cannot be used for a nominal variable like minimum age for social networking \n(Figure) that has no order to  its categories. \nEx: Figure(a)   gives average annual purchases and figure(b)   presents a histogram for same. The \nmidpoint for each interval for the variable of interest (average annual purchases) is shown on the \nhorizontal axis; the frequency or number of observations in each interval, on the vertical axis. The \nheight of the bar corresponds with the frequency of observations in the interval. \n \nFigure(a): Average Annual Purchases of \nPrimeSell\u2019s Top 50 Customers \n \n \n \n \nFigure (b): Histogram of PrimeSell\u2019s Top 50 \nCustomers\u2019 Average Annual Purchases \n \n(iv) Stem-and-leaf displays: \nThey are EDA techniques that provide visual representations of distributions. In contrast to \nhistograms, which lose information by grouping data values into intervals, the stem -and-leaf presents \nactual data values that can b",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_aef337b682674466a4e98b67959eed89": {
    "id": "parent_aef337b682674466a4e98b67959eed89",
    "metadata": {
      "content": "n by grouping data values into intervals, the stem -and-leaf presents \nactual data values that can be inspected directly. Adv1: EDA reveals the distribution of values within \nthe interval and preserves their rank order for finding the median, quartiles, and other summary \nstatistics. Adv2: It eases linking a specific observation back to the data file and to subject that \nproduced it. \nAdv3: Visualization: The range of values and both shape and spread are apparent at a glance. Patterns \nin the data\u2014such as gaps where no values exist, areas where values are clustered, or outlying values \nthat differ from the main body of the data \u2014are easily observed. Ex: To develop a stem -and-leaf \ndisplay for the data given in figure, the first digits of each data item are arranged to the left of a \nvertical line. Next, pass through the values in the order they were recorded and place the last digit, in \nunit position, for each item to the right of the vertical line (ignore the decimal values). The st",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_092ab7508f78479f8041183a518039c6": {
    "id": "parent_092ab7508f78479f8041183a518039c6",
    "metadata": {
      "content": "unit position, for each item to the right of the vertical line (ignore the decimal values). The stem -and-\nleaf display is shown in figure. \nDr. J P Ganjigatti, Professor, IEM \nPage 12 of 14 \n \n \nv. Pareto diagrams : \nPareto diagrams are named after a 19th  century Italian economist and are used in quality management. \nTo illustrate the 80/20 rule, where 80% of quality improvements can come from addressing 20% of \nthe causes. In these diagrams, responses are sorted by importance, with bars arranged from tallest to \nshortest. Ex: Figure shows MindWriter customer complaints, highlighting that the top two issues \naccounted for 80% of perceptions of inadequate repair service. \n \nFigure:  Pareto Diagram of MindWriter Repair Complaints \n \n \nvi. Boxplots: \n Boxplots convey a detailed picture of the distribution\u2019s location, spread, shape, tail length, and \noutliers. They use the five -number summary that consists of the median, the upper and lower \nquartiles, and the largest and smallest obs",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_116bf13874614a7aaaac8c23f061faa0": {
    "id": "parent_116bf13874614a7aaaac8c23f061faa0",
    "metadata": {
      "content": "ummary that consists of the median, the upper and lower \nquartiles, and the largest and smallest observations. \nThe basic ingredients of the plot are:  \n1. The rectangular plot that encompasses 50 % of the data values.  \n2. A center line marking the median.  \n3. The edges of the box, called hinges.  \nDr. J P Ganjigatti, Professor, IEM \nPage 13 of 14 \n \n4. The \u201cwhiskers\u201d that extend from the right and left hinges to the largest and smallest values. These \nvalues may be found within 1.5 times the interquartile range (IQR) from either edge of the box. These \ncomponents and their relationships are shown in Figure. \nOutliers, data points that exceed +1.5 the interquartile range, reflect unusual cases and are an \nimportant source of information for the study. Outliers that are entry mistakes should be corrected or \nremoved during editing. Ex: In figure, multiple boxplots compare five sectors of PrimeSell\u2019s \ncustomers by their average annual purchases data. \nThe overall impression is one of p",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_c1c07f94e28f4ed1a3cf07a7f11dc57f": {
    "id": "parent_c1c07f94e28f4ed1a3cf07a7f11dc57f",
    "metadata": {
      "content": "f PrimeSell\u2019s \ncustomers by their average annual purchases data. \nThe overall impression is one of potential problems for the analyst: unequal variances, skewness, and \nextreme outliers. Note the similarities of the profiles of finance and retailing in contrast to the high -\ntech and insurance sectors. \n \nFigure: Boxplot Components \n \n \nFigure: Diagnostics with Boxplots \n \n Figure: Boxplot Comparison of Customer Sectors  \nvii. Mapping: \n Geographic Information System (GIS) software and coordinate measuring devices work by linking \ndata sets to each other with at least one common data field (e.g., a household\u2019s street address). The \nGIS allows the researcher to connect target and classification variables from a survey to specific \ngeographic-based databases like U.S. Census data, to develop a richer understanding of the \nsample\u2019s attitudes and behavior. The most common way to display such data is with a map. Colors \nand patterns denoting knowledge, attitude, behavior, or demographic dat",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_d50a3707977347b8836db3496bea3009": {
    "id": "parent_d50a3707977347b8836db3496bea3009",
    "metadata": {
      "content": "data is with a map. Colors \nand patterns denoting knowledge, attitude, behavior, or demographic data arrays are superimposed \nDr. J P Ganjigatti, Professor, IEM \nPage 14 of 14 \n \nover street, county, state, or country maps. \n \nCross-tabulation:  \nCross-tabulation is used to examine relationships involving categorical variables. The tables used for this \npurpose consist of cells and marginals (row and column total). The cells may contain combinations of count, \nrow, column, and total percentages. It serves as a framework for later statistical testing. Computer software \nfor cross-classification analysis allows for efficient table-based data visualization and decision making by \nincorporating one or more control variables. An advanced variation on n-way tables is automatic interaction \ndetection (AID).",
      "title": "RM & IPR (SHS04) Unit-II JPG"
    }
  },
  "parent_6fd0749b962a4e3194797e094b3690fb": {
    "id": "parent_6fd0749b962a4e3194797e094b3690fb",
    "metadata": {
      "content": "\ufeffRobot Learning: A Tutorial\nFrancesco Capuano Caroline Pascal Adil Zouitine ThomasWolf Michel Aractingi\n\nUniversity of Oxford, Hugging Face\n\nAbstract\nRobot learning is at an inflection point, driven by rapid advancements in machine learning and the growing\navailability of large-scale robotics data. This shift from classical, model-based methods to data-driven,\nlearning-based paradigms is unlocking unprecedented capabilities in autonomous systems. This tutorial\nnavigates the landscape of modern robot learning, charting a course from the foundational principles of\nReinforcement Learning and Behavioral Cloning to generalist, language-conditioned models capable of\noperating across diverse tasks and even robot embodiments. This work is intended as a guide for researchers\nand practitioners, and our goal is to equip the reader with the conceptual understanding and practical tools\nnecessary to contribute to developments in robot learning, with ready-to-use examples implemented in lerobot.\n\nCod",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_13748f5073c44dc1b61152f899b438bf": {
    "id": "parent_13748f5073c44dc1b61152f899b438bf",
    "metadata": {
      "content": "ontribute to developments in robot learning, with ready-to-use examples implemented in lerobot.\n\nCode: https://github.com/huggingface/lerobot\nDate: October 15, 2025\n\nContents\n\n1 Introduction 3\n1.1 LeRobotDataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n\n1.1.1 The dataset class design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2 Code Example: Batching a (Streaming) Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.3 Code Example: Collecting Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n\n2 Classical Robotics 9\n2.1 Explicit and Implicit Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2 Different Types of Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.3 Example: Planar Manipulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_de2b8606f8fb41d3ad898c1e8eaf78b5": {
    "id": "parent_de2b8606f8fb41d3ad898c1e8eaf78b5",
    "metadata": {
      "content": ". . . 10\n2.3 Example: Planar Manipulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n\n2.3.1 Adding Feedback Loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.4 Limitations of Dynamics-based Robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n\n3 Robot (Reinforcement) Learning 16\n3.1 A (Concise) Introduction to RL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.2 Real-world RL for Robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n\n3.2.1 Code Example: Real-world RL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.2.2 Limitations of RL in Real-World Robotics: Simulators and Reward Design . . . . . . . . . . . 32\n\n4 Robot (Imitation) Learning 33\n4.1 A (Concise) Introduction to GenerativeModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\n4.1.1 Variational",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c0a1a4a38de044129691beb50bdda301": {
    "id": "parent_c0a1a4a38de044129691beb50bdda301",
    "metadata": {
      "content": "GenerativeModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n\n4.1.1 Variational Auto-Encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n4.1.2 DiffusionModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n4.1.3 FlowMatching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n\n4.2 Action Chunking with Transformers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.2.1 Code Example: Training and Using ACT in Practice . . . . . . . . . . . . . . . . . . . . . . . . 46\n\n4.3 Diffusion Policy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n4.3.1 Code Example: Training and Using Diffusion Policies in Practice . . . . . . . . . . . . . . . . 50\n\n1\n\narXiv:2510.12403v1  [cs.RO]  14 Oct 2025\n\n\n\n4.4 Optimized Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_17c43cef029b4b0ebbdeca5111795a5d": {
    "id": "parent_17c43cef029b4b0ebbdeca5111795a5d",
    "metadata": {
      "content": "4 Oct 2025\n\n\n\n4.4 Optimized Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.4.1 Code Example: Using Async Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n\n5 Generalist Robot Policies 57\n5.1 Preliminaries: Models and Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n5.2 VLAs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n\n5.2.1 VLMs for VLAs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n5.3 \u03c00 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n\n5.3.1 Code Example: Using \u03c00 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.4 SmolVLA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n\n5.4.1 Code Example: Usi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_79a35bad30ad42ce8869196aaeb668b6": {
    "id": "parent_79a35bad30ad42ce8869196aaeb668b6",
    "metadata": {
      "content": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n\n5.4.1 Code Example: Using SmolVLA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n\n6 Conclusions 67\n\nForeword\nRobotics is an inherently multidisciplinary field, which is witnessing unprecedented advancements since its inception\nin the 1960s. Yet, more than sixty years after the debut of Unimate, robots have still not fully integrated into the rich,\nunstructured, and dynamic world we humans inhabit. Over the decades, numerous disciplines have shown immense\npromise in tackling the challenges of creating autonomous robotic systems. This tutorial takes a clear stance in the\ndebate on whether modern Machine Learning can play a pivotal role in the development of autonomous robots: we\nbelieve this to be the case.\nNonetheless, we also hold that the wealth of research from both academia and industry in classical robotics over the\npast six decades is, simply put, too valuable to be cast aside",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3906da2a0ed248d6a30d02f544ea48a8": {
    "id": "parent_3906da2a0ed248d6a30d02f544ea48a8",
    "metadata": {
      "content": "ustry in classical robotics over the\npast six decades is, simply put, too valuable to be cast aside in favor of purely learning-based methods. However,\nthe interplay between classical robotics and modern machine learning is still in its nascent stages, and the path to\nintegration yet to be clearly defined. In turn our goal here is to present what we consider to be the most relevant\napproaches within robot learning today, while warmly extending an invite to collaborate to expand the breadth of\nthis work! Start contributing today here.\nThis tutorial. . .\n\n\u2022 Does not aim to be a comprehensive guide to general field of robotics, manipulation or underactuated systems: Si-\nciliano and Khatib (2016) and Tedrake (a,b) do this better than we ever could.\n\n\u2022 Does not aim to be an introduction to statistical or deep learning: Shalev-Shwartz and Ben-David (2014) and Prince\n(2023) cover these subjects better than we ever could.\n\n\u2022 Does not aim to be a deep dive into Reinforcement Learning, Diffusion",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7255f627496040a79fabf4d9e3e034be": {
    "id": "parent_7255f627496040a79fabf4d9e3e034be",
    "metadata": {
      "content": "better than we ever could.\n\n\u2022 Does not aim to be a deep dive into Reinforcement Learning, Diffusion Models, or Flow Matching: invaluable works\nsuch as Sutton and Barto (2018), Nakkiran et al. (2024), and Lipman et al. (2024) do this better than we ever\ncould.\n\nInstead, our goal here is to provide an intuitive explanation as per why these disparate ideas have converged to form\nthe exciting field of modern robot learning, driving the unprecedented progress we see today. In this spirit, we follow\nthe adage: \"a jack of all trades is a master of none, but oftentimes better than a master of one.\"\nWe sincerely hope this tutorial serves as a valuable starting point for your journey into robot learning.\n\n2\n\n\n\nFigure 1 | lerobot is the open-source library for end-to-end robotics developed by Hugging Face. The library is vertically\nintegrated on the entire robotics stack, supporting low-level control of real-world robot devices, advanced data and inference\noptimizations, as well as SOTA robot le",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f153bf72586e43faafe556f91f8fb94f": {
    "id": "parent_f153bf72586e43faafe556f91f8fb94f",
    "metadata": {
      "content": "rol of real-world robot devices, advanced data and inference\noptimizations, as well as SOTA robot learning methods with simple implementations in pure Pytorch.\n\n1 Introduction\nAutonomous robotics holds the premise of relieving humans from repetitive, tiring or dangerous manual tasks.\nConsequently, the field of robotics has been widely studied since its first inception in the 1950s. Lately, advancements\nin Machine Learning (ML) have sparked the development of a relatively new class of methods used to tackle robotics\nproblems, leveraging large amounts of data and computation rather than human expertise and modeling skills to\ndevelop autonomous systems.\nThe frontier of robotics research is indeed increasingly moving away from classical model-based control paradigm,\nembracing the advancements made in ML, aiming to unlock (1) monolithic perception-to-action control pipelines\nand (2) multi-modal data-driven feature extraction strategies, together with (3) reduced reliance on precise models\no",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_58d972c3f8484c88a1576ea0d09b69f6": {
    "id": "parent_58d972c3f8484c88a1576ea0d09b69f6",
    "metadata": {
      "content": "al data-driven feature extraction strategies, together with (3) reduced reliance on precise models\nof the world and (4) a better positioning to benefit from the growing availability of open robotics data. While\ncentral problems in manipulation, locomotion and whole-body control demand knowledge of rigid-body dynamics,\ncontact modeling, planning under uncertainty, recent results seem to indicate learning can prove just as effective as\nexplicit modeling, sparking interest in the field of robot learning. This interest can be largely justified considering the\nsignificant challenges related to deriving accurate models of robot-environment interactions.\nMoreover, since end-to-end learning on ever-growing collections of text and image data has historically been at the\ncore of the development of foundation models capable of semantic reasoning across multiple modalities (images, text,\naudio, etc.), deriving robotics methods grounded in learning appears particularly consequential, especially as",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_6c82b1ae66ed4448b4b134ead0951da9": {
    "id": "parent_6c82b1ae66ed4448b4b134ead0951da9",
    "metadata": {
      "content": "), deriving robotics methods grounded in learning appears particularly consequential, especially as the\nnumber of openly available datasets continues to grow.\nRobotics is, at its core, an inherently multidisciplinary field, requiring a wide range of expertise in both software and\nhardware. The integration of learning-based techniques further broadens this spectrum of skills, raising the bar for\nboth research and practical applications. lerobot is an open-source library designed to integrate end-to-end with\nthe entire robotics stack. With a strong focus on accessible, real-world robots (1) lerobot supports many, openly\navailable, robotic platforms for manipulation, locomotion and even whole-body control. lerobotalso implements a\n(2) unified, low-level approach to reading/writing robot configurations to extend support for other robot platforms\nwith relatively low effort. The library introduces LeRobotDataset, (3) a native robotics dataset\u2019s format currently\nbeing used by the community to",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_242618419df84ad191df26a4a5ffa374": {
    "id": "parent_242618419df84ad191df26a4a5ffa374",
    "metadata": {
      "content": "uces LeRobotDataset, (3) a native robotics dataset\u2019s format currently\nbeing used by the community to efficiently record and share datasets. lerobot also supports many state-of-the-art\n(SOTA) algorithms in robot learning\u2014mainly based on Reinforcement Learning (RL) and Behavioral Cloning (BC)\ntechniques\u2014with efficient implementations in Pytorch, and extended support to experimentation and experiments\ntracking. Lastly, lerobot defines a custom, optimized inference stack for robotic policies decoupling action planning\nfrom action execution, proving effective in guaranteeing more adaptability at runtime.\nThis tutorial serves the double purpose of providing useful references for the Science behind\u2014and practical use\nof\u2014common robot learning techniques. To this aim, we strike to provide a rigorous yet concise overview of the core\nconcepts behind the techniques presented, paired with practical examples of how to use such techniques concretely,\nwith code examples in lerobot, for researchers and",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_fd8c148f89e4487eb10ec8a221d6a585": {
    "id": "parent_fd8c148f89e4487eb10ec8a221d6a585",
    "metadata": {
      "content": "amples of how to use such techniques concretely,\nwith code examples in lerobot, for researchers and practitioners interested in the field of robot learning. This tutorial\nis structured as follows:\n\n\u2022 Section 2 reviews classical robotics foundations, introducing the limitations of dynamics-based approaches to\nrobotics.\n\n3\n\n\n\n\u2022 Section 3 elaborates on the limitations of dynamics-based methods, and introduce RL as a practical approach to\nsolve robotics problems, considering its upsides and potential limitations.\n\n\u2022 Section 4 further describes robot learning techniques that aim at solving single-tasks learning, leveraging BC\ntechniques to autonomously reproduce specific expert demonstrations.\n\n\u2022 Section 5 presents recent contributions on developing generalist models for robotics applications, by learning from\nlarge corpora of multi-task & multi-robot data (robotics foundation models).\n\nOur goal with this tutorial is to provide an intuitive explanation of the reasons various disparate ideas",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d943967604c944d1a7ad806b78939a58": {
    "id": "parent_d943967604c944d1a7ad806b78939a58",
    "metadata": {
      "content": "oal with this tutorial is to provide an intuitive explanation of the reasons various disparate ideas from Machine\nLearning (ML) have converged and are powering the current evolution of Robotics, driving the unprecedented progress\nwe see today. We complement our presentation of the most common and recent approaches in robot learning with\npractical code implementations using lerobot, and start here by presenting the dataset format introduced with\nlerobot.\n\n1.1 LeRobotDataset\nLeRobotDataset is one of the most impactful features of lerobot, developed in keeping with the observation that\nrobotics data is increasingly central in robot learning. Thus, lerobot defines a standardized dataset format designed to\naddress the specific needs of robot learning research, providing a unified and convenient access to robotics data across\nmodalities, including sensorimotor readings, multiple camera feeds and teleoperation status. LeRobotDataset also\naccommodates for storing general information regarding",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a3034aff841c4756bb2e49f2e7f8ffb8": {
    "id": "parent_a3034aff841c4756bb2e49f2e7f8ffb8",
    "metadata": {
      "content": "nd teleoperation status. LeRobotDataset also\naccommodates for storing general information regarding the data being collected, including textual descriptions of the\ntask being performed by the teleoperator, the kind of robot used, and relevant measurement specifics like the frames\nper second at which the recording of both image and robot state\u2019s streams are proceeding.\nIn this, LeRobotDataset provides a unified interface for handling multi-modal, time-series data, and it is designed to\nseamlessly integrate with the PyTorch and Hugging Face ecosystems. LeRobotDataset can be easily extended by\nusers and it is highly customizable by users, and it already supports openly available data coming from a variety of\nembodiments supported in lerobot, ranging from manipulator platforms like the SO-100 arm and ALOHA-2 setup,\nto real-world humanoid arm and hands, as well as entirely simulation-based datasets, and self-driving cars. This\ndataset format is built to be both efficient for training and fl",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_21cb74bcccaa4c78a08d2aa4443ad8a3": {
    "id": "parent_21cb74bcccaa4c78a08d2aa4443ad8a3",
    "metadata": {
      "content": "tasets, and self-driving cars. This\ndataset format is built to be both efficient for training and flexible enough to accommodate the diverse data types\nencountered in robotics, while promoting reproducibility and ease of use for users.\n\n1.1.1 The dataset class design\nA core design choice behind LeRobotDataset is separating the underlying data storage from the user-facing API.\nThis allows for efficient storage while presenting the data in an intuitive, ready-to-use format.\nDatasets are always organized into three main components:\n\n\u2022 Tabular Data: Low-dimensional, high-frequency data such as joint states, and actions are stored in efficient memory-\nmapped files, and typically offloaded to the more mature datasets library by Hugging Face, providing fast with\nlimited memory consumption.\n\n\u2022 Visual Data: To handle large volumes of camera data, frames are concatenated and encoded into MP4 files. Frames\nfrom the same episode are always grouped together into the same video, and multiple videos",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c44a1b05029749d4a1f52aac40c7dcff": {
    "id": "parent_c44a1b05029749d4a1f52aac40c7dcff",
    "metadata": {
      "content": ". Frames\nfrom the same episode are always grouped together into the same video, and multiple videos are grouped together\nby camera. To reduce stress on the file system, groups of videos for the same camera view are also broke into\nmultiple sub-directories, after a given threshold number.\n\n\u2022 Metadata A collection of JSON files which describes the dataset\u2019s structure in terms of its metadata, serving as the\nrelational counterpart to both the tabular and visual dimensions of data. Metadata include the different feature\nschema, frame rates, normalization statistics, and episode boundaries.\n\nFor scalability, and to support datasets with potentially millions of trajectories (resulting in hundreds of millions\nor billions of individual camera frames), we merge data from different episodes into the same high-level structure.\nConcretely, this means that any given tabular collection and video will not typically contain information about one\nepisode only, but rather a concatenation of the informat",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_05c59f5aee984afc9f4c8b4ff27aebb7": {
    "id": "parent_05c59f5aee984afc9f4c8b4ff27aebb7",
    "metadata": {
      "content": "not typically contain information about one\nepisode only, but rather a concatenation of the information available in multiple episodes. This keeps the pressure on\nthe file system limited, both locally and on remote storage providers like Hugging Face, though at the expense of\nleveraging more heavily relational-like, metadata parts of the dataset, which are used to reconstruct information such\nas at which position, in a given file, an episode starts or ends. An example struture for a given LeRobotDataset would\nappear as follows:\n\n\u2022 meta/info.json: This metadata is a central metadata file. It contains the complete dataset schema, defining all\n\n4\n\n\n\nfeatures (e.g., observation.state, action), their shapes, and data types. It also stores crucial information like\nthe dataset\u2019s frames-per-second (fps), lerobot\u2019s version at the time of capture, and the path templates used to\nlocate data and video files.\n\n\u2022 meta/stats.json: This file stores aggregated statistics (mean, std, min, max) for each",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_26d5a02197e24029b782e7965c504ba4": {
    "id": "parent_26d5a02197e24029b782e7965c504ba4",
    "metadata": {
      "content": "eo files.\n\n\u2022 meta/stats.json: This file stores aggregated statistics (mean, std, min, max) for each feature across the entire\ndataset, used for data normalization for most policy models and accessible externally via dataset.meta.stats.\n\n\u2022 meta/tasks.jsonl: This file contains the mapping from natural language task descriptions to integer task indices,\nwhich are useful for task-conditioned policy training.\n\n\u2022 meta/episodes/* This directory contains metadata about each individual episode, such as its length, the corre-\nsponding task, and pointers to where its data is stored in the dataset\u2019s files. For scalability, this information is\nstored in files rather than a single large JSON file.\n\n\u2022 data/*: Contains the core frame-by-frame tabular data, using parquet files to allow for fast, memory-mapped\naccess. To improve performance and handle large datasets, data from multiple episodes are concatenated into larger\nfiles. These files are organized into chunked subdirectories to keep the size of",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_842fbd409bf84427bdc466bc82c253b7": {
    "id": "parent_842fbd409bf84427bdc466bc82c253b7",
    "metadata": {
      "content": "enated into larger\nfiles. These files are organized into chunked subdirectories to keep the size of directories manageable. A single file\ntypically contains data for more than one single episode.\n\n\u2022 videos/*: Contains the MP4 video files for all visual observation streams. Similar to the data/ directory, the\nvideo footage from multiple episodes is concatenated into single MP4 files. This strategy significantly reduces the\nnumber of files in the dataset, which is more efficient for modern filesystems.\n\n1.2 Code Example: Batching a (Streaming) Dataset\nThis section provides an overview of how to access datasets hosted on Hugging Face using the LeRobotDataset class.\nEvery dataset on the Hugging Face Hub containing the three main pillars presented above (Tabular, Visual and\nrelational Metadata), and can be assessed with a single instruction.\nIn practice, most reinforcement learning (RL) and behavioral cloning (BC) algorithms tend to operate on stack of\nobservation and actions. For the sake",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_8c90d0988fb24906bb3d07c808943f44": {
    "id": "parent_8c90d0988fb24906bb3d07c808943f44",
    "metadata": {
      "content": "ehavioral cloning (BC) algorithms tend to operate on stack of\nobservation and actions. For the sake of brevity, we will refer to joint spaces, and camera frames with the single term\nof frame. For instance, RL algorithms may use a history of previous frames ot\u2212Ho:t to mitigate partial observability,\nand BC algorithms are in practice trained to regress chunks of multiple actions (at+t+H ) rather than single controls.\n\na\n\nTo accommodate for these specifics of robot learning training, LeRobotDataset provides a native windowing operation,\nwhereby users can define the seconds of a given window (before and after) around any given frame, by using the\ndelta_timestemps functionality. Unavailable frames are opportunely padded, and a padding mask is also returned\nto filter out the padded frames. Notably, this all happens within the LeRobotDataset, and is entirely transparent to\nhigher level wrappers commonly used in training ML models such as torch.utils.data.DataLoader.\nConveniently, by using LeR",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_accbc5c7d0c74e86944ffacd50077cdc": {
    "id": "parent_accbc5c7d0c74e86944ffacd50077cdc",
    "metadata": {
      "content": "commonly used in training ML models such as torch.utils.data.DataLoader.\nConveniently, by using LeRobotDataset with a Pytorch DataLoader one can automatically collate the individual\nsample dictionaries from the dataset into a single dictionary of batched tensors for downstream training or inference.\nLeRobotDataset also natively supports streaming mode for datasets. Users can stream data of a large dataset\nhosted on the Hugging Face Hub, with a one-line change in their implementation. Streaming datasets supports\nhigh-performance batch processing (ca. 80-100 it/s, varying on connectivity) and high levels of frames randomization,\nkey features for practical BC algorithms which otherwise may be slow or operating on highly non-i.i.d. data. This\nfeature is designed to improve on accessibility so that large datasets can be processed by users without requiring large\namounts of memory and storage.\n\nCode 1: Batching a (Streaming) Dataset\nhttps://github.com/fracapuano/robot-learning-tutorial/blob",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_75f3bd402a8340eea7dc4ac80ca349d4": {
    "id": "parent_75f3bd402a8340eea7dc4ac80ca349d4",
    "metadata": {
      "content": ".\n\nCode 1: Batching a (Streaming) Dataset\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch1/01_datasets.py\n\n1 import torch\n2 from lerobot.datasets.lerobot_dataset import LeRobotDataset\n3 from lerobot.datasets.streaming_dataset import StreamingLeRobotDataset\n4\n5 delta_timestamps = {\n6 # 0.2, and 0.1 seconds *before* each frame\n7 \"observation.images.wrist_camera\": [-0.2, -0.1, 0.0]\n8 }\n9\n\n10 # Optionally , use StreamingLeRobotDataset to avoid downloading the dataset\n11 dataset = LeRobotDataset(\n\n5\n\n\n\n12 \"lerobot/svla_so101_pickplace\",\n13 delta_timestamps=delta_timestamps\n14 )\n15\n16 # Streams frames from the Hugging Face Hub without loading into memory\n17 streaming_dataset = StreamingLeRobotDataset(\n18 \"lerobot/svla_so101_pickplace\",\n19 delta_timestamps=delta_timestamps\n20 )\n21\n22 # Get the 100th frame in the dataset by\n23 sample = dataset [100]\n24 print(sample)\n25 # {\n26 # 'observation.state ': tensor ([...]) ,\n27 # 'action ': tensor ([...]) ,\n28 # 'observation",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2aa89e408d0849d6941b05a4de14582e": {
    "id": "parent_2aa89e408d0849d6941b05a4de14582e",
    "metadata": {
      "content": "5 # {\n26 # 'observation.state ': tensor ([...]) ,\n27 # 'action ': tensor ([...]) ,\n28 # 'observation.images.wrist_camera ': tensor ([3, C, H, W]), for delta timesteps\n29 # ...\n30 # }\n31\n32 batch_size =16\n33 # wrap the dataset in a DataLoader to use process it batches for training purposes\n34 data_loader = torch.utils.data.DataLoader(\n35 dataset ,\n36 batch_size=batch_size\n37 )\n38\n39 # Iterate over the DataLoader in a training loop\n40 num_epochs = 1\n41 device = \"cuda\" if torch.cuda.is_available () else \"cpu\"\n42\n43 for epoch in range(num_epochs ):\n44 for batch in data_loader:\n45 # Move data to the appropriate device (e.g., GPU)\n46 observations = batch[\"observation.state\"].to(device)\n47 actions = batch[\"action\"].to(device)\n48 images = batch[\"observation.images.wrist_camera\"].to(device)\n49\n50 # Next , you can do amazing_model.forward(batch)\n51 ...\n\n1.3 Code Example: Collecting Data\n\nCode 2: Record a Dataset\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch1/02_reco",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4282311daa4d4d0cbc980176acda2117": {
    "id": "parent_4282311daa4d4d0cbc980176acda2117",
    "metadata": {
      "content": "ecord a Dataset\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch1/02_record_data.py\n\n1 \"\"\"\n2 You can also use the CLI to record data. To see the required arguments , run:\n3 lerobot -record --help\n4 \"\"\"\n5 from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig\n6 from lerobot.datasets.lerobot_dataset import LeRobotDataset\n7 from lerobot.datasets.utils import hw_to_dataset_features\n8 from lerobot.robots.so100_follower import SO100Follower , SO100FollowerConfig\n9 from lerobot.teleoperators.so100_leader.config_so100_leader import SO100LeaderConfig\n\n10 from lerobot.teleoperators.so100_leader.so100_leader import SO100Leader\n11 from lerobot.utils.control_utils import init_keyboard_listener\n12 from lerobot.utils.utils import log_say\n13 from lerobot.utils.visualization_utils import init_rerun\n14 from lerobot.scripts.lerobot_record import record_loop\n15\n16 NUM_EPISODES = 5\n17 FPS = 30\n18 EPISODE_TIME_SEC = 60\n19 RESET_TIME_SEC = 10\n\n6\n\n\n\n20 TASK_DESCR",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1a551270fdff4dce865ad20d89b4ee70": {
    "id": "parent_1a551270fdff4dce865ad20d89b4ee70",
    "metadata": {
      "content": "16 NUM_EPISODES = 5\n17 FPS = 30\n18 EPISODE_TIME_SEC = 60\n19 RESET_TIME_SEC = 10\n\n6\n\n\n\n20 TASK_DESCRIPTION = ... # provide a task description\n21\n22 HF_USER = ... # provide your Hugging Face username\n23\n24 follower_port = ... # find your ports running: lerobot -find -port\n25 leader_port = ...\n26 follower_id = ... # to load the calibration file\n27 leader_id = ...\n28\n29 # Create the robot and teleoperator configurations\n30 camera_config = {\"front\": OpenCVCameraConfig(\n31 index_or_path =0, width =640, height =480, fps=FPS)\n32 }\n33 robot_config = SO100FollowerConfig(\n34 port=follower_port ,\n35 id=follower_id ,\n36 cameras=camera_config\n37 )\n38 teleop_config = SO100LeaderConfig(\n39 port=leader_port ,\n40 id=leader_id\n41 )\n42\n43 # Initialize the robot and teleoperator\n44 robot = SO100Follower(robot_config)\n45 teleop = SO100Leader(teleop_config)\n46\n47 # Configure the dataset features\n48 action_features = hw_to_dataset_features(robot.action_features , \"action\")\n49 obs_features = hw_to_dataset_fea",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_dfd0cdc7dd7d414b8e603d6969edf3e9": {
    "id": "parent_dfd0cdc7dd7d414b8e603d6969edf3e9",
    "metadata": {
      "content": "tures = hw_to_dataset_features(robot.action_features , \"action\")\n49 obs_features = hw_to_dataset_features(robot.observation_features , \"observation\")\n50 dataset_features = {** action_features , ** obs_features}\n51\n52 # Create the dataset where to store the data\n53 dataset = LeRobotDataset.create(\n54 repo_id=f\"{HF_USER }/robot -learning -tutorial -data\",\n55 fps=FPS ,\n56 features=dataset_features ,\n57 robot_type=robot.name ,\n58 use_videos=True ,\n59 image_writer_threads =4,\n60 )\n61\n62 # Initialize the keyboard listener and rerun visualization\n63 _, events = init_keyboard_listener ()\n64 init_rerun(session_name=\"recording\")\n65\n66 # Connect the robot and teleoperator\n67 robot.connect ()\n68 teleop.connect ()\n69\n70 episode_idx = 0\n71 while episode_idx < NUM_EPISODES and not events[\"stop_recording\"]:\n72 log_say(f\"Recording episode {episode_idx + 1} of {NUM_EPISODES}\")\n73\n74 record_loop(\n75 robot=robot ,\n76 events=events ,\n77 fps=FPS ,\n78 teleop=teleop ,\n79 dataset=dataset ,\n80 control_time_s=EP",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_0d327f57145e4207a4513b39f651b647": {
    "id": "parent_0d327f57145e4207a4513b39f651b647",
    "metadata": {
      "content": "robot ,\n76 events=events ,\n77 fps=FPS ,\n78 teleop=teleop ,\n79 dataset=dataset ,\n80 control_time_s=EPISODE_TIME_SEC ,\n81 single_task=TASK_DESCRIPTION ,\n82 display_data=True ,\n83 )\n84\n85 # Reset the environment if not stopping or re-recording\n86 if (not events[\"stop_recording\"]) and \\\n87 (episode_idx < NUM_EPISODES - 1 or events[\"rerecord_episode\"]):\n88 log_say(\"Reset the environment\")\n89 record_loop(\n\n7\n\n\n\n90 robot=robot ,\n91 events=events ,\n92 fps=FPS ,\n93 teleop=teleop ,\n94 control_time_s=RESET_TIME_SEC ,\n95 single_task=TASK_DESCRIPTION ,\n96 display_data=True ,\n97 )\n98\n99 if events[\"rerecord_episode\"]:\n\n100 log_say(\"Re -recording episode\")\n101 events[\"rerecord_episode\"] = False\n102 events[\"exit_early\"] = False\n103 dataset.clear_episode_buffer ()\n104 continue\n105\n106 dataset.save_episode ()\n107 episode_idx += 1\n108\n109 # Clean up\n110 log_say(\"Stop recording\")\n111 robot.disconnect ()\n112 teleop.disconnect ()\n113 dataset.push_to_hub ()\n\n8\n\n\n\nFigure 2 | Overview of methods to generate mot",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3fbaa30ccb354c40a27e7688f9108d7c": {
    "id": "parent_3fbaa30ccb354c40a27e7688f9108d7c",
    "metadata": {
      "content": "teleop.disconnect ()\n113 dataset.push_to_hub ()\n\n8\n\n\n\nFigure 2 | Overview of methods to generate motion (clearly non-exhausitve, see Bekris et al. (2024)). The different methods\ncan be grouped based on whether they explicitly (dynamics-based) or implicitly (learning-based) model robot-environment\ninteractions.\n\n2 Classical Robotics\nKnow your enemy [...]\n\nSun Tzu\n\nTL;DR\n\nLearning-based approaches to robotics are motivated by the need to (1) generalize across tasks and embodiments\n(2) reduce dependency on human expertise (3) leverage historical trends on the production of data\u2014all\ntraditionally overlooked by dynamics-based techniques.\n\n2.1 Explicit and Implicit Models\nRobotics is concerned with producing artificial motion in the physical world in useful, reliable and safe fashion. Thus,\nrobotics is an inherently multi-disciplinar domain: producing autonomous motion in the physical world requires, to the\nvery least, interfacing different software (motion planners) and hardware (motion exe",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_fc1014e8543549d1924ff6f543cef645": {
    "id": "parent_fc1014e8543549d1924ff6f543cef645",
    "metadata": {
      "content": "quires, to the\nvery least, interfacing different software (motion planners) and hardware (motion executioners) components. Further,\nknowledge of mechanical, electrical, and software engineering, as well as rigid-body mechanics and control theory\nhave therefore proven quintessential in robotics since the field first developed in the 1950s. More recently, Machine\nLearning (ML) has also proved effective in robotics, complementing these more traditional disciplines (Connell and\nMahadevan, 1993). As a direct consequence of its multi-disciplinar nature, robotics has developed as a rather wide\narray of methods, all concerned with the main purpose of producing artificial motion in the physical world.\nMethods to produce robotics motion range from traditional explicit models\u2014dynamics-based1 methods, leveraging\nprecise descriptions of the mechanics of robots\u2019 rigid bodies and their interactions with eventual obstacles in the\nenvironment\u2014to implicit models\u2014learning-based methods, treating artifici",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f33f76782e3b453898739c1e35c92a56": {
    "id": "parent_f33f76782e3b453898739c1e35c92a56",
    "metadata": {
      "content": "h eventual obstacles in the\nenvironment\u2014to implicit models\u2014learning-based methods, treating artificial motion as a statistical pattern to learn\ngiven multiple sensorimotor readings (Agrawal; Bekris et al., 2024). A variety of methods have been developed\nbetween these two extrema. For instance, Hansen et al. (2022) show how learning-based systems can benefit from\ninformation on the physics of problems, complementing a traditional learning method such as Temporal Difference\n(TD)-learning Sutton and Barto (2018) with Model-Predictive Control (MPC). Conversely, as explicit models may\nbe relying on assumptions proving overly simplistic\u2014or even unrealistic\u2014in practice, learning can prove effective\nto improve modeling of complex phenomena or complement perception (McCormac et al., 2016). Such examples\n\n1In here, we refer to both kinematics and dynamics-based control.\n\n9\n\n\n\nFigure 3 | Different kinds of motions are achieved with potentially very different robotic platforms. From left to right,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_146b43b5264a4bf88e0c0b9c21bfb9aa": {
    "id": "parent_146b43b5264a4bf88e0c0b9c21bfb9aa",
    "metadata": {
      "content": "kinds of motions are achieved with potentially very different robotic platforms. From left to right, top to\nbottom: ViperX, SO-100, Boston Dynamics\u2019 Spot, Open-Duck, 1X\u2019s NEO, Boston Dynamics\u2019 Atlas. This is an example list of\nrobotic platforms and is (very) far from being exhaustive.\n\naim at demonstrating the richness of approaches to robotics, and Figure 2 graphically illustrates some of the most\nrelevant techniques. Such a list is clearly far from being exhaustive, and we refer to Bekris et al. (2024) for a more\ncomprehensive overview of both general and application-specific methods for motion generation. In this section, we\nwish to introduce the inherent benefits of learning-based approaches to robotics\u2014the core focus on this tutorial.\n\n2.2 Different Types ofMotion\nIn the vast majority of instances, robotics deals with producing motion via actuating joints connecting nearly\nentirely-rigid links. A key distinction between focus areas in robotics is based on whether the generated mot",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_bf46c8d19cf84af793c5ebd1f0e5e5d3": {
    "id": "parent_bf46c8d19cf84af793c5ebd1f0e5e5d3",
    "metadata": {
      "content": "rigid links. A key distinction between focus areas in robotics is based on whether the generated motion\nmodifies (1) the absolute state of the environment (via dexterity), (2) the relative state of the robot with respect to\nits environment (exercising mobility skills), or (3) a combination of the two (Figure 3).\nEffects such as (1) are typically achieved through the robot, i.e. generating motion to perform an action inducing\na desirable modification, effectively manipulating the environment (manipulation). Motions like (2) may result in\nchanges in the robot\u2019s physical location within its environment. Generally, modifications to a robot\u2019s location within\nits environment may be considered instances of the general locomotion problem, further specified as wheeled or legged\nlocomotion based on whenever a robot makes use of wheels or leg(s) to move in the environment. Lastly, an increased\nlevel of dynamism in the robot-environment interactions can be obtained combining (1) and (2), thus desi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_fc7ad4a64cab4354a41eb9a3b51d130f": {
    "id": "parent_fc7ad4a64cab4354a41eb9a3b51d130f",
    "metadata": {
      "content": "l of dynamism in the robot-environment interactions can be obtained combining (1) and (2), thus designing\nsystems capable to interact with and move within their environment. This category is problems is typically termed\nmobile manipulation, and is characterized by a typically much larger set of control variables compared to either\nlocomotion or manipulation alone.\nThe traditional body of work developed since the very inception of robotics is increasingly complemented by learning-\nbased approaches. ML has indeed proven particularly transformative across the entire robotics stack, first empowering\nplanning-based techniques with improved state estimation used for traditional planning (Tang et al., 2023) and\nthen end-to-end replacing controllers, effectively yielding perception-to-action methods (Kober et al.). Work in\nproducing robots capable of navigating a diverse set of terrains demonstrated the premise of both dynamics and\nlearning-based approaches for locomotion (Griffin et al., 2017",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_6b07659f5bea410cb212390fb2413288": {
    "id": "parent_6b07659f5bea410cb212390fb2413288",
    "metadata": {
      "content": "ated the premise of both dynamics and\nlearning-based approaches for locomotion (Griffin et al., 2017; Ji et al., 2023; Lee et al., 2020; Margolis et al., 2022),\nand recent works on whole-body control indicated the premise of learning-based approaches to generate rich motion\non complex robots, including humanoids (Zhang et al., 2024; Bjorck et al., 2025). Manipulation has also been widely\nstudied, particularly considering its relevance for many impactful use-cases ranging from high-risk applications for\nhumans (Fujita et al., 2020; Alizadeh and Zhu, 2024) to manufacturing (Sanneman et al., 2020). While explicit models\nhave proven fundamental in achieving important milestones towards the development of modern robotics, recent\nworks leveraging implicit models proved particularly promising in surpassing scalability and applicability challenges\nvia learning (Kober et al.).\n\n2.3 Example: PlanarManipulation\nRobot manipulators typically consist of a series of links and joints, articulated in a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c50e6671645e4f9fb4a39abf28455598": {
    "id": "parent_c50e6671645e4f9fb4a39abf28455598",
    "metadata": {
      "content": "rManipulation\nRobot manipulators typically consist of a series of links and joints, articulated in a chain finally connected to an\nend-effector. Actuated joints are considered responsible for generating motion of the links, while the end effector is\ninstead used to perform specific actions at the target location (e.g., grasping/releasing objects via closing/opening a\ngripper end-effector, using a specialized tool like a screwdriver, etc.).\n\n10\n\n\n\nFigure 4 | Cheaper, more accessible robots are starting to rival traditional platforms like the Panda arm platforms in adoption\nin resource-constrained scenarios. The SO-100, in particular, has a cost in the 100s of Euros, and can be entirely 3D-printed in\nhours, while the industrially-manufactured Panda arm costs tens of thousands of Euros and is not openly available.\n\nFigure 5 | The SO-100 arm is a 6-dof manipulator arm. Preventing some of its joints (shoulder pane, wrist flex and wrist roll)\nfrom actuating, it can be represented as a tradit",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_034562f5719746aabd95823a09d1d267": {
    "id": "parent_034562f5719746aabd95823a09d1d267",
    "metadata": {
      "content": "joints (shoulder pane, wrist flex and wrist roll)\nfrom actuating, it can be represented as a traditional 2-dof planar manipulator (the gripper joint in the end-effector is not\nconsidered towards the count of the degrees of freedom used to produce motion).\n\nRecently, the development of low-cost manipulators like the ALOHA (Zhao et al., 2023) ALOHA-2 (Aldaco et al.)\nand SO-100/SO-101 (Knight et al.) platforms significantly lowered the barrier to entry to robotics, considering the\nincreased accessibility of these robots compared to more traditional platforms like the Franka Emika Panda arm\n(Figure 4).\nDeriving an intuition as per why learning-based approaches are gaining popularity in the robotics community requires\nbriefly analyzing traditional approaches for manipulation, leveraging tools like forward and inverse kinematics (FK,\nIK) and control theory. Providing a detailed overview of these methods falls (well) out of the scope of this tutorial,\nand we refer the reader to works includi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a36564b77b4740218b1615daaac7b03b": {
    "id": "parent_a36564b77b4740218b1615daaac7b03b",
    "metadata": {
      "content": "ese methods falls (well) out of the scope of this tutorial,\nand we refer the reader to works including Siciliano and Khatib (2016); Lynch and Park (2017); Tedrake (a,b) for a\nmuch more comprehensive description of these techniques. Here, we mostly wish to highlight the benefits of ML over\nthese traditional techniques\nConsider the (simple) case where a SO-100 is restrained from actuating (1) the shoulder pane and (2) the wrist flex\nand roll motors. This effectively reduces the degrees of freedom of the SO-100 from the original 5+1 (5 joints + 1\ngripper) to 2+1 (shoulder lift, elbow flex + gripper). As the end-effector does not impact motion in this model,\nthe SO-100 is effectively reduced to the planar manipulator robot presented in Figure 5, where spheres represent\nactuators, and solid lines indicate length-l links from the base of the SO-100 to the end-effector (ee).\nFurther, let us make the simplifying assumption that actuators can produce rotations up to 2\u03c0 radians. In practice,\nthi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_179ce1827873458388bb6c29c6555f00": {
    "id": "parent_179ce1827873458388bb6c29c6555f00",
    "metadata": {
      "content": "e the simplifying assumption that actuators can produce rotations up to 2\u03c0 radians. In practice,\nthis is seldom the case due to movement obstructions caused by the robot body itself (for instance, the shoulder lift\ncannot produce counter-clockwise movement due to the presence of the robot\u2019s base used to secure the SO-100 to its\nsupport and host the robot bus), but we will introduce movement obstruction at a later stage.\nAll these simplifying assumptions leave us with the planar manipulator of Figure 6a, free of moving its end-\neffector by controlling the angles \u03b81 and \u03b82, jointly referred to as the robot\u2019s configuration, and indicated with\nq = [\u03b81, \u03b82] \u2208 [\u2212\u03c0,+\u03c0]2. The axis attached to the joints indicate the associated reference frame, whereas circular\n\n11\n\n\n\n(a) | Free to move (b) | Constrained by the surface (c) | Constrained by surface and (fixed)\nobstacle\n\nFigure 6 | Planar, 2-dof schematic representation of the SO-100 manipulator under diverse deployment settings. From left\nto rig",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_06c5d044b0d5444a8f4824e3afedd094": {
    "id": "parent_06c5d044b0d5444a8f4824e3afedd094",
    "metadata": {
      "content": "hematic representation of the SO-100 manipulator under diverse deployment settings. From left\nto right: completely free of moving; constrained by the presence of the surface; constrained by the surface and presence of\nobstacles. Circular arrows around each joint indicate the maximal rotation feasible at that joint.\n\narrows indicate the maximal feasible rotation allowed at each joint. In this tutorial, we do not cover topics related to\nspatial algebra, and we instead refer the reader to Lynch and Park (2017, Chapter 2) and Tedrake (a, Chapter 3) for\nexcellent explanations of the mechanics and theoretical foundations of producing motion on rigid bodies.\nConsidering the (toy) example presented in Figure 6a, then we can analytically write the end-effector\u2019s position p \u2208 R2\n\nas a function of(the robot\u2019)s con(figuration, p = p(q), p : Q)7\u2192 R2. In particular, we have:\n\npx(\u03b81, \u03b82) l cos(\u03b8\n= 1) + l cos(\u03b81 + \u03b8\n\np(q) = 2) \u2208 Sn=2\nl ( ) R : p q\n1+l = {p q \u2208 2 \u2225 ( )\u222522 \u2264 (2l)2, \u2200q \u2208 Q}\n\n2\npy(\u03b81, \u03b82)",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3fb0a9852eb941128ea6a5e9aa27b24c": {
    "id": "parent_3fb0a9852eb941128ea6a5e9aa27b24c",
    "metadata": {
      "content": "l cos(\u03b81 + \u03b8\n\np(q) = 2) \u2208 Sn=2\nl ( ) R : p q\n1+l = {p q \u2208 2 \u2225 ( )\u222522 \u2264 (2l)2, \u2200q \u2208 Q}\n\n2\npy(\u03b81, \u03b82) l sin(\u03b81) + l sin(\u03b81 + \u03b82)\n\nDeriving the end-effector\u2019s pose\u2014position and orientation\u2014in some m-dimensional space p \u2208 P \u2282 Rm starting from\nthe configuration q \u2208 Q \u2282 Rn of a n-joints robot is referred to as forward kinematics (FK), whereas identifying the\nconfiguration corresponding to any given target pose is termed inverse kinematics (IK). In that, FK is used to map a\nrobot configuration into the corresponding end-effector pose, whereas IK is used to reconstruct the configuration(s)\ngiven an end-effector pose.\nIn the simplified case here considered (for which p \u2261 p, as the orientation of the end-effector is disregarded for\nsimplicity), one can solve the problem of controlling the end-effector\u2019s location to reach a goal position p\u2217 by solving\nanalytically for q : p(q) = fFK(q) = p\u2217. However, in the general case, one might not be able to solve this problem\nanalytically, and can typically",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_9d2a19f5f8d24117a5200bd34979bae0": {
    "id": "parent_9d2a19f5f8d24117a5200bd34979bae0",
    "metadata": {
      "content": "er, in the general case, one might not be able to solve this problem\nanalytically, and can typically resort to iterative optimization methods comparing candidate solutions using a loss\nfunction (in the simplest case, \u2225p(q)\u2212 p\u2217\u222522 is a natural candidate), yielding:\n\nmin \u2225p(q)\u2212 p\u2217\u222522 . (1)\nq\u2208Q\n\nExact analytical solutions to IK are even less appealing when one considers the presence of obstacles in the robot\u2019s\nworkspace, resulting in constraints on the possible values of q \u2208 Q \u2286 [\u2212\u03c0,+\u03c0]n \u2282 Rn in the general case of n-links\nrobots.\nFor instance, the robot in Figure 6b is (very naturally) obstacled by the presence of the surface upon which it rests: \u03b81\ncan now exclusively vary within [0, \u03c0], while possible variations in \u03b82 depend on \u03b81 (when \u03b81 \u2192 0 or \u03b81 \u2192 \u03c0, further\ndownwards movements are restricted). Even for a simplified kinematic model, developing techniques to solve eq. 1 is\nin general non-trivial in the presence of constraints, particularly considering that the feasible set of soluti",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3531c019f56442758639773de7e3795f": {
    "id": "parent_3531c019f56442758639773de7e3795f",
    "metadata": {
      "content": "non-trivial in the presence of constraints, particularly considering that the feasible set of solutions Q may\nchange across problems. Figure 6c provides an example of how the environment influences the feasible set considered,\nwith a new set of constraints deriving from the position of a new obstacle.\nHowever, IK\u2014solving eq. 1 for a feasible q\u2014only proves useful in determining information regarding the robot\u2019s\nconfiguration in the goal pose, and crucially does not provide information on the trajectory to follow over time to\nreach a target pose. Expert-defined trajectories obviate to this problem providing a length-K succession of goal\nposes \u03c4K = [p\u22170, p\n\n\u2217\n1, . . . p\n\n\u2217\nK ] for tracking. In practice, trajectories can also be obtained automatically through motion\n\nplanning algorithms, thus avoiding expensive trajectory definition from human experts. However, tracking \u03c4K via\nIK can prove prohibitively expensive, as tracking would require K resolutions of eq. 1 (one for each target pose).",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_52e4c780c3524af083db4631ded23e73": {
    "id": "parent_52e4c780c3524af083db4631ded23e73",
    "metadata": {
      "content": "rohibitively expensive, as tracking would require K resolutions of eq. 1 (one for each target pose).\nDifferential inverse kinematics (diff-IK) complements IK via closed-form solution of a variant of eq. 1. Let J(q) denote\n\n12\n\n\n\nthe Jacobian matrix of (partial) derivatives of the FK-function fFK : Q 7\u2192 P, such that J(q) = \u2202fFK(q)\n\u2202q . Then, one\n\ncan apply the chain rule to any p(q) = fFK(q), deriving p\u0307 = J(q)q\u0307, and thus finally relating variations in the robot\nconfigurations to variations in pose, thereby providing a platform for control.\nGiven a desired end-effector trajectory p\u0307\u2217(t) (1) indicating anchor regions in space and (2) how much time to spend\nin each region, diff-IK finds q\u0307(t) solving for joints\u2019 velocities instead of configurations,\n\nq\u0307(t) = argmin \u2225J(q(t))\u03bd \u2212 p\u0307\u2217(t)\u222522 (2)\n\u03bd\n\nUnlike eq. 1, solving for q\u0307 is much less dependent on the environment (typically, variations in velocity are constrained\nby physical limits on the actuators). Conveniently, eq. 2 also often admits",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_291b5e31750d4a4bb3156e434f85ec37": {
    "id": "parent_291b5e31750d4a4bb3156e434f85ec37",
    "metadata": {
      "content": "velocity are constrained\nby physical limits on the actuators). Conveniently, eq. 2 also often admits the closed-form solution q\u0307 = J(q)+p\u0307\u2217,\nwhere J+(q) denotes the Moore-Penrose pseudo-inverse of J(q). Finally, discrete-time joint configurations q can be\nreconstructed from joint velocities q\u0307 using forward-integration on the continuous-time joint velocity , qt+1 = qt +\u2206t q\u0307t\nfor a given \u2206t, resulting in tracking via diff-IK.\nFollowing trajectories with diff-IK is a valid option in well-controlled and static environments (e.g., industrial\nmanipulators in controlled manufacturing settings), and relies on the ability to define a set of target velocities to\ntrack [p\u0307\u22170, p\u0307\n\n\u2217\n1, . . . , p\u0307\n\n\u2217\nk]\u2014an error-prone task largely requiring human expertise. Furthermore, diff-IK relies on the ability\n\nto (1) access J(q)\u2200q \u2208 Q and (2) compute its pseudo-inverse at every iteration of a given control cycle\u2014a challenging\nassumption in highly dynamical settings, or for complex kinematic chains.\n\n2.3.1",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_39894c58594d4fca8cc903813b6e1533": {
    "id": "parent_39894c58594d4fca8cc903813b6e1533",
    "metadata": {
      "content": "ycle\u2014a challenging\nassumption in highly dynamical settings, or for complex kinematic chains.\n\n2.3.1 Adding Feedback Loops\nWhile very effective when a goal trajectory has been well specified, the performance of diff-IK can degrade significantly\nin the presence of modeling/tracking errors, or in the presence of non-modeled dynamics in the environment.\nOne such case is presented in Figure 7, where another rigid body other than\nthe manipulator is moving in the environment along the horizontal axis, with\nvelocity x\u0307B . Accounting analytically for the presence of this disturbance\u2014for\ninstance, to prevent the midpoint of the link from ever colliding with the\nobject\u2014requires access to x\u0307B at least, to derive the equation characterizing\nthe motion of the environment.\nLess predictable disturbances however (e.g., x\u0307B \u2190 x\u0307B + \u03b5, \u03b5 \u223c N(0, 1)) may\nprove challenging to model analytically, and one could attain the same result of Figure 7 | Planar manipulator robot\npreventing link-object collision by a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7292da16e6354836bd9269039ee9da92": {
    "id": "parent_7292da16e6354836bd9269039ee9da92",
    "metadata": {
      "content": "attain the same result of Figure 7 | Planar manipulator robot\npreventing link-object collision by adding a condition on the distance between in the presence of a moving obstacle.\nthe midpoint of l and xB, enforced through a feedback loop on the position\nof the robot and object at each control cycle.\nTo mitigate the effect of modeling errors, sensing noise and other disturbances,\nclassical pipelines indeed do augment diff-IK with feedback control looping back quantities of interest. In practice,\nfollowing a trajectory with a closed feedback loop might consist in backwarding the error between the target and\nmeasured pose, \u2206p = p\u2217 \u2212 p(q), hereby modifying the control applied to q\u0307 = J(q)+(p\u0307\u2217 + kp\u2206p), with kp defined as\nthe (proportional) gain.\nMore advanced techniques for control consisting in feedback linearization, PID control, Linear Quatratic Regulator\n(LQR) or Model-Predictive Control (MPC) can be employed to stabilize tracking and reject moderate perturbations,\nand we refer to Sic",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_232173df295a4270bd02bfda913f28d1": {
    "id": "parent_232173df295a4270bd02bfda913f28d1",
    "metadata": {
      "content": "l (MPC) can be employed to stabilize tracking and reject moderate perturbations,\nand we refer to Siciliano and Khatib (2016, Chapter 8) for in-detail explanation of these concepts, or (Tedrake, a,\nChapter 8) for a simple, intuitive example in the case of a point-mass system. Nonetheless, feedback control presents\nits challenges as well: tuning gains remains laborious and system-specific. Further, manipulation tasks present\nintermittent contacts inducing hybrid dynamics (mode switches) and discontinuities in the Jacobian, challenging\nthe stability guarantees of the controller and thus often necessitating rather conservative gains and substantial\nhand-tuning.\nWe point the interested reader to Siciliano and Khatib (2016, Chapter 2,7,8), Lynch and Park (2017, Chapter 6,11),\nand Tedrake (a, Chapter 3,8) for extended coverage of FK, IK, diff-IK and control for (diff-)IK.\n\n2.4 Limitations of Dynamics-based Robotics\nDespite the last 60+ years of robotics research, autonomous robots are still l",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ff841e337dfd4f65847f18a7e327bb80": {
    "id": "parent_ff841e337dfd4f65847f18a7e327bb80",
    "metadata": {
      "content": "namics-based Robotics\nDespite the last 60+ years of robotics research, autonomous robots are still largely incapable of performing tasks at\nhuman-level performance in the physical world generalizing across (1) robot embodiments (different manipulators,\n\n13\n\n\n\nFigure 8 | Dynamics-based approaches to robotics suffer from several limitations: (1) orchestrating multiple components poses\nintegration challenges; (2) the need to develop custom processing pipelines for the sensing modalities and tasks considered\nhinders scalability; (3) simplified analytical models of physical phenomena (here friction at the gripper; credits to Antonova\net al. (2017)) limit real-world performance. Lastly, (4) dynamics-based methods overlook trends in the availability and growth\nof robotics data.\n\ndifferent locomotion platforms, etc.) and (2) tasks (tying shoe-laces, manipulating a diverse set of objects). While\nessential in the early development of robotics, the aforementioned methods require significant human",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c56c4ed180d44c40b09954d230c31ff3": {
    "id": "parent_c56c4ed180d44c40b09954d230c31ff3",
    "metadata": {
      "content": "essential in the early development of robotics, the aforementioned methods require significant human expertise to be\nused in practice, and are typically specific to a particular applicative problem.\nDynamics-based robotics pipelines have historically been developed sequentially, engineering the different blocks now\nwithin most architectures for specific purposes. That is, sensing, state estimation, mapping, planning, (diff-)IK, and\nlow-level control have been traditionally developed as distinct modules with fixed interfaces. Pipelining these specific\nmodules proved error-prone, and brittleness emerges\u2014alongside compounding errors\u2014whenever changes incur (e.g.,\nchanges in lighting for sensing, occlusion/failure of sensors, control failures). Adapting such a stack to new tasks\nor robotic platforms often entails re-specifying objectives, constraints, and heuristics at multiple stages, incurring\nsignificant engineering overhead.\nMoreover, classical planners operate on compact, assumed-suffi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_cc4ccdb4116a49e1b836edf28f3ffb89": {
    "id": "parent_cc4ccdb4116a49e1b836edf28f3ffb89",
    "metadata": {
      "content": "ing\nsignificant engineering overhead.\nMoreover, classical planners operate on compact, assumed-sufficient state representations; extending them to reason\ndirectly over raw, heterogeneous and noisy data streams is non-trivial. This results in a limited scalability to\nmultimodal data and multitask settings, as incorporating high-dimensional perceptual inputs (RGB, depth, tactile,\naudio) traditionally required extensive engineering efforts to extract meaningful features for control. Also, the large\nnumber of tasks, coupled with the adoption of per-task planners, goal parameterizations, and safety constraints,\nresults in an explosion in design and validation options, with little opportunity to reuse solutions across tasks.\nSetting aside integration and scalability challenges: developing accurate modeling of contact, friction, and compliance\nfor complicated systems remains difficult. Rigid-body approximations are often insufficient in the presence of\ndeformable objects, and relying on appro",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d611cebee6134b4b8c68bd2d57caaf79": {
    "id": "parent_d611cebee6134b4b8c68bd2d57caaf79",
    "metadata": {
      "content": "dy approximations are often insufficient in the presence of\ndeformable objects, and relying on approximated models hinders real-world applicability of the methods developed.\n\n14\n\n\n\nIn the case of complex, time-dependent and/or non-linear dynamics, even moderate mismatches in parameters,\nunmodeled evolutions, or grasp-induced couplings can qualitatively affect the observed dynamics.\nLastly, dynamics-based methods (naturally) overlook the rather recent increase in availability of openly-available\nrobotics datasets. The curation of academic datasets by large centralized groups of human experts in robotics (O\u2019Neill\net al., 2025; Khazatsky et al., 2025) is now increasingly complemented by a growing number of robotics datasets\ncontributed in a decentralized fashion by individuals with varied expertise. If not tangentially, dynamics-based\napproaches are not posed to maximally benefit from this trend, which holds the premise of allowing generalization in\nthe space of tasks and embodiments, lik",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b405ce9a5033486c864b33ee824d07e9": {
    "id": "parent_b405ce9a5033486c864b33ee824d07e9",
    "metadata": {
      "content": "trend, which holds the premise of allowing generalization in\nthe space of tasks and embodiments, like data was the cornerstone for advancements in vision (Alayrac et al., 2022)\nand natural-language understanding (Brown et al., 2020).\nTaken together, these limitations (Figure 8) motivate the exploration of learning-based approaches that can (1)\nintegrate perception and control more tightly, (2) adapt across tasks and embodiments with reduced expert modeling\ninterventions and (3) scale gracefully in performance as more robotics data becomes available.\n\n15\n\n\n\nFigure 9 | Learning-based robotics streamlines perception-to-action by learning a (1) unified high-level controller capable to\ntake (2) high-dimensional, unstructured sensorimotor information. Learning (3) does not require a dynamics model and instead\nfocuses on interaction data, and (4) empirically correlates with the scale of the data used.\n\n3 Robot (Reinforcement) Learning\nApproximate the solution, not the\nproblem [...]\n\nRichard S",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e5a7cd8d9c93492ebbead7db91b4f4bb": {
    "id": "parent_e5a7cd8d9c93492ebbead7db91b4f4bb",
    "metadata": {
      "content": "a used.\n\n3 Robot (Reinforcement) Learning\nApproximate the solution, not the\nproblem [...]\n\nRichard Sutton\n\nTL;DR\n\nThe need for expensive, high-fidelity simulators can be obviated learning from real-world data, using sample-\nefficient algorithms that can safely train directly on hardware.\n\nLearning-based techniques for robotics naturally address the limitations presented in Section 2 (Figure 9). In particular,\nlearning-based techniques typically rely on monolithich prediction-to-action pipelines (visuomotor policies) which\ndo directly map sensorimotor inputs to predicted actions, streamlining control policies by removing the need to\ninterface multiple components. Mapping sensory inputs to actions also makes it possible to incorporate diverse\ninput modalities, leveraging the automatic feature extraction capabilities of modern learning systems. Moreover,\nlearning-based approaches can, in principle, bypass explicit modeling altogether and instead rely solely on interaction\ndata\u2014an advantag",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2d3840ef7b3d4e44811e8f5fff136dfa": {
    "id": "parent_2d3840ef7b3d4e44811e8f5fff136dfa",
    "metadata": {
      "content": "inciple, bypass explicit modeling altogether and instead rely solely on interaction\ndata\u2014an advantage that proves transformative when dynamics are difficult to model or entirely unknown. Lastly,\nlearning for robotics (robot learning) is naturally well posed to leverage the growing amount of robotics data openly\navailable, just as computer vision and natural language processing did historically benefit from large-scale corpora of\ndata, in great part overlooked by dynamics-based approaches.\nBeing a field at its relative nascent stages, no prevalent technique(s) proves distinctly better than any other in the\n\n16\n\n\n\nFigure 11 | Examples of two different robotics tasks performed using RL. In the manipulation task (A) an agent learns to reach\nfor a yellow plastic block in its environment, and to put it inside of a box. In the locomotion task (B) an agent learns to move\nits center of mass sideways without falling.\n\ndomain of robot learning. Still, two major classes of methods gained prominenc",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_90577cb6896b41858ba9ebf1b5563f75": {
    "id": "parent_90577cb6896b41858ba9ebf1b5563f75",
    "metadata": {
      "content": "ays without falling.\n\ndomain of robot learning. Still, two major classes of methods gained prominence: Reinforcement Learning (RL) and\nBehavioral Cloning (BC) (Figure 10). In this section, we provide a conceptual overview of applications of RL to\nrobotics, as well as introduce practical examples of how to use RL within lerobot. We then introduce the major\nlimitations RL suffers from, to introduce BC techniques in Section 4 and Section sec:learning-foundation.\nIn Figure 10 we deliberately include generalist robot models (Black et al.,\n2024; Shukor et al., 2025) alongside task-specific BC methods. While signif-\nicantly different in spirit\u2014generalist models are language-conditioned and use\ninstructions to generate motion valid across many tasks, while task-specific\nmodels are typically not language-conditioned and used to perform a single\ntask\u2014foundation models are still largely trained to reproduce trajectories\ncontained in a (large) training set of input demonstrations. Thus, we argue\ng",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f5bb67d2bf8340d6bb3028db0db8f802": {
    "id": "parent_f5bb67d2bf8340d6bb3028db0db8f802",
    "metadata": {
      "content": "reproduce trajectories\ncontained in a (large) training set of input demonstrations. Thus, we argue\ngeneralist policies can indeed be grouped alongside other task-specific BC\nmethods, as they both leverage similar training data and schemas. Figure 10 il-\nlustrates this categorization graphically, explicitly listing all the robot learning\npolicies currently available in lerobot: Action Chunking with Transformers\n(ACT) (Zhao et al., 2023), Diffusion Policy (Chi et al., 2024), Vector-Quantized\nBehavior Transformer (VQ-BeT) (Lee et al., 2024), \u03c00 (Black et al., 2024),\nSmolVLA (Shukor et al., 2025), Human-in-the-loop Sample-efficient RL (HIL-\nSERL) (Luo et al., 2024) and TD-MPC (Hansen et al., 2022).\nApplications of RL to robotics have been studied long enough that the rela- Figure 10 | Overview of the\ntionship between these two disciplines has been compared to that of physics robot learning methods implemented\n\nand matematics (Kober et al.). Indeed, due to their inherently interactive in le",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1d2ea6b424e64ad1896409dc354152f4": {
    "id": "parent_1d2ea6b424e64ad1896409dc354152f4",
    "metadata": {
      "content": "ethods implemented\n\nand matematics (Kober et al.). Indeed, due to their inherently interactive in lerobot. All algorithms are imple-\nmented in Pytorch. References: Zhao\n\nand sequential nature, robotics control problems can be directly cast as RL et al. (2023); Chi et al. (2024); Lee et al.\nproblems. Figure 11 presents two of such cases. Reaching for an object to (2024); Black et al. (2024); Shukor et al.\nthen move it somewhere else in the scene is a sequential problem where over (2025); Luo et al. (2024); Hansen et al.\ntime the controller needs to adjust the position of the robot arm based on (2022) (top-to-bottom, left-to-right).\nthe current configuration and the (possibly varying) position of the object.\nFigure 11 also shows an example of a locomotion problem, where sequentiality is inherent in the problem formulation:\nwhile sliding to the side, the controller needs to keep adjusting to the robot\u2019s to avoid failure (falling).\n\n3.1 A (Concise) Introduction to RL\nThe RL framework (Sutt",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ef071cf173e641c4b58e2791e462b76d": {
    "id": "parent_ef071cf173e641c4b58e2791e462b76d",
    "metadata": {
      "content": "o the robot\u2019s to avoid failure (falling).\n\n3.1 A (Concise) Introduction to RL\nThe RL framework (Sutton and Barto, 2018), which we briefly introduce here, has often been used to tackle robotics\nproblems (Kober et al.). RL is a subfield within ML fundamentally concerned with the development of autonomous\nsystems (agents) capable to continuously behave in an evolving environment, developing (ideally, well-performing)\ncontrol strategies (policies). Crucially for robotics, RL agents improve through trial and error, bypassing explicit\nmodels of the problem dynamics in favor of interaction data. In RL, this feedback loop between actions and outcomes\n(Figure 12) is established through the agent sensing a scalar quantity (reward) measuring how desirable a given\ntransition is for the accomplishment of its goal.\nFormally, interactions between an agent and its environment are typically modeled via a Markov Decision Pro-\n\n17\n\n\n\nFigure 12 | Agent-Environment interaction diagram (image credits to Sut",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2aeae1f58fe1470ab0d96ab6162e0b29": {
    "id": "parent_2aeae1f58fe1470ab0d96ab6162e0b29",
    "metadata": {
      "content": "Markov Decision Pro-\n\n17\n\n\n\nFigure 12 | Agent-Environment interaction diagram (image credits to Sutton and Barto (2018)).\n\ncess (MDP) (Bellman, 1957). Representing robotics problems via MDPs offers several advantages, including (1)\nincorporating uncertainty through MDP\u2019s inherently stochastic formulation and (2) providing a theoretically-sound\nframework for learning without an explicit model of the environment dynamics. While accommodating a continuous\ntime formulation too, MDPs are typically considered in discrete time in RL, assuming interactions to atomically take\nplace at discrete timestep t = 0, 1, 2, 3, . . . , T . MDPs allowing for an unbounded number of interactions (T \u2192 +\u221e)\nare termed infinite-horizon, and opposed to finite-horizon MDPs in which T is finite. Unless diversely specified, we\nwill only be referring to discrete-time finite-horizon (episodic) MDPs.\nFormally, a lenght-T Markov Decision Process (MDP) is a tuple M = \u27e8S,A,D, r, \u03b3, \u03c1, T \u27e9, where:\n\n\u2022 S is the state space",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2dfabc80d4ce40a28d22f453bf812921": {
    "id": "parent_2dfabc80d4ce40a28d22f453bf812921",
    "metadata": {
      "content": "-T Markov Decision Process (MDP) is a tuple M = \u27e8S,A,D, r, \u03b3, \u03c1, T \u27e9, where:\n\n\u2022 S is the state space; st \u2208 S denotes the (possibly non-directly observable) environment state at time t. In robotics,\nstates often comprise robot configuration and velocities (qt, q\u0307t), and can also accomodate sensor readings such as\ncamera or audio streams.\n\n\u2022 A is the action space; at \u2208 A may represent joint torques, joint velocities, or even end-effector commands at\ntimestep t. In general, actions correspond to commands intervenings on the configuration of the robot.\n\n\u2022 D represents the (possibly non-deterministic) environment dynamics, with D : S \u00d7A\u00d7S 7\u2192 [0, 1], D (st, at, st+1) =\nP(st+1|st, at). For instance, for a planar manipulator dynamics could be considered deterministic when the\nenvironment is fully described (Figure 6a), and stochastic when unmodeled disturbances depending on non-\nobservable parameters intervene (Figure 7).\n\n\u2022 r : S \u00d7A\u00d7 S \u2192 R is the reward function, weighing the transition (st,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_0f2b9340dc0845eb92cbf7138452a831": {
    "id": "parent_0f2b9340dc0845eb92cbf7138452a831",
    "metadata": {
      "content": "eters intervene (Figure 7).\n\n\u2022 r : S \u00d7A\u00d7 S \u2192 R is the reward function, weighing the transition (st, at, st+1) in the context of the achievement of\nan arbitrary goal. For instance, a simple reward function for quickly moving along the x axis (Figure 11) could\nbe based on the absolute position of the robot along the x axis (pxt), present negative penalties for falling over\n(measured from pz ) and a introduce bonuses p\u0307x for speed, r(st, at, st+1) \u2261 r(st) = p \u00b7 p\u0307 1\n\nt t xt x \u2212t p .\nzt\n\nLastly, \u03b3 \u2208 [0, 1) represent the discount factor regulating preference for immediate versus long-term reward (with an\neffective horizon equal to 1\n\n1\u2212\u03b3 ), and \u03c1 is the distribution over S for the MDP\u2019s initial, s0 \u223c \u03c1.\nTherefore, a length-T trajectory is the (random) sequence\n\n\u03c4 = (s0, a0, r0, s1, a1, r1, . . . , sT\u22121, aT\u22121, rT\u22121, sT ), (3)\nwith per-step rewards defined as rt = r(st, at, st+1) for ease of notation. Interestingly, assuming both the environment\ndynamics and conditional distribution over acti",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_106af7e2c2924b479c3088c6ac925921": {
    "id": "parent_106af7e2c2924b479c3088c6ac925921",
    "metadata": {
      "content": "tation. Interestingly, assuming both the environment\ndynamics and conditional distribution over actions given states\u2014i.e., the policy\u2014to be Markovian:\n\nP(st+1|st, at, st\u22121, at\u22121, . . . s0, a0) = P(st+1|st, at) (4)\nP(at|st, at\u22121, st\u22121, s0, a0) = P(at|st), (5)\n\nthe probability of observing a given trajectory \u03c4 factorizes into:\nT\u220f\u22121\n\nP(\u03c4) = P(s0) P(st+1|st, at) P(at|st). (6)\nt=0\n\nPolicies P(at|st) are typically indicated as \u03c0(at|st), often parametrized via \u03b8, yielding \u03c0\u03b8(at|st), and are traine by\noptimizing the (discounted) return associated to a given \u03c4 , i.e. the (random) sum of measured rewards over an\narbitrary trajectory,\n\nT\u2211\u22121\n\nG(\u03c4) = \u03b3trt.\nt=0\n\n18\n\n\n\nFigure 13 | Popular RL algorithms. See Achiam (2018) for a complete list of citations.\n\nIn that, agents seek to learn control strategies (policies, \u03c0\u03b8) maximizing the expected return E\u03c4\u223c\u03c0 G(\u03c4). For a given\n\u03b8\n\ndynamics D\u2014i.e., for a given problem\u2014taking the expectation over the (possibly random) trajectories resulting from\nacting accord",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_718884ffa1a04b25825f2a8e592957f4": {
    "id": "parent_718884ffa1a04b25825f2a8e592957f4",
    "metadata": {
      "content": "problem\u2014taking the expectation over the (possibly random) trajectories resulting from\nacting according to a certain policy provides a direct, goal-conditioned ordering in the space of all the possible policies\n\u03a0, yielding the (maximization) target J : \u03a0 7\u2192 R\n\nJ(\u03c0\u03b8) = E\u03c4\u223cP\u03b8;D [G(\u03c4)], (7)\nT\u220f\u22121\n\nP\u03b8;D(\u03c4) = \u03c1 D(st, at, st+1) \u03c0\u03b8(at|st). (8)\nt=0\n\nCrucially, in the RL framework the agent is assumed to only observe the environment dynamics and not to intervene\non them, and thus eq. 7 varies exclusively with the policy followed. In turn, MDPs naturally provide a framework\nto optimize over the space of the possible behaviors an agent might enact (\u03c0 \u2208 \u03a0), searching for the optimal policy\n\u03c0\u2217 = argmax\u03b8 J(\u03c0\u03b8), where \u03b8 is the parametrization adopted by the policy set \u03a0 : \u03c0\u03b8 \u2208 \u03a0, \u2200\u03b8. Besides providing a\ntarget for policy search, G(\u03c4) can also be used to discriminate between states st and st, at pairs. Given any state\ns \u2208 S\u2014e.g., given a configuration q of a robot\u2014the state-v[alue \u2223functio]n\n\nV\u03c0(s) = E",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3b9a68eca7e84c58970b318d9338b41c": {
    "id": "parent_3b9a68eca7e84c58970b318d9338b41c",
    "metadata": {
      "content": "iven any state\ns \u2208 S\u2014e.g., given a configuration q of a robot\u2014the state-v[alue \u2223functio]n\n\nV\u03c0(s) = E\u03c4\u223c\u03c0 G(\u03c4)\u2223s0 = s\n\ncan be used to discriminate between desirable and undesirable state in terms of long-term (discounted) reward\nmaximization, under a given policy \u03c0. Similarily, the state-action value function also conditions the cumulative\ndiscounted reward on selecting action a when in s, and[therea\u2223 fter act accord] ing to \u03c0,\n\nQ\u03c0(s, a) = E\u03c4\u223c G(\u03c4)\u2223\u03c0 s0 = s, a0 = a .\n\nImportantly, value functions are interrelated:\n\nQ\u03c0(st, at) = Est+1\u223cP(\u2022|st,at)[rt + \u03b3V\u03c0(st+1)] (9)\nV\u03c0(st) = Eat\u223c\u03c0(\u2022|st)[Q\u03c0(st, at)], (10)\n\ninducing an ordering over states and state-action pairs under \u03c0, and value functions are thus central to most RL\nalgorithms. A variety of algorithms have been developed in RL attempting to find (approximate) solutions to the\nproblem of maximizing cumulative reward (we report some in Figure 13).\nPopular approaches to continuous state and action space\u2014such as those studied within robotics\u2014i",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ae33c1adad4f4425b94774c6069e60db": {
    "id": "parent_ae33c1adad4f4425b94774c6069e60db",
    "metadata": {
      "content": "13).\nPopular approaches to continuous state and action space\u2014such as those studied within robotics\u2014include Schulman\net al. (2017a, TRPO), Schulman et al. (2017b, PPO) and Haarnoja et al. (2018, SAC). Across manipulation (Akkaya\n\n19\n\n\n\nFigure 14 | Simulated (left) vs. real-world (right) OpenDuck. Discrepancies in the simulation dynamics (reality gap) pose risks\nto policy transfer.\n\net al., 2019) and locomotion problems (Lee et al., 2020), RL proved extremely effective in providing a platform to (1)\nleverage a unified, streamlined perception-to-action pipeline, (2) natively integrate propioperception with multi-modal\nhigh-dimensional sensory streams (3) disregard a description of the environment dynamics, by focusing on observed\ninteraction data rather than modeling, and (4) anchor policies in the experience collected and stored in datasets. For\na more complete survey of applications of RL to robotics, we refer the reader to Kober et al.; Tang et al. (2025).\n\n3.2 Real-world RL for Roboti",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7002098a18b14cd69e8f6fbc1c4e8322": {
    "id": "parent_7002098a18b14cd69e8f6fbc1c4e8322",
    "metadata": {
      "content": "to robotics, we refer the reader to Kober et al.; Tang et al. (2025).\n\n3.2 Real-world RL for Robotics\nStreamlined end-to-end control pipelines, data-driven feature extraction and a disregard for explicit modeling in favor\nof interaction data are all features of RL for robotics. However, RL still suffers from limitations concerning safety and\nlearning efficiency, particularly pressing for real-world robotics applications.\nFirst, especially early in training, actions are typically explorative, and thus may be erractic. On physical systems,\nuntrained policies may command high velocities, self-collisiding configurations, or torques exceeding joint limits,\nleading to wear and potential hardware damage. Mitigating these risks requires external safeguards (e.g., watchdogs,\nsafety monitors, emergency stops), often incuring in a high degree of human supervision. Further, in the typical\nepisodic setting considered in most robotics problems, experimentation is substantially slowed down by the ne",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_654af3d680fd457eb9b7f46097efb9e4": {
    "id": "parent_654af3d680fd457eb9b7f46097efb9e4",
    "metadata": {
      "content": "setting considered in most robotics problems, experimentation is substantially slowed down by the need to\nmanually reset the environment over the course of training, a time-consuming and error-prone process. Second, learning\nefficiently remains problematic in RL, limiting the applicability of RL in real-world robotics due to consequently\nprohibitive timescales of training. Even strong algorithms such as SAC (Haarnoja et al., 2018) typically require a\nlarge numbers of transitions {(st, at, rt, st+1)}Nt=1. On real-world hardware, generating this data is time-consuming.\nTraining RL policies in simulation (Tobin et al., 2017) addresses both issues, eliminating physical risk and dramatically\nincreasing throughput. Yet, simulators require significant modeling effort, and rely on assumptions (simplified physical\nmodeling, instantaneous actuation, static environmental conditions, etc.) limiting the possibilities to transfer the\npolicies learned in simulation, due the discrepancy between real a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_37d3bc15087c4b9084571f10d325e8dd": {
    "id": "parent_37d3bc15087c4b9084571f10d325e8dd",
    "metadata": {
      "content": "the possibilities to transfer the\npolicies learned in simulation, due the discrepancy between real and simulated environments (reality gap, Figure 14).\nDomain randomization (Tobin et al., 2017) (DR) is a popular technique to overcome the reality gap, and consists in\nrandomizing the parameters of the simulated environment during training, aiming at inducing robustness to specific\ndisturbances. In this, DR is typically employed to increase the diversity of scenarios over the course of training,\nimproving on the performace sim-to-real transferred policies (Akkaya et al., 2019; Antonova et al., 2017; Ji et al.,\n2023). In practice, DR is performed training in simulation on simulated dynamics D, further parametrized as D \u2261 D\u03be,\nwith a dynamics (random) vector \u03be drawn an arbitrary distribution, \u03be \u223c \u039e. For instance, one could decide to\nrandomize the friction coefficient of the surface in a locomotion task (Figure 15), or the center of mass of an object\nfor a manipulation task. Over the course o",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ba1551e6aef14f95b19d7b4ae43f513c": {
    "id": "parent_ba1551e6aef14f95b19d7b4ae43f513c",
    "metadata": {
      "content": "tion task (Figure 15), or the center of mass of an object\nfor a manipulation task. Over the course of training\u2014typically at each episode\u2019s reset\u2014a new \u03be is drawn, and used to\nspecify the environment\u2019s dynamics for that episode.\nWhile effective in transfering policies across the reality gap in real-world robotics (Tobin et al., 2017; Akkaya et al.,\n2019; Ji et al., 2023; Tiboni et al., 2024), DR often requires extensive manual engineering. First, identifying which\n\n20\n\n\n\nFigure 15 | The same locomotion task can be carried out in different (simulated) domains (exemplified by the difference in\nterrains) at training time, resulting to increased robustness over diverse environment dynamics.\n\nparameters to randomize\u2014i.e., the support supp(\u039e) of \u039e\u2014is an inherently task specific process. When locomoting over\ndifferent terrains, choosing to randomize the friction coefficient is a reasonable choice, yet not completely resolutive as\nother factors (lightning conditions, external temperature, joint",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_421919954fce4b108b72d3b5b22e7cad": {
    "id": "parent_421919954fce4b108b72d3b5b22e7cad",
    "metadata": {
      "content": "e, yet not completely resolutive as\nother factors (lightning conditions, external temperature, joints\u2019 fatigue, etc.) may prove just as important in practice,\nmaking selecting these parameters yet another source of brittlness.\nSelecting the dynamics distribution \u039e is also non-trivial. On the one hand, distributions with low entropy might risk\nto cause failure at transfer time, due to the limited robustness induced over the course of training. On the other hand,\nexcessive randomization may cause over-regularization and hinder performance (Margolis et al., 2022). Consequently,\nthe research community investigated approaches to automatically select the randomization distribution \u039e, using\nsignals from the training process or tuning it to reproduce observed real-world trajectories. Akkaya et al. (2019)\nuse a parametric uniform distribution U(a, b) as \u039e, widening the bounds a, b as training progresses and the agent\u2019s\nperformance improves (AutoDR). While effective, AutoDR requires significant",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_9a3be3a0e5c94a3ab59709af69ed58b0": {
    "id": "parent_9a3be3a0e5c94a3ab59709af69ed58b0",
    "metadata": {
      "content": "gresses and the agent\u2019s\nperformance improves (AutoDR). While effective, AutoDR requires significant tuning\u2014the bounds are widened by a\nfixed, pre-specified amount \u2206 along\u2014and may disregard data when performance does not improve after a distribution\nupdate (Tiboni et al., 2024). Tiboni et al. (2024) propose a similar method to AutoDR (DORAEMON) to evolve \u039e\nbased on the training signal, but with the key difference of explicitly maximizing the entropy of a parametric Beta\ndistribution\u2014inherently more flexible than uniform distributions\u2014with learned updates instead of fixed \u2206. In this,\nDORAEMON proves particularly effective at dynamically increasing the entropy levels of the training distribution by\nemploying an outer-loop max-entropy objective, tackled under performance constraints in the inner-loop RL problem.\nOther approaches to automatically perform DR consist in specifically tuning \u039e to align as much as possible the\nsimulation and real-world domains. For instance, Chebotar et al. (201",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_97cf3dbd90524be2ac92967b4731fb4a": {
    "id": "parent_97cf3dbd90524be2ac92967b4731fb4a",
    "metadata": {
      "content": "align as much as possible the\nsimulation and real-world domains. For instance, Chebotar et al. (2019) interleave in-simulation policy training with\nrepeated real-world policy rollouts used to adjust \u039e based on real-world data, while Tiboni et al. (2023) leverage a\nsingle, pre-collected set of real-world trajectories and tune \u039e under a simple likelihood objective.\nWhile DR has shown promise, it does not address the main limitation that, even under the assumption that an ideal\ndistribution \u039e was available, many robotics problems cannot be simulated with high-enough fidelity under practical\ncomputational constraints. Simulating contact-rich manipulation of possibly deformable or soft materials\u2014i.e., folding\na piece of clothing\u2014can prove time-intensive, limiting the benefits of in-simulation training.\nA perhaps more foundamental limitation of RL for robotics is the general unavailability of complicated tasks\u2019 dense\nreward function, the design of which is essentially based on human experti",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_6f61c6c6e98b4d9e9be4f2abac47936e": {
    "id": "parent_6f61c6c6e98b4d9e9be4f2abac47936e",
    "metadata": {
      "content": "complicated tasks\u2019 dense\nreward function, the design of which is essentially based on human expertise, ingenuity and trial-and-error. In\npractice, sparse reward functions can be used to conclude whether one specific goal has been attained\u2014has this t-shirt\nbeen correctly folded?\u2014but unfortunately incur in more challenging learning. As a result, despite notable successes,\ndeploying RL directly on real-world robots at scale remains challenging.\nTo make the most of (1) the growing number of openly available datasets and (2) relatively inexpensive robots like the\nSO-100, RL could (1) be anchored in already-collected trajectories\u2014limiting erratic and dangerous exploration\u2014and\n(2) train in the real-world directly\u2014bypassing the aforementioned issues with low-fidelity simulations. In such a\ncontext, sample-efficient learning is also paramount, as training on the real-world is inherently time-bottlenecked.\nOff-policy algorithms like Soft Actor-Critic (SAC) (Haarnoja et al., 2018) tend to be mor",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4f96e186315941ae99e8db23ea5f2c5a": {
    "id": "parent_4f96e186315941ae99e8db23ea5f2c5a",
    "metadata": {
      "content": "tlenecked.\nOff-policy algorithms like Soft Actor-Critic (SAC) (Haarnoja et al., 2018) tend to be more sample efficient then their\non-policy counterpart (Schulman et al., 2017b), due to the presence a replay buffer used over the course of training.\nOther than allowing to re-use past transitions (st, at, rt, st+1), the replay buffer can also accomodate for the injection\nof previously-collected data in the training process (Ball et al., 2023). Using expert demonstrations to guide learning\ntogether with learned rewards, RL can be effectively carried out in the real-world (Luo et al., 2025). Interestingly,\nwhen complemented with in-training human interventions, real-world RL agents have been shown to learn policies\nwith near-perfect success rates on challenging manipulation tasks in 1-2 hours (Luo et al., 2024).\n\n21\n\n\n\nSample-efficient RL In an MDP, the optimal policy \u03c0\u2217 can be derived from its associated Q-function, Q\u2217 \u2261 Q\u03c0\u2217 ,\nand in particular the optimal action(s) \u00b5(st) can be selected m",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f8bb6bd650334b3092035eab236b50b4": {
    "id": "parent_f8bb6bd650334b3092035eab236b50b4",
    "metadata": {
      "content": "ts associated Q-function, Q\u2217 \u2261 Q\u03c0\u2217 ,\nand in particular the optimal action(s) \u00b5(st) can be selected maximizing the optimal Q-function over the action space,\n\n\u00b5(st) = maxQ\u2217(st, at).\nat\u2208A\n\nInterestingly, the Q\u2217-function satisfies a recursive relationship (Bellman equation) based on a very natural intuition2:\n[...] If the optimal value Q\u2217(st+1, at+1) of the [state] st+1 was known for all possible actions at+1, then\nthe optimal strategy is to select the action at+1 [maximizing the expected value of\n\n\u2223\nr \u2223 ]rt + \u03b3Q\u2217(st+1, at+1)\n\nQ\u2217(st, at) = Est+1\u223cP(\u2022|st,at) t + \u03b3 max Q\u2217(st+1, at+1) st, at\nat+1\u2208A\n\nIn turn, the optimal Q-function is guaranteed to be self-consistent by definition. Value-iteration methods exploit this\nrelationship (and/or its state-value counterpart, V \u2217(st) ) by iteratively updating an initial estimate of Q\u2217, Qk using\nthe Bellman equation as update rule (Q-learn[ing):\n\n\u2223\nr \u2223 ]\n\nQi+1(st, at)\u2190 Est+1\u223cP(\u2022|st,at) t + \u03b3 max Qi(st+1, at+1) st, at , i = 0, 1, 2, . . . ,K\nat+1\u2208A\n\nThen,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d85f9b060e8541d9a4b8b523a7251d69": {
    "id": "parent_d85f9b060e8541d9a4b8b523a7251d69",
    "metadata": {
      "content": "Qi+1(st, at)\u2190 Est+1\u223cP(\u2022|st,at) t + \u03b3 max Qi(st+1, at+1) st, at , i = 0, 1, 2, . . . ,K\nat+1\u2208A\n\nThen, one can derive the (ideally, near-optimal) policy by explicitly maximizing over the action space the final (ideally,\nnear-optimal) estimate QK \u2248 Q\u2217 at each timestep. Indeed, one can show that under certain assumptions on the MDP\nconsidered, QK \u2192 Q\u2217 as K \u2192\u221e.\nEffective in its early applications to small-scale discrete problems, vanilla Q-learning was found complicated to scale\nto large S \u00d7A problems, in which storing Q : S \u00d7A 7\u2192 R alone might result prohibitive. Also, vanilla Q-learning is\nnot directly usable for continuous, unstructured state-action space MPDs, such as those considered in robotics. In\ntheir seminal work on Deep Q-Learning (DQN), Mnih et al. (2013) propose learning Q-values using deep convolutional\nneural networks, thereby accomodating for large and even unstructured state spaces. DQN parametrizes the Q-function\nusing a neural network with parameters \u03b8, updating the param",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_99a09b0de8194edbb8679a76b7fdc6f8": {
    "id": "parent_99a09b0de8194edbb8679a76b7fdc6f8",
    "metadata": {
      "content": "spaces. DQN parametrizes the Q-function\nusing a neural network with parameters \u03b8, updating the parameters by sequentially minimizing the expected squared\ntemporal-difference error (TD-error, \u03b4i): [\n\n(\ufe38 ]\nL(\u03b8i) = E(st,at)\u223c\u03c7(\u2022) yi \u2212Q\ufe37\u03b8\ufe37(s a\n\ni t, t\ufe38))2 , (11)\n\n[ \u03b4i ]\nyi = Est+1\u223cP(\u2022|s r + \u03b3 ma\n\nt,a x\nt) t Q\u03b8 (\n\ni\u2212 s\n1 t+1, at+1) , (12)\n\nat\u2208A\n\nwhere \u03c7 represents a behavior distribution over state-action pairs. Crucially, \u03c7 can in principle be different from the\npolicy being followed, effectively allowing to reuse prior data stored in a replay buffer D in the form of (st, at, rt, st+1)\ntransitions, used to form the TD-target yi, TD-error \u03b4i and loss function eq. 11 via Monte-Carlo (MC) estimates.\nWhile effective in handling large, unstructured state spaces for discrete action-space problems, DQN\u2019s application to\ncontinous control problems proved challenging. Indeed, in the case of high-capacity function approximators such as\nneural networks, solving maxat\u2208AQ\u03b8(st, at) at each timestep is sim",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f3f948831a914c24b4e482e7e64cc33e": {
    "id": "parent_f3f948831a914c24b4e482e7e64cc33e",
    "metadata": {
      "content": "ty function approximators such as\nneural networks, solving maxat\u2208AQ\u03b8(st, at) at each timestep is simply unfeasible due to the (1) continous nature\nof the action space (A \u2282 Rn for some n) and (2) impossibility to express the policy with a cheap (ideally, even\nclosed-form) formulation, so that maxQ\u03b8 could be solved analytically. Silver et al. (2014) tackle these fundamental\nchallenges by using a deterministic function of the state st as policy, \u00b5\u03d5(st) = at, parametrized by \u03d5. Thus, policies\ncan be iteratively refined updat[ing \u03d5 along the direct]ion: [ ]\n\nd\u03d5 = Est\u223cP(\u2022) \u2207\u03d5Q(st, at)|a =\nt=\u00b5\u03d5(st) Est\u223cP(\u2022) \u2207a Q(s a\n\nt t, t)|a \u2207\nt=\u00b5\u03d5(st) \u00b7 \u03d5\u00b5(st) (13)\n\nProvably, eq. 13 is the deterministic policy gradient (DPG) of the policy \u00b5\u03d5 (Silver et al., 2014), so that updates\n\u03d5k+1 \u2190 \u03d5k + \u03b1d\u03d5 are guaranteed to increase the (deterministic) cumulative discounted reward, J(\u00b5\u03d5). Lillicrap\net al. (2019) extended DPG to the case of (1) high-dimensional unstructured observations and (2) continuous action\nspace",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_8212e8c510264e16a64572a5adf4f277": {
    "id": "parent_8212e8c510264e16a64572a5adf4f277",
    "metadata": {
      "content": "ed DPG to the case of (1) high-dimensional unstructured observations and (2) continuous action\nspaces, introducing Deep Deterministic Policy Gradient (DDPG), an important algorithm in RL and its applications\nto robotics. DDPG adopts a modified TD-target com[pared to eq. 12, by maintaining a policy network used to select\nactions, yielding ]\n\nyi = Est+1\u223cP(\u2022|st,at) rt + \u03b3Q\u03b8 , \u00b5 (\ni\u2212 (s s\n\n1 t+1 \u03d5 t+1)) . (14)\n2Quote from Mnih et al. (2013). The notation used has slightly been adapted for consistency with the rest of this tutorial.\n\n22\n\n\n\nSimilarily to DQN, DDPG also employs the same replay buffer mechanism, reusing past transitions over training for\nincreased sample efficiency and estimate the loss function via MC-estimates.\nSoft Actor-Critic (SAC) (Haarnoja et al., 2018) is a derivation of DDPG in the max-entropy (MaxEnt) RL framework,\nin which RL agents are tasked with maximizing the discounted cumulative reward, while acting as randomly as\npossible. MaxEnt RL (Haarnoja et al., 2017) ha",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_6b01813ab0ef4136a647f6313b940382": {
    "id": "parent_6b01813ab0ef4136a647f6313b940382",
    "metadata": {
      "content": "ounted cumulative reward, while acting as randomly as\npossible. MaxEnt RL (Haarnoja et al., 2017) has proven particularly robust thanks to the development of diverse\nbehaviors, incentivized by its entropy-regularization formulation. In that, MaxEnt revisits the RL objective J(\u03c0) to\nspecifically account for the policy entropy H(\u03c0(\u2022|st)),\n\n\u2211T\nJ(\u03c0) = E(s H \u2022 )\n\nt,a r + \u03c0 s ]\nt)\u223c\u03c7[ t \u03b1 ( ( | t ) . (15)\n\nt=0\n\nThis modified objective results in t[he soft( TD-target: )]\nyi = Est+1\u223cP(\u2022|st,at) rt + \u03b3 Q\u03b8i\u22121(st+1, at+1)\u2212 \u03b1 log \u03c0\u03d5(at+1|st+1) , at+1 \u223c \u03c0\u03d5(\u2022|st) (16)\n\nSimilarily to DDPG, SAC also maintains an explicit policy, trained under the same MaxEnt framework for the\nmaximization of eq. 15, updated using: ( \u2225 )\n\n\u03c0k+1 \u2190 arg min D \u2032 \u2225exp(Q\u03c0 (s , )\nk\n\nKL \u03c0 (\u2022| t \u2022 )\nst)\u2225\n\n\u03c0\u2032\u2208\u03a0 \u2225 (17)\nZ\u03c0 (s )\n\nk t\n\nThe update rule provided in eq. 17 optimizes the policy while projecting it on a set \u03a0 of tractable distributions (e.g.,\nGaussians, Haarnoja et al. (2017)).\n\nSample-efficient, data-driven RL Sampling (st",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7cd4cbe187bc402f8a6d53ba3b6afb75": {
    "id": "parent_7cd4cbe187bc402f8a6d53ba3b6afb75",
    "metadata": {
      "content": "tributions (e.g.,\nGaussians, Haarnoja et al. (2017)).\n\nSample-efficient, data-driven RL Sampling (st, at, rt, st+1) from the replay buffer D conveniently allows to approx-\nimate expectations for TD-target and TD-error through Monte-Carlo (MC) estimates. The replay buffer D also\nproves extremely useful in maintaining a history of previous transitions and using it for training, improving on sample\nefficiency. Furthermore, it also naturally provides an entry point to inject offline trajectories recorded by a human\ndemonstrator into the training process.\nReinforcement Learning with Prior Data (RLPD) (Ball et al., 2023) is an Offline-to-Online RL algorithm leveraging\nprior data to effectively accelerate the training of a SAC agent. Unlike previous works on Offline-to-Online RL, RLPD\navoids any pre-training and instead only uses the available offline data Doffline to improve online-learning from scratch.\nDuring each training step, transitions from both the offline and online replay buffers a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7f808893cd964fb4b440e00605f3053e": {
    "id": "parent_7f808893cd964fb4b440e00605f3053e",
    "metadata": {
      "content": "om scratch.\nDuring each training step, transitions from both the offline and online replay buffers are sampled in equal proportions,\nand used in the underlying SAC routine. Together with other implementation details (using LayerNorm layers to\nprevent value overestimation, and the use of ensembles techniques to form the TD-target), RLPD proves a particularly\nsimple yet effective approach to use Doffline for Offline-to-Online RL.\n\nSample-efficient, data-driven, real-world RL Despite the possibility to leverage offline data for learning, the\neffectiveness of real-world RL training is still limited by the need to define a task-specific, hard-to-define reward\nfunction. Further, even assuming to have access to a well-defined reward function, typical robotics pipelines rely\non augmenting propioperceptive inputs with camera streams, and thus even well-defined rewards would need to be\ndefined starting from unstructured observation\u2014a challenging assumption in practice. In their technical report,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d716f1decdcf44968dd9f22199f094f2": {
    "id": "parent_d716f1decdcf44968dd9f22199f094f2",
    "metadata": {
      "content": "rting from unstructured observation\u2014a challenging assumption in practice. In their technical report, Luo\net al. (2025) empirically address the needs (1) to define a reward function and (2) to use it starting from unstructured,\nimage observations. In particular, Luo et al. (2025, SERL) introduces a suite of tools streamlining training of reward\nclassifiers c, as well as jointly learn forward-backward controllers to speed up real-world RL.\nReward classifiers are particularly useful in treating complex, dynamic tasks\u2014e.g., folding a t-shirt\u2014for which a\nprecise reward formulation is arbitrarily complex to obtain, or that do require significant shaping and are more easily\nlearned directly from demonstrations of success (e+) or failure (e\u2212) states, rather than from a precise formulation\nof rt, with a natural target for the reward classifier being r(s) = log c(e+ verts). Furthermore, Luo et al. (2025)\ndemonstrate the benefits of learning separate (1) forward and (2) backward controllers\u2014param",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4af16ca7f407414fad28adb2744daf4b": {
    "id": "parent_4af16ca7f407414fad28adb2744daf4b",
    "metadata": {
      "content": "(2025)\ndemonstrate the benefits of learning separate (1) forward and (2) backward controllers\u2014parametrized by separate\npolicies\u2014where (1) the former learns to execute a task to completion and (2) the latter learns to reset the environment\nto its initial state from terminal states, thereby aiding training in real-world episodic settings.\nLastly, in order to improve on the robustness of their approach to different goals while maintaing practical scalabil-\nity, Luo et al. (2025) introduced a modified state and action space, expressing proprioperceptive configurations q and\nactions q\u0307 in the frame of the end-effector pose at t = 0. Randomizing the initial pose of the end-effector (s0), Luo\net al. (2025) achieved a similar result to that of manually randomizing the environment at every timestep, but with\n\n23\n\n\n\nFigure 16 | (A) HIL-SERL allows for real-world training of high performance RL agents by building on top advancements\npresented by of SAC, RLPD and SERL. (B) Example of human interv",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_508b21ceb81d4846b69e0b3cb468a3b6": {
    "id": "parent_508b21ceb81d4846b69e0b3cb468a3b6",
    "metadata": {
      "content": "ents by building on top advancements\npresented by of SAC, RLPD and SERL. (B) Example of human intervention during a HIL-SERL training process on a real-world\nSO-100.\n\nthe benefit of maintaining the environment in the same condition across multiple training episodes, achieving higher\nscalability of their method thanks to the increased practicality of their approach.\nBuilding on off-policy deep Q-learning with replay buffers, entropy regularization for better exploration, expert\ndemonstrations to guide learning, and a series of tools and recommendations for real-world training using reward\nclassifiers (Figure 16), Luo et al. (2024) introduce human interactions during training, learning near-optimal policies\nin challenging real-world manipulation tasks in 1-2 hours.\nHuman-in-the-Loop, Sample Efficient Robot reinforcement Learning (HIL-SERL) (Luo et al., 2024) augments offline-\nto-online RL with targeted human corrections during training, and employs prior data to (1) train a reward classi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_bfac60e2d5904a588328abba5afe996c": {
    "id": "parent_bfac60e2d5904a588328abba5afe996c",
    "metadata": {
      "content": "with targeted human corrections during training, and employs prior data to (1) train a reward classifier\nand (2) bootstrap RL training on expert trajectories. While offline demonstrations provide the initial dataset seeding\nlearning and constraining early exploration, interactive, online corrections allow a human supervisor to intervene on\nfailure modes and supply targeted interventions, greatly aiding the learning process (Luo et al., 2024). Crucially,\nhuman intervention data is stored in both the offline and online replay buffers, differently from the autonomous\ntransitions generated at training time and stored in the online buffer only. In turn, given an intervention timestep\nk \u2208 (0, T ), length-K human intervention data {shuman\n\nk , ahuman\nk , rhuman\n\nk , shuman\nk+1 , }Kk=1 is more likely to be sampled\n\nthan the data generated online during training, providing stronger supervision to the agent while still allowing for\nautonomous learning. Empirically, HIL-SERL attains near-perfect",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_128b89787e3f491296c1175e662f01dc": {
    "id": "parent_128b89787e3f491296c1175e662f01dc",
    "metadata": {
      "content": "the agent while still allowing for\nautonomous learning. Empirically, HIL-SERL attains near-perfect success rates (99%+) on diverse manipulation\ntasks within 1-2 hours of training (Luo et al., 2024), underscoring how offline datasets with online RL can markedly\nimprove stability and data efficiency, and ultimately even allow real-world RL-training.\n\n3.2.1 Code Example: Real-world RL\nThis example shows how to use the HIL-SERL implementation supported by lerobot. This code example is organized\ninto four parts: we first show how to train a reward classifier from a custom set of demonstrations, then define\nthe Actor and Learner components, and finally, we bring them together in a complete script showing how to use\nHIL-SERL in practice.\nAt a higher level, the HIL-SERL architecture (Figure 17) relies on two main components:\n\n\u2022 An Actor, running a frozen policy network used to interact with the environment and obtain observations.\nObservations are used to both condition the frozen actor in se",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_40c4ec348fbb4465b763dbcd24730a0a": {
    "id": "parent_40c4ec348fbb4465b763dbcd24730a0a",
    "metadata": {
      "content": "environment and obtain observations.\nObservations are used to both condition the frozen actor in selecting the action to enact, and to form (st, at, rt, st+1)\ntransitions that are shared with the Learner. Rewards are inferred using a custom, learned reward classifier trained\non a dataset of offline demonstrations.\n\n\u2022 A Learner, used to optimize the policy\u2019s parameters \u03b8 for maximum expected return. The learner samples batches\n\n24\n\n\n\nFigure 17 | HIL-SERL is a SOTA RL algorithm for training control policies directly in the real-world. Its implementation in\nlerobot relies on a decoupled actor-learner architecture, communicating over processes (and possibly networks) with queues\nused to share (1) transitions (st, at, rt, st+1) and (2) parameters \u03b8.\n\nof offline data from online and offline buffers in equal proportion (Ball et al., 2023), and shares updated parameters\nwith the Actor.\n\nThe HIL-SERL architecture presented in this example can be exclusively run locally, but the implementation",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2444534a89734dc3a638d33178afbf4e": {
    "id": "parent_2444534a89734dc3a638d33178afbf4e",
    "metadata": {
      "content": "-SERL architecture presented in this example can be exclusively run locally, but the implementation in\nlerobot also allows the Actor and Learner to run on two separate machines connected by the network.\n\nCode 3: Training a Reward Classifier\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch3/01_reward_classifier.py\n\n1 import torch\n2\n3 from lerobot.datasets.lerobot_dataset import LeRobotDataset\n4 from lerobot.policies.factory import make_policy , make_pre_post_processors\n5 from lerobot.policies.sac.reward_model.configuration_classifier import RewardClassifierConfig\n6\n7 # Device to use for training\n8 device = \"mps\" # or \"cuda\", or \"cpu\"\n9\n\n10 # Load the dataset used for training\n11 repo_id = \"lerobot/example_hil_serl_dataset\"\n12 dataset = LeRobotDataset(repo_id)\n13\n14 # Configure the policy to extract features from the image frames\n15 camera_keys = dataset.meta.camera_keys\n16\n17 config = RewardClassifierConfig(\n18 num_cameras=len(camera_keys),\n19 device=device ,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_6ff17bcc6ceb436093f0dda2b88bc0a5": {
    "id": "parent_6ff17bcc6ceb436093f0dda2b88bc0a5",
    "metadata": {
      "content": "era_keys\n16\n17 config = RewardClassifierConfig(\n18 num_cameras=len(camera_keys),\n19 device=device ,\n20 # backbone model to extract features from the image frames\n21 model_name=\"microsoft/resnet -18\",\n22 )\n23\n24 # Make policy , preprocessor , and optimizer\n25 policy = make_policy(config , ds_meta=dataset.meta)\n26 optimizer = config.get_optimizer_preset (). build(policy.parameters ())\n27 preprocessor , _ = make_pre_post_processors(policy_cfg=config , dataset_stats=dataset.meta.stats)\n\n25\n\n\n\n28\n29\n30 # your HF username and model repo id for the reward classifier\n31 classifier_id = \"lerobot/reward_classifier_hil_serl_example\"\n32\n33 # Instantiate a dataloader\n34 dataloader = torch.utils.data.DataLoader(dataset , batch_size =16, shuffle=True)\n35\n36 # Training loop\n37 num_epochs = 5\n38 for epoch in range(num_epochs ):\n39 total_loss = 0\n40 total_accuracy = 0\n41 for batch in dataloader:\n42 # Preprocess the batch and move it to the correct device.\n43 batch = preprocessor(batch)\n44\n45 # Forward p",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_638b087abcef45acb496cd7edd96d6b9": {
    "id": "parent_638b087abcef45acb496cd7edd96d6b9",
    "metadata": {
      "content": "rocess the batch and move it to the correct device.\n43 batch = preprocessor(batch)\n44\n45 # Forward pass\n46 loss , output_dict = policy.forward(batch)\n47\n48 # Backward pass and optimization\n49 optimizer.zero_grad ()\n50 loss.backward ()\n51 optimizer.step()\n52\n53 total_loss += loss.item()\n54 total_accuracy += output_dict[\"accuracy\"]\n55\n56 avg_loss = total_loss / len(dataloader)\n57 avg_accuracy = total_accuracy / len(dataloader)\n58 print(\n59 f\"Epoch {epoch + 1}/{ num_epochs}, Loss: {avg_loss :.4f}, Accuracy: {avg_accuracy :.2f}%\"\n60 )\n61\n62 print(\"Training finished!\")\n63\n64 # You can now save the trained policy.\n65 policy.push_to_hub(classifier_id)\n\nCode 4: Defining the Actor\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch3/02_actor.py\n\n1 import multiprocessing as mp\n2 from queue import Empty\n3\n4 import torch\n5 from pathlib import Path\n6\n7 from lerobot.envs.configs import HILSerlRobotEnvConfig\n8 from lerobot.policies.sac.modeling_sac import SACPolicy\n9 from lero",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_fde54bd03e8742699047904c35bdcdc8": {
    "id": "parent_fde54bd03e8742699047904c35bdcdc8",
    "metadata": {
      "content": "s import HILSerlRobotEnvConfig\n8 from lerobot.policies.sac.modeling_sac import SACPolicy\n9 from lerobot.policies.sac.reward_model.modeling_classifier import Classifier\n\n10 from lerobot.rl.gym_manipulator import make_robot_env\n11 from lerobot.teleoperators.utils import TeleopEvents\n12\n13 MAX_EPISODES = 5\n14 MAX_STEPS_PER_EPISODE = 20\n15\n16 def make_policy_obs(obs , device: torch.device = \"cpu\"):\n17 return {\n18 \"observation.state\": torch.from_numpy(obs[\"agent_pos\"]). float (). unsqueeze (0).to(device),\n19 **{\n20 f\"observation.image .{k}\":\n21 torch.from_numpy(obs[\"pixels\"][k]). float (). unsqueeze (0).to(device)\n22 for k in obs[\"pixels\"]\n23 },\n24 }\n\n26\n\n\n\n25\n26 def run_actor(\n27 transitions_queue: mp.Queue ,\n28 parameters_queue: mp.Queue ,\n29 shutdown_event: mp.Event ,\n30 policy_actor: SACPolicy ,\n31 reward_classifier: Classifier ,\n32 env_cfg: HILSerlRobotEnvConfig ,\n33 device: torch.device = \"mps\",\n34 output_directory: Path | None = None\n35 ):\n36 \"\"\"The actor process - interacts with env",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_21ceea5252b34d71b0137284613a0bbf": {
    "id": "parent_21ceea5252b34d71b0137284613a0bbf",
    "metadata": {
      "content": "= \"mps\",\n34 output_directory: Path | None = None\n35 ):\n36 \"\"\"The actor process - interacts with environment and collects data.\n37 The policy is frozen and only the parameters are updated , popping the most recent ones\n38 from a queue.\"\"\"\n39 policy_actor.eval()\n40 policy_actor.to(device)\n41\n42 reward_classifier.eval()\n43 reward_classifier.to(device)\n44\n45 # Create robot environment inside the actor process\n46 env , teleop_device = make_robot_env(env_cfg)\n47\n48 try:\n49 for episode in range(MAX_EPISODES ):\n50 if shutdown_event.is_set ():\n51 break\n52\n53 obs , _info = env.reset ()\n54 episode_reward = 0.0\n55 step = 0\n56 episode_transitions = []\n57\n58 print(f\"[ACTOR] Starting episode {episode + 1}\")\n59\n60 while step < MAX_STEPS_PER_EPISODE and not shutdown_event.is_set ():\n61 try:\n62 new_params = parameters_queue.get_nowait ()\n63 policy_actor.load_state_dict(new_params)\n64 print(\"[ACTOR] Updated policy parameters from learner\")\n65 except Empty: # No new updated parameters available from lear",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2eb4741aa61b4b2dba6548af55fbbf40": {
    "id": "parent_2eb4741aa61b4b2dba6548af55fbbf40",
    "metadata": {
      "content": "ed policy parameters from learner\")\n65 except Empty: # No new updated parameters available from learner , waiting\n66 pass\n67\n68 # Get action from policy\n69 policy_obs = make_policy_obs(obs , device=device)\n70 # predicts a single action , not a chunk of actions!\n71 action_tensor = policy_actor.select_action(policy_obs)\n72 action = action_tensor.squeeze (0). cpu (). numpy ()\n73\n74 # Step environment\n75 next_obs , _env_reward , terminated , truncated , _info = env.step(action)\n76 done = terminated or truncated\n77\n78 # Predict reward\n79 policy_next_obs = make_policy_obs(next_obs , device=device)\n80 reward = reward_classifier.predict_reward(policy_next_obs)\n81\n82 if reward >= 1.0: # success detected! halt episode\n83 if not done:\n84 terminated = True\n85 done = True\n86\n87 # In HIL -SERL , human interventions come from the teleop device\n88 is_intervention = False\n89 if hasattr(teleop_device , \"get_teleop_events\"):\n90 # Real intervention detection from teleop device\n91 teleop_events = teleop_de",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c5f4975f5f4e4bcb9e00a0f43af488e2": {
    "id": "parent_c5f4975f5f4e4bcb9e00a0f43af488e2",
    "metadata": {
      "content": "et_teleop_events\"):\n90 # Real intervention detection from teleop device\n91 teleop_events = teleop_device.get_teleop_events ()\n92 is_intervention = teleop_events.get(TeleopEvents.IS_INTERVENTION , False)\n93\n94 # Store transition with intervention metadata\n\n27\n\n\n\n95 transition = {\n96 \"state\": policy_obs ,\n97 \"action\": action ,\n98 \"reward\": float(reward) if hasattr(reward , \"item\") else reward ,\n99 \"next_state\": policy_next_obs ,\n\n100 \"done\": done ,\n101 \"truncated\": truncated ,\n102 \"complementary_info\": {\n103 \"is_intervention\": is_intervention ,\n104 },\n105 }\n106\n107 episode_transitions.append(transition)\n108\n109 episode_reward += reward\n110 step += 1\n111\n112 obs = next_obs\n113\n114 if done:\n115 break\n116\n117 # Send episode transitions to learner\n118 transitions_queue.put_nowait(episode_transitions)\n119\n120 except KeyboardInterrupt:\n121 print(\"[ACTOR] Interrupted by user\")\n122 finally:\n123 # Clean up\n124 if hasattr(env , \"robot\") and env.robot.is_connected:\n125 env.robot.disconnect ()\n126 i",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a711d7b70eb543c5983f08ef4f9dd6ca": {
    "id": "parent_a711d7b70eb543c5983f08ef4f9dd6ca",
    "metadata": {
      "content": "Clean up\n124 if hasattr(env , \"robot\") and env.robot.is_connected:\n125 env.robot.disconnect ()\n126 if teleop_device and hasattr(teleop_device , \"disconnect\"):\n127 teleop_device.disconnect ()\n128 if output_directory is not None:\n129 policy_actor.save_pretrained(output_directory)\n130 print(f\"[ACTOR] Latest actor policy saved at: {output_directory}\")\n131\n132 print(\"[ACTOR] Actor process finished\")\n\nCode 5: Defining the Learner\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch3/03_learner.py\n\n1 import multiprocessing as mp\n2 from queue import Empty , Full\n3\n4 import torch\n5 import torch.optim as optim\n6\n7 from lerobot.policies.sac.modeling_sac import SACPolicy\n8 from lerobot.rl.buffer import ReplayBuffer\n9\n\n10 LOG_EVERY = 10\n11 SEND_EVERY = 10\n12\n13 def run_learner(\n14 transitions_queue: mp.Queue ,\n15 parameters_queue: mp.Queue ,\n16 shutdown_event: mp.Event ,\n17 policy_learner: SACPolicy ,\n18 online_buffer: ReplayBuffer ,\n19 offline_buffer: ReplayBuffer ,\n20 lr: f",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1f4955f7ef94468db2582d589fc81dbf": {
    "id": "parent_1f4955f7ef94468db2582d589fc81dbf",
    "metadata": {
      "content": "icy_learner: SACPolicy ,\n18 online_buffer: ReplayBuffer ,\n19 offline_buffer: ReplayBuffer ,\n20 lr: float = 3e-4,\n21 batch_size: int = 32,\n22 device: torch.device = \"mps\",\n23 ):\n24 \"\"\"The learner process - trains SAC policy on transitions streamed from the actor ,\n\n28\n\n\n\n25 updating parameters for the actor to adopt.\"\"\"\n26 policy_learner.train()\n27 policy_learner.to(device)\n28\n29 # Create Adam optimizer from scratch - simple and clean\n30 optimizer = optim.Adam(policy_learner.parameters (), lr=lr)\n31\n32 print(f\"[LEARNER] Online buffer capacity: {online_buffer.capacity}\")\n33 print(f\"[LEARNER] Offline buffer capacity: {offline_buffer.capacity}\")\n34\n35 training_step = 0\n36\n37 while not shutdown_event.is_set ():\n38 # retrieve incoming transitions from the actor process\n39 try:\n40 transitions = transitions_queue.get(timeout =0.1)\n41 for transition in transitions:\n42 # HIL -SERL: Add ALL transitions to online buffer\n43 online_buffer.add(** transition)\n44\n45 # HIL -SERL: Add ONLY human interven",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_132d0d44036048718f75baef5d636e8f": {
    "id": "parent_132d0d44036048718f75baef5d636e8f",
    "metadata": {
      "content": "ions to online buffer\n43 online_buffer.add(** transition)\n44\n45 # HIL -SERL: Add ONLY human intervention transitions to offline buffer\n46 is_intervention = \\\n47 transition.get(\"complementary_info\", {}). get(\"is_intervention\", False)\n48 if is_intervention:\n49 offline_buffer.add(** transition)\n50 print(\n51 f\"[LEARNER] Human intervention detected!\"\n52 f\"Added to offline buffer (now {len(offline_buffer )} transitions)\"\n53 )\n54\n55 except Empty:\n56 pass # No transitions available , continue\n57\n58 # Train if we have enough data\n59 if len(online_buffer) >= policy_learner.config.online_step_before_learning:\n60 # Sample from online buffer (autonomous + human data)\n61 online_batch = online_buffer.sample(batch_size // 2)\n62\n63 # Sample from offline buffer (human demonstrations only)\n64 offline_batch = offline_buffer.sample(batch_size // 2)\n65\n66 # Combine batches - this is the key HIL -SERL mechanism!\n67 batch = {}\n68 for key in online_batch.keys ():\n69 if key in offline_batch:\n70 batch[key] = tor",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_406d96dc0b564001bba79f21c4a98664": {
    "id": "parent_406d96dc0b564001bba79f21c4a98664",
    "metadata": {
      "content": "m!\n67 batch = {}\n68 for key in online_batch.keys ():\n69 if key in offline_batch:\n70 batch[key] = torch.cat([ online_batch[key], offline_batch[key]], dim =0)\n71 else:\n72 batch[key] = online_batch[key]\n73\n74 loss , _ = policy_learner.forward(batch)\n75\n76 optimizer.zero_grad ()\n77 loss.backward ()\n78 optimizer.step()\n79 training_step += 1\n80\n81 if training_step % LOG_EVERY == 0:\n82 print(\n83 f\"[LEARNER] Training step {training_step}, Loss: {loss.item ():.4f}, \"\n84 f\"Buffers: Online ={len(online_buffer )}, Offline ={len(offline_buffer )}\"\n85 )\n86\n87 # Send updated parameters to actor every 10 training steps\n88 if training_step % SEND_EVERY == 0:\n89 try:\n90 state_dict = {k: v.cpu() for k, v in policy_learner.state_dict (). items ()}\n91 parameters_queue.put_nowait(state_dict)\n92 print(\"[LEARNER] Sent updated parameters to actor\")\n93 except Full:\n94 # Missing write due to queue not being consumed (should happen rarely)\n\n29\n\n\n\n95 pass\n96\n97 print(\"[LEARNER] Learner process finished\")\n\nCode 6:",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_0fec7fd5e3514ff0bb248c863be62513": {
    "id": "parent_0fec7fd5e3514ff0bb248c863be62513",
    "metadata": {
      "content": "ed (should happen rarely)\n\n29\n\n\n\n95 pass\n96\n97 print(\"[LEARNER] Learner process finished\")\n\nCode 6: Using HIL-SERL\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch3/04_hil_serl.py\n\n1 import multiprocessing as mp\n2 import signal\n3 from typing import Callable\n4 from pathlib import Path\n5\n6 from lerobot.datasets.lerobot_dataset import LeRobotDataset\n7 from lerobot.datasets.utils import hw_to_dataset_features\n8 from lerobot.envs.configs import HILSerlProcessorConfig , HILSerlRobotEnvConfig\n9 from lerobot.policies.sac.configuration_sac import SACConfig\n\n10 from lerobot.policies.sac.modeling_sac import SACPolicy\n11 from lerobot.policies.sac.reward_model.modeling_classifier import Classifier\n12 from lerobot.rl.buffer import ReplayBuffer\n13 from lerobot.rl.gym_manipulator import make_robot_env\n14 from lerobot.robots.so100_follower import SO100FollowerConfig\n15 from lerobot.teleoperators.so100_leader import SO100LeaderConfig\n16\n17\n18 run_learner: Callable = ... # use/",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_29056debc3fa44deba27981786098870": {
    "id": "parent_29056debc3fa44deba27981786098870",
    "metadata": {
      "content": "obot.teleoperators.so100_leader import SO100LeaderConfig\n16\n17\n18 run_learner: Callable = ... # use/modify the functions defined earlier\n19 run_actor: Callable = ...\n20\n21 \"\"\"Main function - coordinates actor and learner processes.\"\"\"\n22\n23 device = \"mps\" # or \"cuda\" or \"cpu\"\n24 output_directory = Path(\"outputs/robot_learning_tutorial/hil_serl\")\n25 output_directory.mkdir(parents=True , exist_ok=True)\n26\n27 # find ports using lerobot -find -port\n28 follower_port = ...\n29 leader_port = ...\n30\n31 # the robot ids are used the load the right calibration files\n32 follower_id = ...\n33 leader_id = ...\n34\n35 # A pretrained model (to be used in -distribution !)\n36 reward_classifier_id = \"lerobot/reward_classifier_hil_serl_example\"\n37 reward_classifier = Classifier.from_pretrained(reward_classifier_id)\n38\n39 reward_classifier.to(device)\n40 reward_classifier.eval()\n41\n42 MAX_EPISODES = 5\n43 MAX_STEPS_PER_EPISODE = 20\n44\n45 # Robot and environment configuration\n46 robot_cfg = SO100FollowerConfig(po",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_6b412f5e72c64e00b57f88778b1914fa": {
    "id": "parent_6b412f5e72c64e00b57f88778b1914fa",
    "metadata": {
      "content": "S_PER_EPISODE = 20\n44\n45 # Robot and environment configuration\n46 robot_cfg = SO100FollowerConfig(port=follower_port , id=follower_id)\n47 teleop_cfg = SO100LeaderConfig(port=leader_port , id=leader_id)\n48 processor_cfg = HILSerlProcessorConfig(control_mode=\"leader\")\n49\n50 env_cfg = HILSerlRobotEnvConfig(robot=robot_cfg , teleop=teleop_cfg , processor=processor_cfg)\n51\n52 # Create robot environment\n53 env , teleop_device = make_robot_env(env_cfg)\n54\n55 obs_features = hw_to_dataset_features(env.robot.observation_features , \"observation\")\n56 action_features = hw_to_dataset_features(env.robot.action_features , \"action\")\n57\n58 # Create SAC policy for action selection\n59 policy_cfg = SACConfig(\n\n30\n\n\n\n60 device=device ,\n61 input_features=obs_features ,\n62 output_features=action_features ,\n63 )\n64\n65 policy_actor = SACPolicy(policy_cfg)\n66 policy_learner = SACPolicy(policy_cfg)\n67\n68 demonstrations_repo_id = \"lerobot/example_hil_serl_dataset\"\n69 offline_dataset = LeRobotDataset(repo_id=demons",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_da2680b266704d1bb8bcab9caf29ecc1": {
    "id": "parent_da2680b266704d1bb8bcab9caf29ecc1",
    "metadata": {
      "content": "ions_repo_id = \"lerobot/example_hil_serl_dataset\"\n69 offline_dataset = LeRobotDataset(repo_id=demonstrations_repo_id)\n70\n71 # Online buffer: initialized from scratch\n72 online_replay_buffer = ReplayBuffer(device=device , state_keys=list(obs_features.keys ()))\n73 # Offline buffer: Created from dataset (pre -populated it with demonstrations)\n74 offline_replay_buffer = ReplayBuffer.from_lerobot_dataset(\n75 lerobot_dataset=offline_dataset , device=device , state_keys=list(obs_features.keys ())\n76 )\n77\n78 # Create communication channels between learner and actor processes\n79 transitions_queue = mp.Queue(maxsize =10)\n80 parameters_queue = mp.Queue(maxsize =2)\n81 shutdown_event = mp.Event()\n82\n83\n84 # Signal handler for graceful shutdown\n85 def signal_handler(sig):\n86 print(f\"\\nSignal {sig} received , shutting down ...\")\n87 shutdown_event.set()\n88\n89\n90 signal.signal(signal.SIGINT , signal_handler)\n91 signal.signal(signal.SIGTERM , signal_handler)\n92\n93 # Create processes\n94 learner_process =",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_5acc80bb48364f6eb25797d193075950": {
    "id": "parent_5acc80bb48364f6eb25797d193075950",
    "metadata": {
      "content": "ler)\n91 signal.signal(signal.SIGTERM , signal_handler)\n92\n93 # Create processes\n94 learner_process = mp.Process(\n95 target=run_learner ,\n96 args=(\n97 transitions_queue ,\n98 parameters_queue ,\n99 shutdown_event ,\n\n100 policy_learner ,\n101 online_replay_buffer ,\n102 offline_replay_buffer ,\n103 ),\n104 kwargs ={\"device\": device}, # can run on accelerated hardware for training\n105 )\n106\n107 actor_process = mp.Process(\n108 target=run_actor ,\n109 args=(\n110 transitions_queue ,\n111 parameters_queue ,\n112 shutdown_event ,\n113 policy_actor ,\n114 reward_classifier ,\n115 env_cfg ,\n116 output_directory ,\n117 ),\n118 kwargs ={\"device\": \"cpu\"}, # actor is frozen , can run on CPU or accelerate for inference\n119 )\n120\n121 learner_process.start()\n122 actor_process.start()\n123\n124 try:\n125 # Wait for actor to finish (it controls the episode loop)\n126 actor_process.join()\n127 shutdown_event.set()\n128 learner_process.join(timeout =10)\n129\n\n31\n\n\n\n130 except KeyboardInterrupt:\n131 print(\"Main process interrup",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2a4c8ba8f1544f64b51c9114253054f4": {
    "id": "parent_2a4c8ba8f1544f64b51c9114253054f4",
    "metadata": {
      "content": "_process.join(timeout =10)\n129\n\n31\n\n\n\n130 except KeyboardInterrupt:\n131 print(\"Main process interrupted\")\n132 shutdown_event.set()\n133 actor_process.join(timeout =5)\n134 learner_process.join(timeout =10)\n135\n136 finally:\n137 if learner_process.is_alive ():\n138 learner_process.terminate ()\n139 if actor_process.is_alive ():\n140 actor_process.terminate ()\n\n3.2.2 Limitations of RL in Real-World Robotics: Simulators and Reward Design\nDespite the advancements in real-world RL training, training RL agents for real-world tasks still suffers from the\nfollowing limitations:\n\n\u2022 In those instances where real-world training experience is prohibitively expensive to gather (e.g., Tokamak\ncontrol (Degrave et al., 2022), Autonomous Stratospehere Navigation (Bellemare et al., 2020))in-simulation training\nis often the only viable option. However, high-fidelity simulators for real-world problems can be difficult to build\nand maintain, especially for contact-rich manipulation and tasks involving deformable",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4a7e60079b184591a159d031b858828a": {
    "id": "parent_4a7e60079b184591a159d031b858828a",
    "metadata": {
      "content": "icult to build\nand maintain, especially for contact-rich manipulation and tasks involving deformable or soft materials.\n\n\u2022 Reward design is a fundamental source of brittleness in real-world RL pipelines. While shaping dense rewards\nis often necessary to guide exploration in long-horizon tasks, the process is error-prone and heavily reliant on\nhuman expertise and intuition. Poorly tuned terms can lead to specification gaming or convergence to local optima,\nmaking reward shaping a critical challenge for applying RL in practice. Sparse rewards that only signal successful\ntrajectories can avoid these pitfalls but typically result in much slower learning due to reduced supervision.\n\nAdvances in learning to act from potentially large corpora of human demonstrations via Behavioral Cloning (BC)\naddress both of these concerns. Although suffering from an inherent suboptimality\u2014imitation learning can at most\nmatch the performance level of the demonstrator\u2014learning to reproduce expert demonstratio",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7eca520c58ad4747bc9647c4e9266b8e": {
    "id": "parent_7eca520c58ad4747bc9647c4e9266b8e",
    "metadata": {
      "content": "an at most\nmatch the performance level of the demonstrator\u2014learning to reproduce expert demonstrations via BC has proven\nincreasingly competitive and practical, bypassing the need for simulated environments and hard-to-define reward\nfunctions.\n\n32\n\n\n\nFigure 18 | (A) Average (with standard deviation) evolution of the actuation levels over the first 5 recorded episodes in\nlerobot/svla_so101_pickplace. Proprioperceptive states provide invaluable to determine the robot\u2019s state during an episode.\n(B) Camera frames are also recorded alongside measurements on the robot\u2019s state, capturing information about the robot\u2019s\ninteraction with its environment.\n\n4 Robot (Imitation) Learning\nThe best material model for a cat\nis another, or preferably the same\ncat\n\nNorbert Wiener\n\nTL;DR\n\nBehavioral Cloning provides a natural platform to learn from real-world interactions without the need to\ndesign any reward function, and generative models prove more effective than point-wise policies at dealing with\nmult",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_313925ac88644a1da40251b9d5f8e513": {
    "id": "parent_313925ac88644a1da40251b9d5f8e513",
    "metadata": {
      "content": "d function, and generative models prove more effective than point-wise policies at dealing with\nmultimodal demonstration datasets.\n\nLearning from human demonstrations provides a pragmatic alternative to the RL pipeline discussed in Section 3.\nIndeed, especially in real-world robotics, online exploration is typically costly and potentially unsafe, and designing\n(dense) reward signals is a brittle and task-specific process. Further, even success detection itself often requires bespoke\ninstrumentation, while episodic training demands reliable resets\u2014all factors complicating training RL algorithms\non hardware at scale. Behavioral Cloning (BC) sidesteps these constraints by casting control an imitation learning\nproblem, leveraging previously collected expert demonstrations to anchor the learned autonomous behavior. Most\nnotably, by learning-to-imitate, autonomous systems naturally adhere to the objectives, preferences, and success\ncriteria implicitly encoded in the data, which reduces early",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_331d3bb31cb847e3b2a0ebd90d9e79e6": {
    "id": "parent_331d3bb31cb847e3b2a0ebd90d9e79e6",
    "metadata": {
      "content": "he objectives, preferences, and success\ncriteria implicitly encoded in the data, which reduces early-stage exploratory failures and obviates hand-crafted reward\nshaping altogether.\n\nFormally, let D = {\u03c4 (i)}Ni=1 be a set of expert trajectories, with (\n\u03c4 (i) = { i) (i)\n\n(o T\nt , a i\n\nt )}t=0 representing the i-th length-Ti\ntrajectory in D, ot \u2208 O denoting observations (e.g., images and proprioception altogether), and at \u2208 A the expert\nactions. Typically, observations o \u2208 O consist of both image and proprioperceptive information, while actions a \u2208 A\nrepresent control specifications for the robot to execute, e.g. a joint configuration. Note that differently from Section 3,\nin the imitation learning context D denotes an offline dataset collecting N length-Ti reward-free (expert) human\ntrajectories \u03c4 (i), and not the environment dynamics. Similarily, in this section \u03c4 (i) represent a length-Ti trajectory\nof observation-action pairs, which crucially omits entirely any reward information. Fig",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d3662a986b674209b166d68a78e4781f": {
    "id": "parent_d3662a986b674209b166d68a78e4781f",
    "metadata": {
      "content": "i trajectory\nof observation-action pairs, which crucially omits entirely any reward information. Figure 18 graphically shows\ntrajectories in terms of the average evolution of the actuation on the 6 joints of a teleoperated SO-100 manipulator.\nNotice how proprioperceptive states are captured jointly with camera frames over the course of the recorded episodes,\nproviding a unified high-frame rate collection of both image and joint teleoperation data. Figure 19 shows (ot, at)-pairs\nfor the same dataset, with the actions performed by the human expert illustrated alongside the corresponding\nobservation. In principle, (expert) trajectories \u03c4 (i) can have different lengths since demonstrations might exhibit\nmulti-modal strategies to attain the same goal, resulting in multiple, different behaviors.\nBehavioral Cloning (BC) (Pomerleau, 1988) aims at producing synthetic behaviors by learning the mapping from\n\n33\n\n\n\nFigure 19 | Sample observations and action pairs over the course of a given traject",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_99ac8931b9ab419f9d0c9a6824770bcd": {
    "id": "parent_99ac8931b9ab419f9d0c9a6824770bcd",
    "metadata": {
      "content": "ping from\n\n33\n\n\n\nFigure 19 | Sample observations and action pairs over the course of a given trajectory recorded in lerobot/svla_so101_\npickplace. Observations, comprising of both proprioperceptive and visual information, are recorded alongside the configuration\nof a second, leader robot controlled by a human expert, providing complete information for regressing actions given observations.\n\nobservations to actions, and in its most natural formulation can be effectively tackled as a supevised learning problem,\nconsisting of learning the (deterministic) mapping f : O 7\u2192 A, at = f(ot) by solving\n\nminE(ot,at)\u223cp(\u2022)L(at, f(ot)), (18)\nf\n\ngiven an arbitrary risk function L : A\u00d7A 7\u2192 R, L(a, a\u2032).\nTypically, the expert\u2019s joint observation-action distribution p : O \u00d7A 7\u2192 [0, 1] is assumed to be unknown, in keeping\nwith a classic Supervised Learning (SL) framework3. However, differently from standard SL assumptions, the samples\ncollected in D\u2014realizations of the underlying p\u2014are not i.i.d., as expe",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a5dc7e2bbb834aeab8721e131698d657": {
    "id": "parent_a5dc7e2bbb834aeab8721e131698d657",
    "metadata": {
      "content": "SL assumptions, the samples\ncollected in D\u2014realizations of the underlying p\u2014are not i.i.d., as expert demonstrations are collected sequentially in\nthe form of trajectories. In practice, this aspect can be partially mitigated by considering pairs in a non-sequential\norder\u2014shuffling the samples in D\u2014so that the expected risk under p can be approximated using MC estimates,\nalthough these estimates may in general be less accurate. Another strategy to mitigate the impact of regressing\nover non-i.i.d. samples relies on the possibility of interleaving BC and data collection (Ross et al., 2011, DAgger),\naggregating multiple datasets iteratively. However, because we only consider the case where a single offline dataset D\nof trajectories is available and no more data can be collected, DAgger falls out of our scope.\nDespite the inherent challenges of learning from non-i.i.d. data, the BC formulation presents several operational\nadvantages in robotics. First, training happens offline and naturall",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_343824325da24f5da560424c6d1dbd8f": {
    "id": "parent_343824325da24f5da560424c6d1dbd8f",
    "metadata": {
      "content": "on presents several operational\nadvantages in robotics. First, training happens offline and naturally accomodates for expert, demonstration data,\nhereby severily limiting exploration risks by preventing the robot from performing dangerous actions altogether,\nby anchoring action in imitation. Second, reward design is entirely unnecessary in BC, as demonstrations already\nreflect human intent. The absence of rewards also prevents the risk of misalignment and specification gaming (reward\nhacking), otherwise inherent in purely reward-based RL (Heess et al., 2017). Third, because expert trajectories encode\nterminal conditions, success detection and resets are implicit in the dataset. Finally, empirical evidence suggests the\nperformance of BC scales naturally with growing corpora of demonstrations collected across tasks, embodiments, and\nenvironments. Nonetheless, BC can, in principle, only reproduce behaviors that are at best as good as those of the\ndemonstrator, and therefore offers no reme",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4d901d5e3f734be5bdcfab21c5777573": {
    "id": "parent_4d901d5e3f734be5bdcfab21c5777573",
    "metadata": {
      "content": "roduce behaviors that are at best as good as those of the\ndemonstrator, and therefore offers no remedy for the suboptimal decisions that humans may enact. This limitation is\nparticularly problematic in sequential decision-making tasks where expert demonstrations are scarce\u2013\u2014either because\ndata collection is costly or because human performance is inherently suboptimal. Yet, many robotics applications still\nbenefit from relatively inexpensive pipelines for collecting high-quality human-generated trajectories, justifying the\nuse of BC in such settings.\nWhile conceptually elegant, point-estimate policies f : O 7\u2192 A learned by solving eq. 18 have been observed to\nsuffer from (1) compounding errors (Ross et al., 2011) and (2) poor fit to multimodal distributions (Florence et al.,\n2022; Ke et al., 2020). Figure 20 illustrates these two key issues related to learning explicit policies (Florence\net al., 2022). Besides sequentiality in D, compounding errors due to covariate shift may also prove",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_513afd6c0c0644df93d772e7ae48b7bc": {
    "id": "parent_513afd6c0c0644df93d772e7ae48b7bc",
    "metadata": {
      "content": "et al., 2022). Besides sequentiality in D, compounding errors due to covariate shift may also prove catastrophic,\nas even small \u03f5-prediction errors 0 < \u2225\u00b5(ot) \u2212 at\u2225 \u2264 \u03f5 can quickly drive the policy into out-of-distribution states,\nincuring in less confident generations and thus compounding errors (Figure 20, left). Moreover, point-estimate policies\ntypically fail to learn multimodal targets, which are very common in human demonstrations solving real-world robotics\nproblems, as multiple trajectories can be equally as good towards the accomplishment of a goal (e.g., symmetric\ngrasps, Figure 20, right). In particular, unimodal regressors tend to average across modes, yielding indecisive or\n\n3Throughout, we will adopt the terminology and notation for SL used in Shalev-Shwartz and Ben-David (2014)\n\n34\n\n\n\nFigure 20 | Point-wise policies suffer from limitations due to (A) covariate shifts and (B) poor approximation of multimodal\ndemonstrations. (A) Small errors may drive the policy out of dis",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_deb0f64093674be3835fbe9268ed179e": {
    "id": "parent_deb0f64093674be3835fbe9268ed179e",
    "metadata": {
      "content": "B) poor approximation of multimodal\ndemonstrations. (A) Small errors may drive the policy out of distribution, incuring in a vicious circle ultimately resulting in\nfailure. (B) Both modes of reaching for a target object in the scene\u2014either left or right-first\u2014are equally as good and thus\nequally as likely to be present in a dataset of human demonstrations, ultimately resulting in multimodal demonstrations.\n\nFigure 21 | Intuitively, latent variable in a single latent model may contain information regarding the task being performed,\nwhich directly results in the likelihood of the same observation-action pair being different for two different tasks. When (A)\npicking a block the likelihood of a wide gripper\u2019s opening should be higher than narrower one, while it should be the opposite\nwhen (B) pushing the block.\n\neven unsafe commands (Florence et al., 2022). To address poor multimodal fitting, Florence et al. (2022) propose\nlearning the generative model p(o, a) underlying the samples in D,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b5da4ed692444fe782b024d18a2934c2": {
    "id": "parent_b5da4ed692444fe782b024d18a2934c2",
    "metadata": {
      "content": ", Florence et al. (2022) propose\nlearning the generative model p(o, a) underlying the samples in D, rather than explicitly learning a prediction function\nf : a = f(o).\n\n4.1 A (Concise) Introduction to GenerativeModels\nGenerative Models (GMs) aim to learn the stochastic process underlying the very generation of the data collected, and\ntypically do so by fitting a probability distribution that approximates the unknown data distribution, p. In keeping\nwith the GM literature, p(x) \u2190 P(x), x \u223c p. In the case of BC, the unknown data distribution p may represent\nthe expert\u2019s joint distribution over (o, a)-pairs. Thus, given a finite set of N pairs D = {(o, a)i}Ni=0 available as an\nimitation learning target (and thus assumed to be i.i.d.), GMs seek to learn a parametric distribution p\u03b8(o, a) such\nthat (1) new samples (o, a) \u223c p\u03b8(\u2022) resemble those stored in D, and (2) high likelihood is assigned to the observed\nregions of the unobservable p. Likelihood-based learning provides a principled train",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_690ddf9bb2f64d518ffc04a5d982378e": {
    "id": "parent_690ddf9bb2f64d518ffc04a5d982378e",
    "metadata": {
      "content": "to the observed\nregions of the unobservable p. Likelihood-based learning provides a principled training objective to achieve both goals,\nand it is thus extensively used in GMs (Prince, 2023).\n\n35\n\n\n\nFigure 22 | (A) The latent variable model in a robotics application regulates influence between observed (o, a) variables and\nan unobservable latent variable. (B) VAEs approximate exact latent variable models by means of variational inference.\n\n4.1.1 Variational Auto-Encoders\nA common inductive bias used in GM posits samples\u222b(o, a) are influenced from an unobservable latent variable z \u2208 Z,\nresulting in:\n\np(o, a) = p(o, a|z)p(z) (19)\nsupp(Z)\n\nIntuitively, in the case of observation-action pairs (o, a) for a robotics application, z could be interpreted as some high\nlevel representation of the underlying task being performed by the human demonstrator. In such case, treating p(o, a)\nas a marginalization over supp(Z) of the complete joint distribution p(o, a, z) natively captures the effect diff",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_11851818eb744f628b9add1a73a0e772": {
    "id": "parent_11851818eb744f628b9add1a73a0e772",
    "metadata": {
      "content": "ization over supp(Z) of the complete joint distribution p(o, a, z) natively captures the effect different\ntasks have on the likelihood of observation-action pairs. Figure 21 graphically illustrates this concept in the case of a\n(A) picking and (B) pushing task, for which, nearing the target object, the likelihood of actions resulting in opening\nthe gripper\u2014the higher q6, the wider the gripper\u2019s opening\u2014should intuitively be (A) high or (B) low, depending\non the task performed. While the latent space Z typically has a much richer structure than the set of all actual\ntasks performed, eq. 19 still provides a solid framework to learn joint distribution conditioned on unobservable yet\nrelevant factors. Figure 22 represents this latent-variable framework in the context of a robotics application: the true,\nz-conditioned generative process assigns likelihood p((o, a)|z) to the single (o, a)-pair. Using Bayes\u2019 theorem, one can\nreconstruct the posterior distribution on supp(Z), q\u03b8(z|o, a) from t",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b602d96c3df9465e992c2d8475cf90da": {
    "id": "parent_b602d96c3df9465e992c2d8475cf90da",
    "metadata": {
      "content": ". Using Bayes\u2019 theorem, one can\nreconstruct the posterior distribution on supp(Z), q\u03b8(z|o, a) from the likelihood p\u03b8(o, a|z), prior p\u03b8(z) and evidence\np\u03b8(o, a). VAEs approximate the latent variable model presented in eq. 19 using an approximate posterior q\u03d5(z|o, a)\nwhile regressing parameters for a parametric likelihood, p\u03b8(o, a|z) (Figure 22).\nGiven a dataset D consisting of N i.i.d. observation-action pairs, the log-likelihood of all datapoints under \u03b8 (in\nBayesian terms, the evidence p\u03b8(D)) can be written as:\n\n\u2211N\nlog p\u03b8(D) = log p\u03b8((o, a)i) (20)\n\n\u2211i=0\n\nN \u222b\n= log p\u03b8((o, a)i|z)p(z) (21)\n\n\u2211i=0 supp(Z)\n\nN \u222b\nq\u03b8(z|(o, a)i)\n\n= log \u00b7 p\u03b8((o, a)i|z)p(z) (22)\ni=0 supp(Z) q\u03b8(z|[(o, a)\u2211 i)\n\nN ]\np(z)\n\n= log Ez\u223cq \u00b7 p\n\u03b8(\u2022|(o,a)i) \u03b8((o, a)i|z) , (23)\n\nq (o, a)\ni=0 \u03b8(z| i)\n\nwhere we used eq. 19 in eq. 20, multiplied by 1 = q\u03b8(z|(o,a)i)\nq and used the definition of expected value in\n\u03b8(z|(o,a) in eq. 21,\n\ni)\neq. 23.\nIn the special case where one assumes distributions to be tractable, p\u03b8(D) is typically",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2a7c86936acf4e19bfbe2d073e8d39b1": {
    "id": "parent_2a7c86936acf4e19bfbe2d073e8d39b1",
    "metadata": {
      "content": "i)\neq. 23.\nIn the special case where one assumes distributions to be tractable, p\u03b8(D) is typically tractable too, and max\u03b8 log p\u03b8(D)\nprovides a natural target for (point-wise) infering the unknown parameters \u03b8 of the generative model. Unfortunately,\neq. 23 is rarely tractable when the distribution p is modeled with approximators such as neural networks, especially\nfor high-dimensional, unstructured data.\nIn their seminal work on Variational Auto-Encoders (VAEs), Kingma and Welling (2013) present two major contribu-\ntions to learn complex latent-variable GMs from unstructured data, proposing (1) a tractable, variational lower-bound\n\n36\n\n\n\nto eq. 23 as an optimization target to jointly learn likelihood and posterior and (2) using high-capacity function\napproximators to model the likelihood p\u03b8(o, a|z) and (approximate) posterior distribution q\u03d5(z|o, a) \u2248 q\u03b8(z|o, a).\nIn particular, the lower bound on eq. 23 (Evidence LOwer Bound, ELBO) can be derived from eq. 23 applying\nJensen\u2019s inequal",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f809dc38f093413aadf41b2cc810993a": {
    "id": "parent_f809dc38f093413aadf41b2cc810993a",
    "metadata": {
      "content": "er bound on eq. 23 (Evidence LOwer Bound, ELBO) can be derived from eq. 23 applying\nJensen\u2019s inequality\u2014logE[\u2022] \u2265 E[log(\u2022)]\u2014yielding:\n\n\u2211N ( [ ] [ ( )])\np(z)\n\nlog p\u03b8(D) \u2265 Ez\u223cq \u2022|(o,a) log p ((o, a)\n\u03b8( i) \u03b8 i|z) + Ez\u223cq\u03b8(\u2022|(o,a) ) log (24)\n\ni q\u03b8(z|(o, a) )\u2211i=0\n\nN ( [ ] [ ]) i\n\n= Ez\u223cq\u03b8(\u2022|(o,a) ) log p\u03b8((o, a)i|z) \u2212D\ni KL q\u03b8(z|(o, a)i)\u2225p(z) (25)\n\ni=0\n\nThe true, generally intractable, posterior q\u03b8(z|o, a) prevents computing both the expectation and KL divergence\nterms in eq. 25, and therefore Kingma and Welling (2013) propose deriving the ELBO using an approximate posterior\nq\u03d5(z|o, a), resulting in the final, tractable, ELBO objective,\n\n\u2211N ( [ ] [ ])\nELBOD(\u03b8, \u03d5) = Ez\u223cq \u2022|(o,a) log p ((o, a) (z) (26)\n\n\u03d5( i) \u03b8 i|z) \u2212DKL q\u03d5(z|(o, a)i)\u2225p\ni=0\n\nFrom Jensen\u2019s inequality, maximizing ELBO results in maximizing the log-likelihood of the data too, thus providing a\nnatural, tractable optim\n\nin eq. 26, w(ization target. Ind\nhile the KL-diver)eed, expectations can be estimated using MC estimates from the",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_743a4f4d65fa4fdc944da980910f11c7": {
    "id": "parent_743a4f4d65fa4fdc944da980910f11c7",
    "metadata": {
      "content": "zation target. Ind\nhile the KL-diver)eed, expectations can be estimated using MC estimates from the learned\n\ndistributions gence term can typically be computed in closed-form (1) modeling q\u03d5 as a\nGaussian q\u03d5(z|o, a) = N \u00b5\u03d5(o, a),\u03a3\u03d5(o, a) with learned mean vector \u00b5\u03d5(o, a) and learned variance-covariance matrix\n\u03a3\u03d5(o, a) and (2) imposing a standard Gaussian prior on the latent space, p(z) = N (0, I).\nAn intuitive explanation of the learning dynamics of VAEs can be given considering the equivalent case of minimizing\nthe negative ELBO, which admits the particularly interpretable factorization (considering, without loss of generality,\nonly one (o, a) \u223c D):\n\nmin\u2212ELBO(o,a)\u223cD(\u03b8, \u03d5) = minLrec(\u03b8) [+ Lreg(\u03d5),\n\u03b8,\u03d5 ] (27)\n\n\u03b8,\u03d5\n\nLrec(\u03b8) = Ez\u223cq[\u03d5(\u2022|o,a) log p\u03b8(o, a|z) (28)\nLreg ]\n\n(\u03d5) = DKL q\u03d5(z|o, a)\u2225p(z) . (29)\n\nFor any given (o, a) pair, the expected value term in eq. 28 is typically computed via MC estimates, resulting in\n\n[ ] \u2211n\n\u2212 1\nEz\u223cq (\u2022|o,a) log p\n\n\u03d5 \u03b8(o, a|z) = Lrec \u2248 \u2212 log p\u03b8(o, a|zi).\nn\n\ni",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_8d1bec60a8344b50bdd6e19c0a482ca4": {
    "id": "parent_8d1bec60a8344b50bdd6e19c0a482ca4",
    "metadata": {
      "content": "estimates, resulting in\n\n[ ] \u2211n\n\u2212 1\nEz\u223cq (\u2022|o,a) log p\n\n\u03d5 \u03b8(o, a|z) = Lrec \u2248 \u2212 log p\u03b8(o, a|zi).\nn\n\ni=0\n\nAssuming p\u03b8(o, a|z) to be parametrized with an isotropic Gaussian distribution with mean \u00b5 d\n\u03b8(z) \u2208 R and variance\n\n\u03c32, the log-likelihood thus simplifies to:\n\n\u2225 \u2225 \u2211n \u2225\nlog p(o, a| 1\n\nz \u2225\ni) = \u2212 (o, a)\u2212 \u00b5 \u22252 \u2225 \u2225\n\n\u03b8(zi) \u2212 d\nlog(2\u03c0\u03c32) =\u21d2 Lrec \u2248 1\n\n(o, a)\u2212 \u00b5\n2\u03c32 2 \u03b8(z \u22252\n\ni)\n2 n 2\n\ni=0\n\nIn practice, it is common to approximate the learned likelihood p\u03b8(o, a|z) with a parametric distribution (e.g.,\nGaussian) whose parameters are given by a learned coefficient vector derived from \u00b5\u03b8(z), z \u223c p(\u2022). Under this\nformulation, learning a VAE amounts to (1) reconstructing the examples in D by minimizing (1) the reconstruction\nloss Lrec\u2014a standard supervised learning objective for regression\u2014while (2) regularizing the latent representation by\nminimizing Lreg. The latter enforces information compression, since with the common prior choice p(z) = N (0, I) in\neq. 29, the regularizer constrains the po",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_fd63fdaef7e9407cbe1a2651767ed7bc": {
    "id": "parent_fd63fdaef7e9407cbe1a2651767ed7bc",
    "metadata": {
      "content": "ion, since with the common prior choice p(z) = N (0, I) in\neq. 29, the regularizer constrains the posterior and thereby limits the expressivity of q\u03d5(z|o, a).\n\n4.1.2 DiffusionModels\nVAEs approximate probability distributions via a single latent variable model, assuming the underlying unknown\ndistribution can be factored\u222baccording to eq. 19, and solve the variational-inference problem of jointly learning\nthe likelihood p\u03b8 and (approximate) posterior q\u03d5 for such model. In that, the unknown data distribution p(o, a) is\neffectively approximated via p(z)p (o, a|z), and the underlying generative process reproduced by (1) sampling a\n\nZ \u03b8\n\n37\n\n\n\nFigure 23 | HMLV models posit the data generation process is influenced by a stack of Markov-dependent latent variables,\nwith samples from the posterior distribution being progressively higher up in the hierarchy.\n\nlatent variable and (2) learning to decode it into a high-likelihood sample under the (unknown) p(o, a). Diffusion\nModels (DMs) (Ho et al.,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d1b53f7d4d9c42cb92db537cdf650333": {
    "id": "parent_d1b53f7d4d9c42cb92db537cdf650333",
    "metadata": {
      "content": "ode it into a high-likelihood sample under the (unknown) p(o, a). Diffusion\nModels (DMs) (Ho et al., 2020) are another class of GMs which treat the similar problem of approximating an\nunderlying unknown data distribution\u2014variational inference\u2014by partially extending VAEs to the case where multiple\nlatent variables influence each other and the generative process underlying o, a itself. In particular, DMs posit the\ngenerative process can be decomposed to a series of piece-wise (Markovian) interactions between (latent) variables\n(Figure 23), resulting in \u222b \u222b \u222b\n\np(\ufe38o\ufe37,\ufe37a\ufe38) = . . . p(z0, z1, . . . zT ) (30)\nsupp(Z0) supp(Z1) supp(ZT )\n\n=z0 \u220fT\np(z0, z1, . . . zT ) = p(zT ) p(zt\u22121|zt), (31)\n\nt=1\n\nwhere we explicitly showed the marginalization over the multiple latents in eq. 30, and used the law of conditional\nprobability and Markov property in eq. 31. Also, for ease of notation, we will refer to observation-action pairs o, a as\nz0.\nSimilar to VAEs, it is generally not possible to assign an ex",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a616da460b9947259f919e8df76ecb2d": {
    "id": "parent_a616da460b9947259f919e8df76ecb2d",
    "metadata": {
      "content": "o observation-action pairs o, a as\nz0.\nSimilar to VAEs, it is generally not possible to assign an exact interpretation to the latent variables. Nevertheless, a\nreasonable application-driven intuition is that Hierarchical Markov Latent Variable (HMLV) models, by capturing\nhierarchical and decoupled interactions among latent variables, can reflect the different resolutions at which conditioning\nfactors intervene. For example, in a robotics setting, one might naturally distinguish between high-level trajectory\nplanning (higher up in the hierarchy, t\u2192 T ) and fine-grained motion adjustments (closer to empirical observations,\nt\u2192 0). In that, HMLV models thus provide a framework to perform variational inference via multiple, sequential\nsampling steps from different higher level distributions instead of approximating the generative process with a\nsingle-latent varia\u221able model. DMs are a particular instantiation of HMLV models for which the posterior is fixed to\nq(zt|zt\u22121) = N (z 1\u2212 \u03b2t, \u03b2tI),",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_dfd136eb27054650a55009d8b3240db8": {
    "id": "parent_dfd136eb27054650a55009d8b3240db8",
    "metadata": {
      "content": "lar instantiation of HMLV models for which the posterior is fixed to\nq(zt|zt\u22121) = N (z 1\u2212 \u03b2t, \u03b2tI), for a given \u03b2t \u2208 R+\n\nt . In practice, \u03b2t is used to iteratively reduce the signal-to-noise\nratio along the latents\u2019 hierarchy, similarily to how a diffusion process influences the information of a physical system.\nJust like VAEs, DMs attemp to learn to reproduce an underlying data distribution p(o, a) given a collection of\ni.i.d. samples approximating the model posited to have generated the data in the first place (eq. 30). Similarily to\nVAEs, DMs approximate the process of sampling from the unknown p(o, a) by (1) sampling from an easy-to-sample\ndistribution (e.g., Gaussian) and (2) learning to reconstruct high-likelihood samples under the unknown distribution.\nHowever, in stark contrast with VAEs, the easy-to-sample distribution contains no mutual information regarding the\ndata distribution p(o, a). Crucially, as no information from the sample (o, a) (denoted as z0 \u2261 (o, a) for simplici",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4ce5bebb5def4b8e870ea3697d574abf": {
    "id": "parent_4ce5bebb5def4b8e870ea3697d574abf",
    "metadata": {
      "content": "on p(o, a). Crucially, as no information from the sample (o, a) (denoted as z0 \u2261 (o, a) for simplicity of\nnotation) is assumed to be propagated throughout the chain of latents, the posterior q(zt|zt\u22121) assumes a relatively\namicable structure in DMs, reducing complexity. The true likelihood p(zt\u22121|zt) is instead typically approximated using\nthe parametrization p\u03b8(zt\u22121|zt). In that, the information contained in the unknwon data distribution is reconstructed\nvia a process in which samples from a fixed distribution are iteratively turned into (ideally) high-likelihood samples\nunder p(o, a)\u2014a process referred to as denoising.\n\n38\n\n\n\nUnder such model\u222b, we can express the log-likelihood of an arbitrary sample z0 as:\n\nlog p\u03b8(z0) = log p\u03b8(z\ufe380, z1, z\ufe372\ufe37, . . . zT\ufe38) (32)\n\n\u222bsupp(Z1)\u00d7supp(Z2)\u00d7\u00b7\u00b7\u00b7\u00d7supp(ZT )\nz0:T\n\np\u03b8(z0:T ) \u00b7 q(z1:T |z0)\n= log [ ] (33)\n\nsupp(Z1:T ) q(z1:T |z0)\np\u03b8(z0:T )\n\n= logEz1:T\u223cq(\u2022[|z0) (34)\nq(z1:T |z0) ]\n\n\u2265 p\u03b8(z0:T )Ez1:T\u223cq(\u2022|z log\n0)[ (35)\n\nq(z1:T\u220f|z0)\u220f T ]\np(zT ) t= p\n\n= Ez1:T",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a2e55f273f954ac99c4398ae50af3c99": {
    "id": "parent_a2e55f273f954ac99c4398ae50af3c99",
    "metadata": {
      "content": "[|z0) (34)\nq(z1:T |z0) ]\n\n\u2265 p\u03b8(z0:T )Ez1:T\u223cq(\u2022|z log\n0)[ (35)\n\nq(z1:T\u220f|z0)\u220f T ]\np(zT ) t= p\n\n= Ez1:T\u223cq(\u2022|z log 1 \u03b8(zt\u22121|zt)\n0)[ (36)\n\nT\nt=1 q(zt|zt\u2212\u220f1)T\n\nt=2 p\u03b8(zt\u22121|zt)\n\n[ \u220f ]\np(zT ) \u00b7 p\u03b8(z0|z1)\n\n= Ez1:T\u223cq(\u2022|z lo\n0) g (\n\nT\u2212 37)\n1\n\nq(zT |zT\u22121) t=1 q(zt|zt\u22121)\n\np(\n= Ez1:T\u223cq(\u2022|z log\n\n0) \u220f\u220fT\u22121 ]\nzT ) \u00b7 p\u03b8(z0|z1) t=1 p\u03b8(zt|zt+1)\n\n[ T\u2212 (38)\nq(zT | 1\n\nzT\u22121) ]t=1 q(zt|zt\u22121) [ T\u220f\u22121 ]\np(zT ) \u00b7 p\u03b8(z0|z1) p\u03b8(zt|zt+1)\n\n= Ez1:T\u223cq(\u2022|z log\n0) + Ez\n\nq(zt|z 1:T\u223cq(\u2022|z log (39)\nt\u22121)\n\n0) q(z |\nt=1 t z[ ] [ ] t\u22121)\n\nT\u2211\u22121 [ ]\np(zT ) p\u03b8(zt|z +1)\n\n= Ez1:T\u223cq(\u2022|z l g (z | ) E\n0) o p\u03b8 0 z1 + z1:T\u223cq(\u2022|z og\n\n0) l + E t\nT\u223cq(\u2022|z l g\n\n0) o (40)\nq(z\n\n[ t|z] [ q(zT | z\nz 1:\nT\u22121) ] t\u2211=1 t\u22121)\n\nT\u22121 [ ]\np\n\nE \u03b8(zt|zt+1)\n= Ez1\u223cq(\u2022|z l g p (z\n\n0) o \u03b8 0|\np(zT )\n\nz1) + EzT\u2212 lo\n1:T\u223cq(\u2022|z z log\n\n0) g +\nq(zT |zT\u22121)\n\nt\u22121:t+1\u223cq(\u2022|z0) q(zt|zt=1 t\u22121)\n\n[ ] (41)\n=\u2211Ez1\u223cq(\u2022|z0) log p\u03b8(z0|z1[)\u2212 EzT\u22121\u223cq(\u2022|z0) DKL(q(zT |z]T\u22121)\u2225p(zT )) (42)\n\nT\u22121\n\n\u2212 E(zt\u22121,zt+1)\u223cq(\u2022|z0) DKL(q(zt|zt\u22121)\u2225p\u03b8(zt|zt+1)) ,\nt=1\n\nwhere we: used eq. 30 and multiplied by 1",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_37990a0e98c34addbe6c90d14d58ab78": {
    "id": "parent_37990a0e98c34addbe6c90d14d58ab78",
    "metadata": {
      "content": "\u2212 E(zt\u22121,zt+1)\u223cq(\u2022|z0) DKL(q(zt|zt\u22121)\u2225p\u03b8(zt|zt+1)) ,\nt=1\n\nwhere we: used eq. 30 and multiplied by 1 = q(z1:T |z0)\nq(z1:T |z0) in eq. 33; used Jensen\u2019s inequality in eq. 35; used the law of\n\nconditional probability for both numerator and denominator in eq. 36; stepped forward and backward the products in\nthe numerator and denominator products in eq. 37, respectively; reindexed the product terms in eq. 38; removed\nout-of-expectation variables in eq. 41; used the defintion of KL-divergence in eq. 42. In turn, eq. 42 provides an\noptimization target to learn p\u03b8 solving max\u03b8 log p\u03b8(D).\nIn their seminal work on using DMs for variational inference, Ho et al. (2020) introduce major contributions regarding\nsolving min\u03b8 \u2212 log p\u03b8(z0). In par\u221aticular, Ho et al. (2020) exclusively adopt a fixed, isotropic Gaussian posterior\nin the form of q(zt|zt\u22121) = N ( 1\u2212 \u03b2tzt\u22121, \u03b2tI). The choice of adopting Gaussians has profound implications\non the generative process modeled. Indeed, under the (mild) assumptio",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1f31337d0d2447e680df8ddf4275b220": {
    "id": "parent_1f31337d0d2447e680df8ddf4275b220",
    "metadata": {
      "content": "ians has profound implications\non the generative process modeled. Indeed, under the (mild) assumption that the variance is sufficiently small\n\u03b2t \u2264 \u03b7, \u03b7 \u2208 R+, Sohn et al. (2015) proved that the likelihood p(zt\u22121|zt) is Gaussian as well, which allows for the\nparticularly convenient parametrization of the approximate likelihood p\u03b8(zt\u22121|zt) = N (\u00b5\u03b8(zt, t),\u03a3\u03b8(zt, t)), t \u2208 [1, T ],\nas well as for closed\u220f-form tractability of the KL-divergence terms in eq. 42. Further, the po\u221asterior\u2019s structure also\nenables the analytical description of the distribution of the t-th latent variable, q(zt|z0) = N ( \u03b1\u0304tz0, (1\u2212 \u03b1\u0304t)I), with\n\nt\n\u03b1t = 1\u2212 \u03b2t, \u03b1\u0304t = k=1 \u03b1k, conveniently preventing iterative posterior sampling simplifying computing eq. 42. It\nfollows:\n\nT\u2211\u22121\n\n\u2207\u03b8 log p\u03b8(z0) = Ez1\u223cq(\u2022|z0)\u2207\u03b8 log p\u03b8(z0|z1)\u2212 Ezt\u22121,zt+1\u223cq(\u2022|z0)\u2207\u03b8DKL(q(zt|zt\u22121)\u2225p\u03b8(zt|zt+1), (43)\nt=1\n\nwhere the former term is equivalent to the reconstruction term in eq. 27 and the latter term can be obtained in closed\nform.\nBesides mathematica",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b35157ec96484cc4bfafbb1adbd05a11": {
    "id": "parent_b35157ec96484cc4bfafbb1adbd05a11",
    "metadata": {
      "content": "econstruction term in eq. 27 and the latter term can be obtained in closed\nform.\nBesides mathematical tractability of eq. 43, adopting Gaussian posteriors allows for a particularly intuitive inter-\npretation of the training dynamics of DMs (Permenter and Yuan, 2024). As the hierarchical latent variables are\n\n39\n\n\n\nFigure 24 | DMs iteratively corrupt samples (left) from an unknown distribution into a quasi-standard Gaussian (center),\nlearning the displacement field (right) that permits to reconstruct samples from the unknown target distribution by iteratively\ndenoising samples of a tractable, easy-to-sample distribution.\n\n40\n\n\n\nFigure 25 | A joint action-observation distribution, in the simplified case where the observation is the elbow-flex actuation in\na SO-100, and the action is the recorded position for the same joint from the teleoperator arm. The motion recorded being\nteleoperated, the points distribute along a the diagonal.\n\nrepeatedly corrupted by applying increasingly more Gaus",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_84fcbf85065649d4a9accc2cc9040adc": {
    "id": "parent_84fcbf85065649d4a9accc2cc9040adc",
    "metadata": {
      "content": "the points distribute along a the diagonal.\n\nrepeatedly corrupted by applying increasingly more Gaussian noise, they progressively lose information about the\noriginal (unknown) sample z0, converging toward a standard Gaussian which eventually contains no information at all\n(Figure 24). Figure 24 illustrates this process on a simplified, bidimensional observation-action distribution, where we\nconsidered o = q2 and a = qh2 , with q2 denoting the robot\u2019s elbow flex actuation and qh2 the corresponding human\nteleoperator\u2019s elbow flex. Because the recorded behavior is teleoperated, measurements mostly distribute along the\nline a = o+ \u03b7, \u03b7 \u223c N(0, 1), with \u03b7-variability accouting for minor control inconsistencies (Figure 25). Notice how\ncorrupted samples distribute differently from the most reasonable structure a \u2243 o, further underscoring how diffusion\ncorrupts both the individual samples and the global distribution (Figure 24, left and center). In this, using Gaussian\nposteriors\u2014i.e., adding",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c4d05fb34a7440288f3eb0fe77703a21": {
    "id": "parent_c4d05fb34a7440288f3eb0fe77703a21",
    "metadata": {
      "content": "e global distribution (Figure 24, left and center). In this, using Gaussian\nposteriors\u2014i.e., adding Gaussian noise\u2014effectively simulates a Brownian motion for the elements in the distribution\u2019s\nsupport (in Figure 24, O\u00d7A), whereby information diffuses away from the samples. Comparing the diffused samples\nto the original data points, one can derive an estimate of the total displacement induced by the diffusion process,\nand, under the assumption that the likelihood of the totally diffused samples is low under the original unknown data\ndistribution, one can effectively approximate the unkwown distribution by learning to reverse such displacement. This\nkey intuition allows to wr[ite a simplified training objectiv\n\n\u221a \u221a ]e4:\n\nL(\u03b8) = Et,z0,\u03f5 \u2225\u03f5\u2212 \u03f5\u03b8( \u03b1\u0304tz0 + \u03f5 1\u2212 \u03b1\u0304t, t)\u22252 , t \u223c U({1, . . . , T}), z0 \u223c D, \u03f5 \u223c N (0, I). (44)\n\nIn this simplified (minimization) objective, the optimization process differs from eq. 42 in that, rather than maximizing\np\u03b8 directly, the parameters \u03b8 of the pairwise lik",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_440da83f2fe64a3f84fa8a802222ac35": {
    "id": "parent_440da83f2fe64a3f84fa8a802222ac35",
    "metadata": {
      "content": "iffers from eq. 42 in that, rather than maximizing\np\u03b8 directly, the parameters \u03b8 of the pairwise likelihood p\u03b8(zt\u22121|zt) are adjusted to predict the total displacement \u03f5 for\na randomly long (t \u223c U({1, . . . , T})) diffusion process starting from a sample of the target distribution.\nBy learning the total displacement from a generally, uninformative corrupted sample obtained diffusing information\nand a sample from an unknown distribution Ho et al. (2020) show that one can approximate the underlying distribution\nreversing the displacement, denoising samples. Interestingly, under the hypothesis that real-world data belongs to a\nsingle, higher-dimensional manifold (Manifold Hypothesis), Permenter and Yuan (2024) show that diffusion learns the\ngradient of a distance function from any off-point manifold (such as perturbed, uniformative samples), and the data\nmanifold itself. Following this gradient\u2014i.e., denoising a sample from an uninformative distribution\u2014corresponds to\nprojecting back into",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_28d0e6522627494eaf16d03273d349af": {
    "id": "parent_28d0e6522627494eaf16d03273d349af",
    "metadata": {
      "content": "ent\u2014i.e., denoising a sample from an uninformative distribution\u2014corresponds to\nprojecting back into the manifold, yielding a procedure to sample from unknown distributions by means of Euclidean\nprojection. Indeed, under the assumption that p\u03b8(zt\u22121|zt) is Gaussian, sampling zt\u22121 \u223c p\u03b8(\u2022|zt) corresponds to\ncomputing: ( )\n\n1 \u03b2\nzt\u22121 \u221a t\n\n= zt \u2212 \u221a \u03f5\u03b8(zt, t) + \u03c3t\u03f5, \u03f5 \u223c N (0, I), (45)\n\u03b1t 1\u2212 \u03b1\u0304t\n\nthus showing that the lower-level latent variables in a DM can be obtained by iteratively removing noise from the\none-step higher order variable, using the noise regressor \u03f5\u03b8(zt, t) learned minimizing eq. 44.\n\n4.1.3 FlowMatching\nThe posterior parametrization adopted by DMs proved traditionally effective, yet it raised concerns circa its efficiency\nat inference time, where a possibly large number (hundreds) of compute-expensive denoising steps are needed in\norder to recover a sample from the target distribution. Flow Matching (FM) (Lipman et al., 2023) extends DMs\n\n4See Luo (2022, \"Three equivalent inte",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ee2c9d69c12f4b10820383e0ae0d09c2": {
    "id": "parent_ee2c9d69c12f4b10820383e0ae0d09c2",
    "metadata": {
      "content": "bution. Flow Matching (FM) (Lipman et al., 2023) extends DMs\n\n4See Luo (2022, \"Three equivalent interpretations\") for a complete derivation\n\n41\n\n\n\nFigure 26 | Probability distributions can be modified differently by applying different vector fields, inducing different\nflows of mass a\u221across \u221athe same support (top versus bottom, using two different time-invariant 2D-fields u1(x, y) = (x, 0) and\nu2(x, y) = (x/ 2, y/ 2)). Notice time flows continuously in [0, 1]. FM models learn to approximate a target vector field,\nthereby producing arbitrary (goal) transformations of an easy-to-sample initial distribution.\n\nto the general case of arbitrary likelihood and posteriors, and in this defines a superseding class of GMs providing\na unified framework for learning continuous transformations between distributions, encompassing and generalizing\nDMs. Instead of a stochastic, discrete, multi-step denoising process, FM aims to learn a deterministic, continuous,\ndifferentiable flow \u03c8 : [0, 1]\u00d7Z 7\u2192 Z, fo",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_317216b603d7459480bf235e8253e13c": {
    "id": "parent_317216b603d7459480bf235e8253e13c",
    "metadata": {
      "content": "ing process, FM aims to learn a deterministic, continuous,\ndifferentiable flow \u03c8 : [0, 1]\u00d7Z 7\u2192 Z, formalized starting from a (possibly time-dependent) vector field v : [0, 1]\u00d7Z 7\u2192 Z\ntransporting over time samples from a simple prior distribution p0\u2014e.g., a standard Gaussian\u2014to a more complex,\ntypically unknown data distribution p1. In this, FM accomodates for arbitrary intermediate distributions, breaking\nfree from the particular case where posterior and likelihood are exclusively Gaussians. Note also how FM models time\nt \u2208 [0, 1] to be varying continuously while moving away from an easy-to-sample distribution p0 towards the unknown\ndata-distribution, p1. This results in a continuous (and deterministic) trajectory at inference, which is in practice\nmore efficient compared to following stochastic paths like in DMs. Formally, FM can be fully characterized by an\nordinary differential equation (ODE) relating instantaneous variations of flows with the underlying vector field, and\nhence prov",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b17e0c7c14d84628a1520e15d9482c61": {
    "id": "parent_b17e0c7c14d84628a1520e15d9482c61",
    "metadata": {
      "content": "on (ODE) relating instantaneous variations of flows with the underlying vector field, and\nhence providing complete trajectories over the distributions\u2019 support when integrating over time,\n\nd\n\u03c8(z, t) = v(t, \u03c8(t, z)), (46)\n\ndt\n\u03c8(0, z) = z. (47)\n\nIn practice, flow models learn to approximate these dynamics by estimating a vector field v that matches the true,\nunknown u, so that the induced flows \u03c8 can approximate the ideal trajectories \u03c8\u2217.\nFM proved very effective in a variety of applications, ranging from image (Esser et al., 2024) and video genera-\ntion (Polyak et al., 2025) to robotics control (Black et al., 2024). Most notably, in their introductory work on FM for\nGM, Lipman et al. (2023) show how DMs can be seen as a specific instance of FM where the conditional target vector\nfield v learned by the noise regressor \u03b5\u03b8 corresponds to:\n\nd \u222b\nu(t, z|z dt\u03b1(1\u2212 t) t\n\n0) = (\u03b1(1\u2212 t)z \u2212 z0), \u03b1(t) = e\u2212\n1\n2 \u03b2(s)ds\n\n0 , \u2200z0 \u2208 D. (48)\n1\u2212 (\u03b1(1\u2212 t))2\n\nConditional vector fields are defined not only ov",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b8d4539d15074ffe9269f35c26dbb78b": {
    "id": "parent_b8d4539d15074ffe9269f35c26dbb78b",
    "metadata": {
      "content": "= e\u2212\n1\n2 \u03b2(s)ds\n\n0 , \u2200z0 \u2208 D. (48)\n1\u2212 (\u03b1(1\u2212 t))2\n\nConditional vector fields are defined not only over their argument z and time t, but do also vary with respect to an\nauxiliary variable z0, thereby extending the standard notion of a vector field to incorporate additional conditioning.\nNote that the traditional discrete-time noise-scheduler {\u03b2t}Tt=0 is now generalized to a continuous map \u03b2 : [0, 1] 7\u2192 R+.\nCrucially, Lipman et al. (2023) prove that by exclusively optimizing the vector field for individual data points z0 \u2208 D,\none also retrieves the optimal flow to morph the entire support of the initial distribution p0 into p1 s.t.D \u223c p1.\nWhile the noising schedule of DMs results in a stochastic resembling a random (Brownian) walk, FM allows for more\ngeneral\u2014potentially, deterministic\u2014likelihood and posterior parametrization. In the FM literature the likelihood and\nposterior probabilty densities defined along a HMLV model are typically referred to as a probability path, where the\ndistrib",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ebac43cea24c49138c8ea8f0449fb391": {
    "id": "parent_ebac43cea24c49138c8ea8f0449fb391",
    "metadata": {
      "content": "sities defined along a HMLV model are typically referred to as a probability path, where the\ndistributions for successive adjacent transitions in the HMLV model are related by the (normalized) flow between them\n(Figure 26). The inherent flexibility of FM is one of their key advantages over DMs, as it opens up the possibility of\n\n42\n\n\n\nFigure 27 | Compared to diffusion, flow matching distorts distribution along a less randomic pattern, resulting in a clearer\ninterpolation between source and target distribution. The visualization shows an example comparison between these two\nmethods on joint distribution of robot observations and actions over T = 50 steps.\n\nlearning more efficient paths. For instance, one can design probability paths inspired by Optimal Transport (OT), a\nmathematical framework concerned with characterizing the most efficient morphings between probability distributions.\nProbability paths obtained through OT paths tend to be straighter than diffusion paths (Figure 27), whi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_5f6e3f7270ad46738df57f38c62ba47c": {
    "id": "parent_5f6e3f7270ad46738df57f38c62ba47c",
    "metadata": {
      "content": "bability paths obtained through OT paths tend to be straighter than diffusion paths (Figure 27), which can lead\nto faster and more stable training, as well as empirically result in higher-quality generations with fewer denoising\nsteps at inference time. In particular, by avoiding unnecessary backtracking associated with the inherent stochastic\nnature of both the noising and denoising process in DMs, test-time compute is typically significantly reduced in FM,\nwhile retaining comparable results (Lipman et al., 2023).\nIn practice, FM can be applied to generative modeling by learning a vector field regressor v\u03b8(z, t) to approximate a\ngiven target vector field u(t, z). In the particular case of DMs, u(t, z) is defined as in eq. 48, while in priciple the\ntarget vector field can be learned to induce an arbitrary mass displacement, or fixed according to OT. Given a sample\nfrom the data distribution z1 \u223c p1 and a sample from an easy-to-sample prior z0 \u223c p0, Conditional FM (CFM) defines\na simple",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_cfa9275e0a284ef3ab036314182f5660": {
    "id": "parent_cfa9275e0a284ef3ab036314182f5660",
    "metadata": {
      "content": "ion z1 \u223c p1 and a sample from an easy-to-sample prior z0 \u223c p0, Conditional FM (CFM) defines\na simple path between them using linear interpolation between samples zt = (1\u2212 t)z0 + tz1, which in turn results in\nthe target vector field u(t, zt) = z1 \u2212 z0.[ FM models can then be trained wit]h a simple regression objective defined as:\n\nL(\u03b8) = E \u2225v\u03b8((1\u2212 t)z0 + tz1, t)\u2212 (z1 \u2212 z0)\u22252t,z0,z , t \u223c U([0, 1]), (49)\n1\n\nwhere z0 \u223c p0(\u2022) and z1 \u223c p1(\u2022). Note how in eq. 49\u2014differently from eq. 44\u2014time is assumed to be varying\ncontinuously t \u223c U([0, 1]) rather than discretely t \u223c U({0,\u2206t, 2\u2206t, . . . , 1}), a key property of flow-based models.\nTherefore, the objective in eq. 49 directly regresses the learned vector field onto the simple, straight path connecting\na point from the prior and a point from the data, providing a simulation-free training procedure that is both stable\nand efficient. At inference time, samples are generated by starting with z0 \u223c p0 and iteratively refined according to\ndz\ndt = v\u03b8(z",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_17aa52075c4846eb9a403c2bc797c642": {
    "id": "parent_17aa52075c4846eb9a403c2bc797c642",
    "metadata": {
      "content": "me, samples are generated by starting with z0 \u223c p0 and iteratively refined according to\ndz\ndt = v\u03b8(zt, t) for t \u2208 [0, 1]\u2014an operation that can be numerically carried out with standard ODE solvers, and that in\npractice is often carried out numerically via forward-Euler integrating over tens of denoising steps.\n\n4.2 Action Chunkingwith Transformers\nWhile GMs prove useful in learning complex, high-dimensional multi-modal distributions, they do not natively address\nthe compouding errors problem characteristic of modeling online, sequential predictions. In Action Chunking with\nTransformers (ACT), Zhao et al. (2023) present an application of VAEs to the problem of learning purely from\noffline trajectories, and introduce a simple, yet effective method to mitigate error compounding, learning high-fidelity\nautonomous behaviors via BC. Drawing inspiration from how humans plan to enact sequences of actions at:t+k instead\nof single actions at, Zhao et al. (2023) propose learning a GM on a dataset",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_5a0dc85db78a464599edd73fadcc448e": {
    "id": "parent_5a0dc85db78a464599edd73fadcc448e",
    "metadata": {
      "content": "actions at:t+k instead\nof single actions at, Zhao et al. (2023) propose learning a GM on a dataset of input demonstrations by modeling\nchunks of multiple actions directly. Besides contributions to learning high-performance autonomous behaviors, Zhao\net al. (2023) also introduce hardware contributions in the form of a low-cost bimanual robot setup (ALOHA) capable\nof performing fine-grained manipulation tasks, such as opening a lid, slotting a battery in its allotment or even prepare\ntape for application. Notably, ALOHA bimanual setup costs just as much as a mono-arm Franka arm and can be\nassembled from easy-to-source parts, underscoring its higher accessibility.\n\n43\n\n\n\nZhao et al. (2023) do also present significant algorithmic contributions related to synthetizing performant autonomous\nbehaviors for the ALOHA setup, adopting transformers as the architectural backbone to learn a Conditional VAE (Sohn\net al., 2015) from demonstrations. Conditional VAEs are a variation of the standard VAE",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c5f3c71631a24ca78be821a9ba7c78b0": {
    "id": "parent_c5f3c71631a24ca78be821a9ba7c78b0",
    "metadata": {
      "content": "al VAE (Sohn\net al., 2015) from demonstrations. Conditional VAEs are a variation of the standard VAE introducing an arbitrary\nconditioning on sampling from the latent prior, modeling one-to-many relationships between latent and data samples.\nFurther, in stark contrast with previous work (Florence et al., 2022; Janner et al., 2022), Zhao et al. (2023) do not\nlearn a full joint p\u03b8(o, a) on observation and actions, and rather focus on the conditional p\u03b8(a|o). While the policy\ndistribution p\u03b8(a|o) can in principle be entirely described fro\u222bm the joint p\u03b8(o, a), conditional distributions are often\nintractable when using function approximators, as p\u03b8(a|o) = p\u03b8(o,a) , and the integral in the denominator is typically\n\nA p\u03b8(o,a)\n\nintractable. Thus, instead of modeling the full joint using a vanilla VAE, Zhao et al. (2023) propose learning a\nconditional VAE (Sohn et al., 2015) modeling the policy distribution directly, hence approximating p(a|o).\nIn practice, when learning from demonstrations ad",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_73f617a13d8d419b8261a682b37745ba": {
    "id": "parent_73f617a13d8d419b8261a682b37745ba",
    "metadata": {
      "content": "distribution directly, hence approximating p(a|o).\nIn practice, when learning from demonstrations adopting CVAEs results in a slight modification to the VAE objective\nin eq. 26, which is adapted to:\n\n\u2211N ( [ ] [ ])\nELBOD(\u03b8, \u03d5, \u03c9) = Ez\u223cq , o\n\n\u03d5(\u00b7|o lo p\ni,ai) g \u03b8(ai|z i) \u2212DKL q\u03d5(z|oi, ai)\u2225p\u03c9(z|oi) (50)\n\ni=0\n\nNotice how in eq. 50 we are now also learning a new set of parameters \u03c9 for the prior distribution in the latent space.\nEffectively, this enables conditioning latent-space sampling (and thus reconstruction) during training (and potentially\ninference too), providing useful when learning inherently conditional distributions like policies. Further, ACT is\ntrained as a \u03b2-CVAE (Higgins et al., 2017), weighing the KL regularization term in eq. 50 with an hyperparameter\n\u03b2 \u2208 R+ regulating the information condensed in the latent space, where higher \u03b2 results in a less expressive latent\nspace.\nIn their work, Zhao et al. (2023) ablated using a GM to learn from human demonstrations compared to a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7bef264b33304ae191e0940271855f3a": {
    "id": "parent_7bef264b33304ae191e0940271855f3a",
    "metadata": {
      "content": "n their work, Zhao et al. (2023) ablated using a GM to learn from human demonstrations compared to a simpler,\nsupervised objective, L1(a, a\n\n\u2032) = \u2225a\u2212 a\u2032\u22251. Interestingly, they found the performance of these two approaches to be\ncomparable when learning from scripted demonstrations. That is, when learning from data collected rolling out a\npredetermined set of commands [qc0, q\n\nc\n1, . . . ], GM did not prove competitive compared to standard supervised learning.\n\nHowever, when learning from human demonstrations\u2014i.e., from data collected executing commands coming from a\nhuman controller [qh0 , q\n\nh\n1 , . . . ]\u2014 Zhao et al. (2023) found performance (defined as the success rate on a downstream\n\ntask) to be severily (-33.3%) hindered from adopting a standard supervised learning objective compared to a richer,\npotentially more complex to learn variational objective. The result of such ablation reflects from the multimodal\nnature of human demonstrations data, and is consistent with the findings",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e5c6580cd0d4495ca5e0ff19d1c6e324": {
    "id": "parent_e5c6580cd0d4495ca5e0ff19d1c6e324",
    "metadata": {
      "content": "eflects from the multimodal\nnature of human demonstrations data, and is consistent with the findings presented by Florence et al. (2022). The\nauthors also ablate the action chunking paradigm, reporting significant performance gains deriving from using action\nchunking (1% vs. 44% success rate). To reduce acting open-loop, Zhao et al. (2023) also design an inference process\nconsisting in performing inference at every timestep t and then aggregate multiple chunks using an exponential moving\naverage (EMA) on the overlapping chunks.\nIn ACT (Figure 30), inference for a given observation o \u2208 O could be performed by (1) defining a prior p\u03c9(z|o) for\nthe latent variable z and (2) decoding an action chunk from a sampled latent z \u223c p\u03c9(\u2022|o), similarily to how sampling\nfrom standard VAEs takes place, with the exception that vanilla VAEs typically pose p(z|o) \u2261 p(z) \u223c N (0, I) and\nthus skip (1).\nHowever, the authors claim that using a deterministic procedure to sample z benefits policy evaluation, an",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e3f43e85f9074ea4b3a7d54e4feb4eaa": {
    "id": "parent_e3f43e85f9074ea4b3a7d54e4feb4eaa",
    "metadata": {
      "content": "r, the authors claim that using a deterministic procedure to sample z benefits policy evaluation, and thus avoid\nusing the conditional prior at all at inference time, effectively using the CVAE framework exclusively to train a more\nexpressive decoder. At test time, Zhao et al. (2023) propose simply using z = 0, as the conditional prior on z used in\ntraining is set to be a standard Gaussian. Further, conditioning on the observation o is achieved through explicitly\nfeeding proprioperceptive and visual observations to the decoder, p\u03b8(a|z, o) at test time. If at inference z is sampled\nfrom a standard Gaussian, during training z is sampled from an approximate posterior distribution q\u03d5(z|o, a), which,\nhowever, disregards image observations and exclusively uses proprioperceptive states to form o for efficiency reasons.\n\n44\n\n\n\nFigure 28 | The CVAE encoder used in ACT. Input action chunks are first embedded and aggregated with positional\nembeddings, before being processed alongside embedded pro",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_bad155e6add140fea90542ea6f103400": {
    "id": "parent_bad155e6add140fea90542ea6f103400",
    "metadata": {
      "content": "st embedded and aggregated with positional\nembeddings, before being processed alongside embedded proprioperceptive information, and a learned [CLS] token used to\naggregate input level information, and predict the style variable z. The encoder is exclusively used to train the decoder, and it\nis entirely disregarded at inference time.\n\nFigure 29 | The CVAE decoder used in ACT, comprising of a full encoder-decoder Transformer architecture. Camera\nobservations from all n camera views are first embedded using pre-trained visual encoders, and then aggregated with the\ncorresponding positional embeddings. Then, the proprioperceptive information and style variable z retrieved from the CVAE\nencoder, are fed to the encoder-decoder Transformer for inference. The encoder shares the matrices K,V with the decoder, and\nis trained to decode fixed position embeddings into action chunks.\n\n45\n\n\n\nFigure 30 | Action Chunking with Transformer (ACT), as in Zhao et al. (2023). ACT introduces an action chunking",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_06a9c148329e49a196a5581644ba88f0": {
    "id": "parent_06a9c148329e49a196a5581644ba88f0",
    "metadata": {
      "content": "Action Chunking with Transformer (ACT), as in Zhao et al. (2023). ACT introduces an action chunking paradigm\nto cope with high-dimensional multi-modal demonstration data, and a transformer-based CVAE architecture.\n\n4.2.1 Code Example: Training and Using ACT in Practice\n\nCode 7: Training ACT\nhttps://github.com/fracapuano/robot-learning-tutorial/snippets/ch4/01_training_act.py\n\n1 from pathlib import Path\n2\n3 import torch\n4\n5 from lerobot.configs.types import FeatureType\n6 from lerobot.datasets.lerobot_dataset import LeRobotDataset , LeRobotDatasetMetadata\n7 from lerobot.datasets.utils import dataset_to_policy_features\n8 from lerobot.policies.act.configuration_act import ACTConfig\n9 from lerobot.policies.act.modeling_act import ACTPolicy\n\n10 from lerobot.policies.factory import make_pre_post_processors\n11\n12\n13 def make_delta_timestamps(delta_indices: list[int] | None , fps: int) -> list[float]:\n14 if delta_indices is None:\n15 return [0]\n16\n17 return [i / fps for i in delta_indices]\n18\n1",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_12028aceefa345b0afa0091ffa105a9f": {
    "id": "parent_12028aceefa345b0afa0091ffa105a9f",
    "metadata": {
      "content": "loat]:\n14 if delta_indices is None:\n15 return [0]\n16\n17 return [i / fps for i in delta_indices]\n18\n19\n20 output_directory = Path(\"outputs/robot_learning_tutorial/act\")\n21 output_directory.mkdir(parents=True , exist_ok=True)\n22\n23 # Select your device\n24 device = torch.device(\"mps\") # or \"cuda\" or \"cpu\"\n25\n26 dataset_id = \"lerobot/svla_so101_pickplace\"\n27\n28 # This specifies the inputs the model will be expecting and the outputs it will produce\n29 dataset_metadata = LeRobotDatasetMetadata(dataset_id)\n30 features = dataset_to_policy_features(dataset_metadata.features)\n31\n32 output_features = {key: ft for key , ft in features.items () if ft.type is FeatureType.ACTION}\n33 input_features = {key: ft for key , ft in features.items() if key not in output_features}\n34\n35 cfg = ACTConfig(input_features=input_features , output_features=output_features)\n36 policy = ACTPolicy(cfg)\n37 preprocessor , postprocessor = make_pre_post_processors(\n\n46\n\n\n\n38 cfg , dataset_stats=dataset_metadata.stats\n39 )\n4",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1c80777ed1ee4f2bb0a51f084342a4be": {
    "id": "parent_1c80777ed1ee4f2bb0a51f084342a4be",
    "metadata": {
      "content": "ostprocessor = make_pre_post_processors(\n\n46\n\n\n\n38 cfg , dataset_stats=dataset_metadata.stats\n39 )\n40\n41 policy.train ()\n42 policy.to(device)\n43\n44 # To perform action chunking , ACT expects a given number of actions as targets\n45 delta_timestamps = {\n46 \"action\": make_delta_timestamps(cfg.action_delta_indices , dataset_metadata.fps),\n47 }\n48\n49 # add image features if they are present\n50 delta_timestamps |= {\n51 k: make_delta_timestamps(cfg.observation_delta_indices , dataset_metadata.fps)\n52 for k in cfg.image_features\n53 }\n54\n55 # Instantiate the dataset\n56 dataset = LeRobotDataset(dataset_id , delta_timestamps=delta_timestamps)\n57\n58 # Create the optimizer and dataloader for offline training\n59 optimizer = cfg.get_optimizer_preset (). build(policy.parameters ())\n60 batch_size = 32\n61 dataloader = torch.utils.data.DataLoader(\n62 dataset ,\n63 batch_size=batch_size ,\n64 shuffle=True ,\n65 pin_memory=device.type != \"cpu\",\n66 drop_last=True ,\n67 )\n68\n69 # Number of training steps and log",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f7b8259a59cd4df39279a467234668b4": {
    "id": "parent_f7b8259a59cd4df39279a467234668b4",
    "metadata": {
      "content": "5 pin_memory=device.type != \"cpu\",\n66 drop_last=True ,\n67 )\n68\n69 # Number of training steps and logging frequency\n70 training_steps = 1\n71 log_freq = 1\n72\n73 # Run training loop\n74 step = 0\n75 done = False\n76 while not done:\n77 for batch in dataloader:\n78 batch = preprocessor(batch)\n79 loss , _ = policy.forward(batch)\n80 loss.backward ()\n81 optimizer.step()\n82 optimizer.zero_grad ()\n83\n84 if step % log_freq == 0:\n85 print(f\"step: {step} loss: {loss.item ():.3f}\")\n86 step += 1\n87 if step >= training_steps:\n88 done = True\n89 break\n90\n91 # Save the policy checkpoint , alongside the pre/post processors\n92 policy.save_pretrained(output_directory)\n93 preprocessor.save_pretrained(output_directory)\n94 postprocessor.save_pretrained(output_directory)\n95\n96 # Save all assets to the Hub\n97 policy.push_to_hub(\"fracapuano/robot_learning_tutorial_act_example_model\")\n98 preprocessor.push_to_hub(\"fracapuano/robot_learning_tutorial_act_example_pipeline\")\n99 postprocessor.push_to_hub(\"fracapuano/robot_l",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_80bdd61f5add47589882e1ce001fc699": {
    "id": "parent_80bdd61f5add47589882e1ce001fc699",
    "metadata": {
      "content": "uano/robot_learning_tutorial_act_example_pipeline\")\n99 postprocessor.push_to_hub(\"fracapuano/robot_learning_tutorial_act_example_pipeline\")\n\n47\n\n\n\nCode 8: Using ACT\nhttps://github.com/fracapuano/robot-learning-tutorial/snippets/ch4/02_using_act.py\n\n1 import torch\n2\n3 from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig\n4 from lerobot.datasets.lerobot_dataset import LeRobotDatasetMetadata\n5 from lerobot.policies.act.modeling_act import ACTPolicy\n6 from lerobot.policies.factory import make_pre_post_processors\n7 from lerobot.policies.utils import build_inference_frame , make_robot_action\n8 from lerobot.robots.so100_follower.config_so100_follower import SO100FollowerConfig\n9 from lerobot.robots.so100_follower.so100_follower import SO100Follower\n\n10\n11 device = torch.device(\"mps\") # or \"cuda\" or \"cpu\"\n12 model_id = \"fracapuano/robot_learning_tutorial_act_example_model\"\n13 model = ACTPolicy.from_pretrained(model_id)\n14\n15 dataset_id = \"lerobot/svla_so101_pickplace\"\n16 #",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e6071a53ae92491a82810ca29d38d594": {
    "id": "parent_e6071a53ae92491a82810ca29d38d594",
    "metadata": {
      "content": "3 model = ACTPolicy.from_pretrained(model_id)\n14\n15 dataset_id = \"lerobot/svla_so101_pickplace\"\n16 # This only downloads the metadata for the dataset , ~10s of MB even for large -scale datasets\n17 dataset_metadata = LeRobotDatasetMetadata(dataset_id)\n18 preprocess , postprocess = make_pre_post_processors(\n19 model.config , dataset_stats=dataset_metadata.stats\n20 )\n21\n22 # # find ports using lerobot -find -port\n23 follower_port = ... # something like \"/dev/tty.usbmodem58760431631\"\n24\n25 # # the robot ids are used the load the right calibration files\n26 follower_id = ... # something like \"follower_so100\"\n27\n28 MAX_EPISODES = 5\n29 MAX_STEPS_PER_EPISODE = 20\n30\n31 # Robot and environment configuration\n32 # Camera keys must match the name and resolutions of the ones used for training!\n33 # You can check the camera keys expected by a model in the info.json card on the Hub\n34 camera_config = {\n35 \"side\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps=30),\n36 \"up\": OpenCVCam",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b3425b783f024a19a0d7e45e920aabc2": {
    "id": "parent_b3425b783f024a19a0d7e45e920aabc2",
    "metadata": {
      "content": "35 \"side\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps=30),\n36 \"up\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps=30),\n37 }\n38\n39 robot_cfg = SO100FollowerConfig(port=follower_port , id=follower_id , cameras=camera_config)\n40 robot = SO100Follower(robot_cfg)\n41 robot.connect ()\n42\n43 for _ in range(MAX_EPISODES ):\n44 for _ in range(MAX_STEPS_PER_EPISODE ):\n45 obs = robot.get_observation ()\n46 obs_frame = build_inference_frame(obs , dataset_metadata.features , device)\n47\n48 obs = preprocess(obs_frame)\n49\n50 action = model.select_action(obs)\n51 action = postprocess(action)\n52\n53 action = make_robot_action(action , dataset_metadata.features)\n54\n55 robot.send_action(action)\n56\n57 print(\"Episode finished! Starting new episode ...\")\n\n4.3 Diffusion Policy\nDMs have proven very effective in approximating complex highly dimensional distributions, such as distributions over\nimages (Ho et al., 2020) or videos (Polyak et al., 2025), thanks to their inheren",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3643e8cd5e0e4a318b703914cb02a3a2": {
    "id": "parent_3643e8cd5e0e4a318b703914cb02a3a2",
    "metadata": {
      "content": "distributions over\nimages (Ho et al., 2020) or videos (Polyak et al., 2025), thanks to their inherent capability to deal with multimodal\ndata, and their training stability. In Diffusion Policy (DP), Chi et al. (2024) present an application of DMs the\n\n48\n\n\n\nFigure 31 | The Diffusion Policy archicture, as in Chi et al. (2024). A stack of Ho previous observations is used as external\nconditioning to denoise a group of Ha actions. Conditioning is performed at every layer of a U-Net block. Diffusion Policy\nallows to obtain fully-formed action chunks with as little as T = 10 denoising steps.\n\nfield of robot learning, leveraging diffusion to model expert demonstrations in a variety of simulated and real-world\ntasks. Similarily to ACT (Zhao et al., 2023), Chi et al. (2024) (1) adopt a modified observation-conditioned target\ndistribution instead of the full joint p(o, a), and (2) predict multiple actions into the future instead of a single action.\nBesides the intractability of the observations\u2019",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d950c5fba25d4f8899a7114813ed3c86": {
    "id": "parent_d950c5fba25d4f8899a7114813ed3c86",
    "metadata": {
      "content": "actions into the future instead of a single action.\nBesides the intractability of the observations\u2019 marginal p\u03b8(o) given p\u03b8(o, a), DP\u2019s choice to model the data distribution\nthrough p\u03b8(a|o) also stems from the computational burden of diffusion at test time: generating actions together with\nobservations would require a large number of denoising steps\u2014an unnecessarily slow and ultimately unhelpful process,\ngiven that robotics focuses on producing controls rather than reconstructing observations.\nIn practice, conditioning on observation data is achieved conditioning the noise regressor \u03f5\u03b8 introduced in eq. 44 on a\nstack of Ho observations, resulting in the co[nditional, simplified diffusion objective:\n\n\u221a \u221a ]\nL(\u03b8) = Et,at:t+Ha ,\u03f5\n\n\u2225\u03f5\u2212 \u03f5\u03b8( \u03b1\u0304tat:t+H + \u03f5 1\u2212 \u03b1\u0304\na t, t, ot\u2212Ho:t)\u22252 , (51)\n\nt \u223c U({1, . . . , T}), at:t+H , o\na t\u2212H \u223c D\n\no:t , \u03f5 \u223c N (0, I).\n\nNote how in eq. 51 the noise regressor is conditioned on both the latent variable rank t and on a stack of previous\nobservations ot\u2212Ho:t. Chi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_04aa5b6bcda64e93b49fd728ad67b871": {
    "id": "parent_04aa5b6bcda64e93b49fd728ad67b871",
    "metadata": {
      "content": "conditioned on both the latent variable rank t and on a stack of previous\nobservations ot\u2212Ho:t. Chi et al. (2024) claim the combination of (1) conditioning on a horizon of previous observations\nand (2) predicting multiple actions into the future allows DP to commit to specific modes in the data at inference\ntime, which proves essential for good performance and avoiding undecisiveness.\nFigure 31 shows the convolution-based version of the architecture proposed by Chi et al. (2024), illustrating inference\non a single sample drawn from D, for simplicity. The starting, arbitrarily noisy chunk of Ha actions a\u0303t:t+H is first\n\na\n\nmapped to a (learned) high-dimensional space. Similarily, both image observations and poses are also embedded\nbefore being aggregated to the action embeddings. Then, a U-Net (Ronneberger et al., 2015) is trained to regress\nthe noise added into a\u0303t:t+Ha , conditioned on observation information at every layer, thus seeking to optimize eq. 51.\nAt inference time, the noi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1263d9ad31ca41ddb964475231118123": {
    "id": "parent_1263d9ad31ca41ddb964475231118123",
    "metadata": {
      "content": "observation information at every layer, thus seeking to optimize eq. 51.\nAt inference time, the noise predictor is used to predict the quantity of noise at every t \u2208 [T, . . . , 0] and iteratively\nsubtract it from a\u0303t:t+H , reversing the diffusion process simulated in training conditioned on ot\u2212Ho:t to predict a .\n\na t:t+Ha\n\nDP can be trained with as little as 50-150 demos (ca. 15-60 minutes of teleoperation data), and exhibit strong\nperformance on a variety of simulated and real-world tasks, including dexterous and deformable manipulation tasks\nsuch as sauce pouring and yoga-mat unrolling. Notably, the authors ablated the relevance of using RGB camera streams\nas input to their policy, and observed how high frame-rate visual observations can be used to attain performance\n(measured as success rate) comparable to that of state-based policies, which are typically trained in simulation with\npriviledged information not directly available in real-world deployments. As high-frame rate RGB in",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_01fd2abdf1a342ddb2eab790aa68311c": {
    "id": "parent_01fd2abdf1a342ddb2eab790aa68311c",
    "metadata": {
      "content": "priviledged information not directly available in real-world deployments. As high-frame rate RGB inputs naturally\naccomodate for dynamic, fast changing environments, Chi et al. (2024)\u2019s conclusion offers significant evidence for\nlearning streamlined control policies directly from pixels. In their work, Chi et al. (2024) also ablate the performance\nof DP against the size of the dataset collected, showing that DP reliably outperforms the considered baseline for\n\n49\n\n\n\nall benchmark sizes considered. Further, in order accelerate inference, Chi et al. (2024) employ Denoising Diffusion\nImplicit Models (Song et al., 2022), a variant of Denoising Diffusion Probabilistic Models (Ho et al., 2020) (DDPM)\nadopting a strictly deterministic denoising paradigm (differently from DDPM\u2019s natively stochastic one) inducing\nthe same final distribution\u2019s as DDPM\u2019s, and yet resulting in 10x less denoising steps at inference time (Chi et al.,\n2024). Across a range of simulated and real-world tasks, Chi et a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_09b240a4c0b04ccba2ec62789dbc12e8": {
    "id": "parent_09b240a4c0b04ccba2ec62789dbc12e8",
    "metadata": {
      "content": "eps at inference time (Chi et al.,\n2024). Across a range of simulated and real-world tasks, Chi et al. (2024) find DPs particularly performant when\nmodeling \u03f5\u03b8 with a transformer-based network, although the authors note the increased sensitivity of transformer\nnetworks to hyperparameters. Thus, Chi et al. (2024) explicitly recommend starting out with a simpler, convolution-\nbased architecture for diffusion (Figure 31), which is however reported to be biased towards learning low-frequency\ncomponents (Tancik et al., 2020), and thus may prove more challenging to train with non-smooth action sequences.\n\n4.3.1 Code Example: Training and Using Diffusion Policies in Practice\n\nCode 9: Training Diffusion Policy\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch4/03_training_diffusion.\npy\n\n1 from pathlib import Path\n2\n3 import torch\n4\n5 from lerobot.configs.types import FeatureType\n6 from lerobot.datasets.lerobot_dataset import LeRobotDataset , LeRobotDatasetMetadata\n7 f",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4c42525a5b6741098e2528a35c706ae9": {
    "id": "parent_4c42525a5b6741098e2528a35c706ae9",
    "metadata": {
      "content": "atureType\n6 from lerobot.datasets.lerobot_dataset import LeRobotDataset , LeRobotDatasetMetadata\n7 from lerobot.datasets.utils import dataset_to_policy_features\n8 from lerobot.policies.diffusion.configuration_diffusion import DiffusionConfig\n9 from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n\n10 from lerobot.policies.factory import make_pre_post_processors\n11\n12\n13 def make_delta_timestamps(delta_indices: list[int] | None , fps: int) -> list[float]:\n14 if delta_indices is None:\n15 return [0]\n16\n17 return [i / fps for i in delta_indices]\n18\n19\n20 output_directory = Path(\"outputs/robot_learning_tutorial/diffusion\")\n21 output_directory.mkdir(parents=True , exist_ok=True)\n22\n23 # Select your device\n24 device = torch.device(\"mps\") # or \"cuda\" or \"cpu\"\n25\n26 dataset_id = \"lerobot/svla_so101_pickplace\"\n27\n28 # This specifies the inputs the model will be expecting and the outputs it will produce\n29 dataset_metadata = LeRobotDatasetMetadata(dataset_id)\n30 features = dat",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_59ec76015de04dadb07ef83d16032a29": {
    "id": "parent_59ec76015de04dadb07ef83d16032a29",
    "metadata": {
      "content": "e outputs it will produce\n29 dataset_metadata = LeRobotDatasetMetadata(dataset_id)\n30 features = dataset_to_policy_features(dataset_metadata.features)\n31\n32 output_features = {key: ft for key , ft in features.items () if ft.type is FeatureType.ACTION}\n33 input_features = {key: ft for key , ft in features.items() if key not in output_features}\n34\n35 cfg = DiffusionConfig(input_features=input_features , output_features=output_features)\n36 policy = DiffusionPolicy(cfg)\n37 preprocessor , postprocessor = make_pre_post_processors(\n38 cfg , dataset_stats=dataset_metadata.stats\n39 )\n40\n41 policy.train ()\n42 policy.to(device)\n43\n44 # To perform action chunking , ACT expects a given number of actions as targets\n45 delta_timestamps = {\n46 \"observation.state\": make_delta_timestamps(\n47 cfg.observation_delta_indices , dataset_metadata.fps\n48 ),\n49 \"action\": make_delta_timestamps(cfg.action_delta_indices , dataset_metadata.fps),\n\n50\n\n\n\n50 }\n51\n52 # add image features if they are present\n53 delta_tim",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_116152c69c35473eb41d1d05c3199cb8": {
    "id": "parent_116152c69c35473eb41d1d05c3199cb8",
    "metadata": {
      "content": "ces , dataset_metadata.fps),\n\n50\n\n\n\n50 }\n51\n52 # add image features if they are present\n53 delta_timestamps |= {\n54 k: make_delta_timestamps(cfg.observation_delta_indices , dataset_metadata.fps)\n55 for k in cfg.image_features\n56 }\n57\n58 # Instantiate the dataset\n59 dataset = LeRobotDataset(dataset_id , delta_timestamps=delta_timestamps)\n60\n61 # Create the optimizer and dataloader for offline training\n62 optimizer = cfg.get_optimizer_preset (). build(policy.parameters ())\n63 batch_size = 32\n64 dataloader = torch.utils.data.DataLoader(\n65 dataset ,\n66 batch_size=batch_size ,\n67 shuffle=True ,\n68 pin_memory=device.type != \"cpu\",\n69 drop_last=True ,\n70 )\n71\n72 # Number of training steps and logging frequency\n73 training_steps = 1\n74 log_freq = 1\n75\n76 # Run training loop\n77 step = 0\n78 done = False\n79 while not done:\n80 for batch in dataloader:\n81 batch = preprocessor(batch)\n82 loss , _ = policy.forward(batch)\n83 loss.backward ()\n84 optimizer.step()\n85 optimizer.zero_grad ()\n86\n87 if step",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_90bca3615fb24bfba7290909a8b0b46a": {
    "id": "parent_90bca3615fb24bfba7290909a8b0b46a",
    "metadata": {
      "content": "licy.forward(batch)\n83 loss.backward ()\n84 optimizer.step()\n85 optimizer.zero_grad ()\n86\n87 if step % log_freq == 0:\n88 print(f\"step: {step} loss: {loss.item ():.3f}\")\n89 step += 1\n90 if step >= training_steps:\n91 done = True\n92 break\n93\n94 # Save the policy checkpoint , alongside the pre/post processors\n95 policy.save_pretrained(output_directory)\n96 preprocessor.save_pretrained(output_directory)\n97 postprocessor.save_pretrained(output_directory)\n98\n99 # Save all assets to the Hub\n\n100 policy.push_to_hub(\"fracapuano/robot_learning_tutorial_diffusion_example_model\")\n101 preprocessor.push_to_hub(\"fracapuano/robot_learning_tutorial_diffusion_example_model\")\n102 postprocessor.push_to_hub(\"fracapuano/robot_learning_tutorial_diffusion_example_model\")\n\nCode 10: Using Diffusion Policy\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch4/04_using_diffusion.py\n\n1 import torch\n2\n3 from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig\n4 from lerobot.dat",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_740c3c5dc6ee4405ac3a912e14cd4a31": {
    "id": "parent_740c3c5dc6ee4405ac3a912e14cd4a31",
    "metadata": {
      "content": "ch\n2\n3 from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig\n4 from lerobot.datasets.lerobot_dataset import LeRobotDatasetMetadata\n5 from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n6 from lerobot.policies.factory import make_pre_post_processors\n7 from lerobot.policies.utils import build_inference_frame , make_robot_action\n8 from lerobot.robots.so100_follower.config_so100_follower import SO100FollowerConfig\n9 from lerobot.robots.so100_follower.so100_follower import SO100Follower\n\n51\n\n\n\n10\n11 device = torch.device(\"mps\") # or \"cuda\" or \"cpu\"\n12 model_id = \"fracapuano/robot_learning_tutorial_diffusion_example_model\"\n13\n14 model = DiffusionPolicy.from_pretrained(model_id)\n15\n16 dataset_id = \"lerobot/svla_so101_pickplace\"\n17 # This only downloads the metadata for the dataset , ~10s of MB even for large -scale datasets\n18 dataset_metadata = LeRobotDatasetMetadata(dataset_id)\n19 preprocess , postprocess = make_pre_post_processors(\n20 model.config",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ffc351d6c50e46f5986ab303f7d42b97": {
    "id": "parent_ffc351d6c50e46f5986ab303f7d42b97",
    "metadata": {
      "content": "tDatasetMetadata(dataset_id)\n19 preprocess , postprocess = make_pre_post_processors(\n20 model.config , model_id , dataset_stats=dataset_metadata.stats\n21 )\n22\n23 MAX_EPISODES = 5\n24 MAX_STEPS_PER_EPISODE = 20\n25\n26\n27 # # find ports using lerobot -find -port\n28 follower_port = ... # something like \"/dev/tty.usbmodem58760431631\"\n29\n30 # # the robot ids are used the load the right calibration files\n31 follower_id = ... # something like \"follower_so100\"\n32\n33 # Robot and environment configuration\n34 # Camera keys must match the name and resolutions of the ones used for training!\n35 # You can check the camera keys expected by a model in the info.json card on the Hub\n36 camera_config = {\n37 \"side\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps=30),\n38 \"up\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps=30),\n39 }\n40\n41 robot_cfg = SO100FollowerConfig(port=follower_port , id=follower_id , cameras=camera_config)\n42 robot = SO100Follower(robot_cfg)\n43 rob",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c7810e3930f449a09ea3a4ef9d4078fe": {
    "id": "parent_c7810e3930f449a09ea3a4ef9d4078fe",
    "metadata": {
      "content": "t=follower_port , id=follower_id , cameras=camera_config)\n42 robot = SO100Follower(robot_cfg)\n43 robot.connect ()\n44\n45\n46 for _ in range(MAX_EPISODES ):\n47 for _ in range(MAX_STEPS_PER_EPISODE ):\n48 obs = robot.get_observation ()\n49 obs_frame = build_inference_frame(obs , dataset_metadata.features , device)\n50\n51 obs = preprocess(obs_frame)\n52\n53 action = model.select_action(obs)\n54 action = postprocess(action)\n55 action = make_robot_action(action , dataset_metadata.features)\n56 robot.send_action(action)\n57\n58 print(\"Episode finished! Starting new episode ...\")\n\n4.4 Optimized Inference ( )\nModern visuomotor policies output action chunks\u2013sequences \u03c0(ot) = at, at+1, . . . , at+H = A\n\na t with At a sequence\nof Ha \u226b 1 low-level commands scheduled for execution in an action queue, all originating from a single environment\nobservation, ot. Predicting series of actions instead of single commands proved essential in learning complex, multi-\nmodal behavior (Zhao et al., 2023; Chi et al., 2024)",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_5f553124ffe24ad0b3b59e0d080aab09": {
    "id": "parent_5f553124ffe24ad0b3b59e0d080aab09",
    "metadata": {
      "content": "ds proved essential in learning complex, multi-\nmodal behavior (Zhao et al., 2023; Chi et al., 2024), and it also holds the premise to be useful to optimize how\ninference is carried out in practice.\nA robot may indeed execute an entire action chunk At before a new observation ot+H is passed to the policy \u03c0 to\n\na\n\npredict the next chunk, which would result in open-loop control between observations captured every Ha timesteps.\nZhao et al. (2023) adopt a different strategy, whereby the robot controller interleaves chunk prediction At \u2190 \u03c0(ot)\nand chunk consumption at \u2190 PopFront(At), and computes a new chunk of actions at every timestep t, to then\naggregate the predicted chunks on overlapping sections. While adaptive\u2014every observation at every timestep ot is\nprocessed\u2014such an approach relies on running inference continuously, which can be prohibitive in resource-constrained\nscenarios, such as edge deployments. A less resource-intensive approach is to entirely exhaust the chunk A before\npred",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_bde2bcf491084ccd8a20b12b82ccf623": {
    "id": "parent_bde2bcf491084ccd8a20b12b82ccf623",
    "metadata": {
      "content": "edge deployments. A less resource-intensive approach is to entirely exhaust the chunk A before\npredicting a new chunk of actions, a strategy we refer to as synchronous (sync) inference. Sync inference allocates\n\n52\n\n\n\nFigure 32 | Asynchronous inference. Illustration of the asynchronous inference stack. Note that the policy can be run on a\nremote server, possibly with GPUs.\n\ncomputation every Ha timesteps, resulting in a reduced computational burden (on average) at control time. In\ncontrast, sync inference also inherently hinders the responsiveness of robot systems, introducing blind lags due to the\nrobot being idle while computing A.\nOne can use the fact that policies output multiple actions at the same time to directly (1) the lack of adaptiveness and\n(2) the presence of lags at runtime by decoupling action chunk prediction A from action execution at \u2190 PopFront(At).\nThis decoupled stack, which we refer to as asynchronous (async) inference (1), also enables optimized inference by\nallo",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_58a9cd60ccf943d3b988445fa6599677": {
    "id": "parent_58a9cd60ccf943d3b988445fa6599677",
    "metadata": {
      "content": "k, which we refer to as asynchronous (async) inference (1), also enables optimized inference by\nallowing action-chunk inference to run on a separate machine, typically equipped with better computational resources\nthan the ones onboard a robot. In async inference, a RobotClient sends an observation ot to a PolicyServer,\nreceiving an action chunk At once inference is complete (Figure 32). In this, we avoid execution lags by triggering\nchunk prediction while the control loop is still consuming a previously available chunk, aggregating the previous\nand incoming chunks whenever the latter is available to the RobotClient. In turn, async-inference tightens the\nloop between action prediction and action execution efficienty, by increasing the frequency at which observations are\nprocessed for chunk prediction while not running inference at every timestep. Crucially, decoupling action prediction\nfrom action execution also allows to allocate more computational resources on a remote policy server s",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4971a6e97835459c86c6a8b259d36ff2": {
    "id": "parent_4971a6e97835459c86c6a8b259d36ff2",
    "metadata": {
      "content": "om action execution also allows to allocate more computational resources on a remote policy server sending actions\nto the robot client over the network.\n\nAlgorithm 1 Asynchronous inference control-loop\n1: Input: horizon T , chunk size Ha, threshold g \u2208 [0, 1]\n2: Init: capture o0; send o0 to PolicyServer; receive A0 \u2190 \u03c0(o0)\n3: for t to Ha do\n4: at \u2190 PopFront(At)\n5: Execute(at) \u25b7 execute action at step t\n6: if |At|\n\nH < g then \u25b7 queue below threshold\na\n\n7: capture new observation, ot+1\n8: if NeedsProcessing (ot+1) then \u25b7 similarity filter, or triggers direct processing\n9: async_handle \u2190 AsyncInfer(ot+1) \u25b7 Trigger new chunk prediction (non blocking)\n\n10: A\u0303t+1 \u2190 \u03c0(ot+1) \u25b7 New queue is predicted with the policy\n11: At+1 \u2190 f(At, A\u0303t+1) \u25b7 aggregate overlaps (if any)\n12: end if\n13: end if\n14: if NotCompleted(async_handle) then\n15: At+1 \u2190 At \u25b7 No update on queue (inference is not over just yet)\n16: end if\n17: end for\n\n53\n\n\n\nFigure 33 | Action queue size evolution at runtime for various levels",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e5cb70f13e384d9c867bfd59ab637b46": {
    "id": "parent_e5cb70f13e384d9c867bfd59ab637b46",
    "metadata": {
      "content": "16: end if\n17: end for\n\n53\n\n\n\nFigure 33 | Action queue size evolution at runtime for various levels of g when (A) not filtering out observation based on\njoint-space similarity and (B) filtering out near-duplicates observation, measuring their similarity in joint-space.\n\nIn practice, async inference (1) tightens the control loop by capturing observations more often, eliminating idle gaps\nat runtime (2) and directly allows to run inference on more powerful computational resources than the ones typically\navailable onboard autonomous robotic platforms. Algorithmically, one can attain (1) on the RobotClient-side\nby consuming actions from a readily available queue until a given condition on the number of remaining actions\nin the queue (|At|/Ha < g) is met. When this condition is triggered, a new observation of the environment is\ncaptured and sent to the (possibly remote) PolicyServer. To avoid redundant server calls and erratic behavior at\nruntime observations are compared in joint-space, an",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_29e9fb30e62e4c03af9591e49d7bc200": {
    "id": "parent_29e9fb30e62e4c03af9591e49d7bc200",
    "metadata": {
      "content": "redundant server calls and erratic behavior at\nruntime observations are compared in joint-space, and near-duplicates are dropped. Two observations are considered\nnear-duplicates if their distance in joint-space falls under a predetermined threshold, dlim \u2208 R+. Importantly, should\nthe queue available to the robot client eventually empty out, the most recent observation is processed regardless of\nsimilarity.\nInterestingly, the behavior of async inference can be studied analytically. First, let \u2113 be a random variable modeling the\ntime needed to receive an action chunk A after sending an observation o, i.e. the sum of (1) the time to send across the\nobservation o between the RobotClient and PolicyServer, tC\u2192S (2) the inference latency on the PolicyServer,\n\u2113S and (3) the time to send A between the PolicyServer and RobotClient, tS\u2192C . Under the (reasonable)\nassumption of independence, E[\u2113] = E[tC\u2192S ] + E[\u2113S ] + E[tS\u2192C ], which can be further simplified to E[\u2113] \u2243 E[\u2113S ],\nassuming communicati",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ab93efe1c2c1484cae772149054559f0": {
    "id": "parent_ab93efe1c2c1484cae772149054559f0",
    "metadata": {
      "content": "E[tC\u2192S ] + E[\u2113S ] + E[tS\u2192C ], which can be further simplified to E[\u2113] \u2243 E[\u2113S ],\nassuming communication time is (1) equal in both directions and (2) negligible with respect to the inference latency.\nSecond, let \u2206t be the environment\u2019s control cycle. With a real-world frame-rate of 30 frames-per-second (fps),\n\u2206t = 33ms. Consequently, exhausted queues at runtime\u2014i.e. being idle awaiting for a new chunk\u2014are avoided for\ng \u2265 E[\u2113S ]/\u2206t\n\nH . In this, the action queue threshold g below which to capture and send a new observation for processing\na\n\nplays a major role relatively to the availability of actions to the RobotClient.\nFigure 33 illustrates how the size of the action chunk |At| evolves over time for three representative values of g,\ndetailing the following key scenarios:\n\n\u2022 Sequential limit (g = 0). The client drains the entire chunk before forwarding a new observation to the server.\nDuring the round-trip latency needed to compute the next chunk, the queue is empty, leaving the robot inc",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b5653bdf754f4838b8813887626ea4b9": {
    "id": "parent_b5653bdf754f4838b8813887626ea4b9",
    "metadata": {
      "content": "g the round-trip latency needed to compute the next chunk, the queue is empty, leaving the robot incapable\nof acting. This reproduces the behavior of a fully sequential deployment and results in an average of E[\u2113S ] idle\nseconds.\n\n\u2022 Asynchronous inference (g \u2208 (0, 1)). Allowing the client to consume a 1\u2212 g fraction of its available queue At\u22121\nbefore triggering inference for a new action queue At, computation is amortized while keeping the queue from\nemptying. The overlap between successive chunks provides a buffer against modeling errors without the full cost of\nthe g = 1 regime. The updated queue At is obtained aggregating queues on the overlapping timesteps between\nAt\u22121 and the incoming A\u0303t.\n\n\u2022 Sync-inference limit (g = 1). As an extreme case, and in keeping with Zhao et al. (2023), an observation is sent\nat every timestep. The queue is therefore almost always filled, with only a minor saw-tooth due to \u2206t/E[\u2113s] < 1.\nWhile maximally reactive, this setting incurs one forward pass per c",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_607d6de29b9a4c5f85ddb03e9c83d454": {
    "id": "parent_607d6de29b9a4c5f85ddb03e9c83d454",
    "metadata": {
      "content": "saw-tooth due to \u2206t/E[\u2113s] < 1.\nWhile maximally reactive, this setting incurs one forward pass per control tick and can prove prohibitively expensive\non limited hardware. Importantly, because the client is consuming actions while the server computes the next\nchunk, the available queue never gets entirely filled.\n\nFigure 33 emphasizes the trade-off governed by g: small values of g result in idle periods, whereas g \u2248 1 assumes a\n\n54\n\n\n\nhighly accurate model and pays a significant compute price. In practice, choosing g \u2208 (0, 1) allows to strike a balance\nbetween reactivity against resource budgets. If not for the aforementioned similarity filter, the RobotClient would\nsend observations for processing every (1\u2212g)Ha \u00b7\u2206t seconds, receiving a new chunk of actions every (1\u2212g)Ha \u00b7\u2206t+E[\u2113S ],\non average. The presence of the filter for observation similarity dilates this processing time, and serves the scope\nof avoiding the robot stalling due to the queue being constantly integrated with an incomi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2b6889709f7d4f1fb6ee67b471f5232f": {
    "id": "parent_2b6889709f7d4f1fb6ee67b471f5232f",
    "metadata": {
      "content": "the scope\nof avoiding the robot stalling due to the queue being constantly integrated with an incoming, nearly identical,\naction chunk. In particular, Figure 33 results in a queue which is filled with incoming actions unless near-duplicate\nobservations are filtered out from the processing pipeline. For clarity, the red arrow in 33 highlights a timestep where\nthe observation similarity mechanism is bypassed, forcing a (nearly identical) observation to be processed as the queue\nresults empty.\n\n4.4.1 Code Example: Using Async Inference\n\nCode 11: Spinning up a Remote Server\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch4/05_policy_server.py\n\n1 from lerobot.async_inference.configs import PolicyServerConfig\n2 from lerobot.async_inference.policy_server import serve\n3\n4 host = ... # something like \"127.0.0.1\" if you're exposing to localhost\n5 port = ... # something like 8080\n6\n7 config = PolicyServerConfig(\n8 host=host ,\n9 port=port ,\n\n10 )\n11 serve(config)\n\nCode 1",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c461d6c6b5844f919678315f97c5efaa": {
    "id": "parent_c461d6c6b5844f919678315f97c5efaa",
    "metadata": {
      "content": "ike 8080\n6\n7 config = PolicyServerConfig(\n8 host=host ,\n9 port=port ,\n\n10 )\n11 serve(config)\n\nCode 12: Attaching a Robot Client\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch4/06_robot_client.py\n\n1 import threading\n2 from lerobot.robots.so100_follower import SO100FollowerConfig\n3 from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig\n4 from lerobot.async_inference.configs import RobotClientConfig\n5 from lerobot.async_inference.robot_client import RobotClient\n6 from lerobot.async_inference.helpers import visualize_action_queue_size\n7\n8 # these cameras must match the ones expected by the policy (use lerobot -find -cameras)\n9 # check the config.json on the Hub for the policy you are using to see the expected camera specs\n\n10 camera_cfg = {\n11 \"top\": OpenCVCameraConfig(index_or_path =0, width =640, height =480, fps=30),\n12 \"side\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps =30)\n13 }\n14\n15 # # find ports using lerobot -",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_fc947743c12b4514af9b290b372bac89": {
    "id": "parent_fc947743c12b4514af9b290b372bac89",
    "metadata": {
      "content": "Config(index_or_path =1, width =640, height =480, fps =30)\n13 }\n14\n15 # # find ports using lerobot -find -port\n16 follower_port = ... # something like \"/dev/tty.usbmodem58760431631\"\n17\n18 # # the robot ids are used the load the right calibration files\n19 follower_id = ... # something like \"follower_so100\"\n20\n21 robot_cfg = SO100FollowerConfig(\n22 port=follower_port ,\n23 id=follower_id ,\n24 cameras=camera_cfg\n25 )\n26\n27 server_address = ... # something like 127.0.0.1:8080 if using localhost\n28\n29 # 3. Create client configuration\n30 client_cfg = RobotClientConfig(\n31 robot=robot_cfg ,\n\n55\n\n\n\n32 server_address=server_address ,\n33 policy_device=\"mps\",\n34 policy_type=\"smolvla\",\n35 pretrained_name_or_path=\"fracapuano/smolvla_async\",\n36 chunk_size_threshold =0.5, # g\n37 actions_per_chunk =50, # make sure this is less than the max actions of the policy\n38 )\n39\n40 # 4. Create and start client\n41 client = RobotClient(client_cfg)\n42\n43 # 5. Provide a textual description of the task\n44 task = ...",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_9fd354dfbd5545eb802a620a1590c791": {
    "id": "parent_9fd354dfbd5545eb802a620a1590c791",
    "metadata": {
      "content": "client = RobotClient(client_cfg)\n42\n43 # 5. Provide a textual description of the task\n44 task = ...\n45\n46 if client.start ():\n47 # Start action receiver thread\n48 action_receiver_thread = threading.Thread(target=client.receive_actions , daemon=True)\n49 action_receiver_thread.start()\n50\n51 try:\n52 # Run the control loop\n53 client.control_loop(task)\n54 except KeyboardInterrupt:\n55 client.stop()\n56 action_receiver_thread.join()\n57 # (Optionally) plot the action queue size\n58 visualize_action_queue_size(client.action_queue_size)\n\n56\n\n\n\nFigure 34 | Fields within ML such as Computer Vision and NLP converged on the development of foundation models, trained\non a variety of large scale models and capable to perform multiple downstream tasks (top). Conversely, robotics suffered from\nlimited standardization in terms of the architectures used, and siloed, task specific datasets, incurring in a high degree of\nfragmentation which traditionally hindered the development of generalist models for roboti",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c4eefb296d524f0ca9873cc41abda5df": {
    "id": "parent_c4eefb296d524f0ca9873cc41abda5df",
    "metadata": {
      "content": "degree of\nfragmentation which traditionally hindered the development of generalist models for robotics in favour of task-specific models\n(bottom).\n\n5 Generalist Robot Policies\nSpecialization is for insects\n\nRobert A. Heinlein\n\nTL;DR\n\nOpenly available, large-scale datasets and the development of stable-to-train, expressive and efficient architectures\nfostered research on the development of generalist robot policies that can operate across embodiment and tasks.\n\nThe advent of large models trained on internet-scale datasets has drastically influenced fields like Computer Vision\n(CV) and Natural Language Processing (NLP), shifting the previously task-specific paradigm towards combining (1) an\ninitial, task-agnostic large-scale pre-training stage and a (2) task-specific, adjustment phase. This pre-train-and-adaptat\nparadigm has now largely replaced more classic approaches consisting of task-specific data collection, curation and\nmodel training in many subdomains within CV and NLP, and it is",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_0fff067c65ae492c9a25c4a74a79ab33": {
    "id": "parent_0fff067c65ae492c9a25c4a74a79ab33",
    "metadata": {
      "content": "pecific data collection, curation and\nmodel training in many subdomains within CV and NLP, and it is motivated by the main drawback of limited\nscalability for task-specific approaches, which have been traditionally more labor intensive. Factors including (1)\nthe advancements in generalist models learned with self-supervision for perception (Oquab et al., 2024) or semantic\nunderstanding (Devlin et al., 2019) and (2) the popularization of collective efforts to aggregate large-scale openly\navailable datasets (O\u2019Neill et al., 2025; Khazatsky et al., 2025) are increasingly pushing the field of robot learning\ntowards the pre-train-and-adapt paradigm. This shift taps into the long-standing challenge of developing generalist\nrobot policies, and holds the premise to surpass traditionally siloed approaches to robotics problems and develop\na foundation robotics model. While Section 4 introduced methods for learning single-task policies such as ACT\nor Diffusion Policy, in this section we present a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1a159ddf050e46499ed6cc2a210092cb": {
    "id": "parent_1a159ddf050e46499ed6cc2a210092cb",
    "metadata": {
      "content": "hods for learning single-task policies such as ACT\nor Diffusion Policy, in this section we present advancements in developing generalist, multi-task, policies, capable\nof performing a wide range of tasks across different environments and embodiments, and guided by unstructured\ninstructions typically given in plain, natural language.\n\n57\n\n\n\nFigure 35 | Early efforts in the development of generalist models for robotics include BC-Zero (Jang et al., 2022), RT-1 (Brohan\net al., 2023b), and RT-2 (Brohan et al., 2023a): large scale models trained on thousands of demonstrations. The open release\nof the Open-X (O\u2019Neill et al., 2025) and DROID datasets (Khazatsky et al., 2025) fostered the development of open source\nmodels: OpenVLA (Kim et al., 2024), \u03c00 (Black et al., 2024) and SmolVLA (Shukor et al., 2025).\n\n5.1 Preliminaries: Models and Data\nThe remarkable success of foundation models in NLP and CV seems to be increasingly predicated on two core\nprinciples: architectural innovation and (join",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_909a3d523af5403d95baface47a7d2ae": {
    "id": "parent_909a3d523af5403d95baface47a7d2ae",
    "metadata": {
      "content": "nd CV seems to be increasingly predicated on two core\nprinciples: architectural innovation and (joint) data-compute scaling. Indeed, the transformer architecture proved very\neffective in capturing long-range dependencies in a variety of data formats, and its stability and expressivity made it\nthe de facto standard for modern large-scale models trained on internet-scale datasets. However, in stark contrast with\nlarge-scale NLP and CV datasets (Raffel et al., 2023; Deng et al., 2009), robotics has historically developed around\nsmall, task-specific datasets. In turn, this traditionally hindered scalability across problems as well as results, posing\nconcrete challenges to developing general-purpose robot learning algorithms. Indeed, differently from the wealth\nof relatively readily-available task-agnostic text and images datasets on the internet, robotics data is intrinsically\nembodied and thus task-specific: datasets collected for manipulation differ significantly from locomotion. In part",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_bc713e87295143389909ba8bee2a53f4": {
    "id": "parent_bc713e87295143389909ba8bee2a53f4",
    "metadata": {
      "content": "hus task-specific: datasets collected for manipulation differ significantly from locomotion. In particular,\nsince each expert trajectory is tied to a specific robot platform and the operating conditions of its environment\nand task, data heterogeneity has long posed a methodological challenge for scaling robotics datasets via aggregation.\nFurther, datasets consisting of expert demonstrations are (1) intrinsically more expensive to collect and (2) notoriously\nheterogeneous\u2014different human experts may perform the same task in very different. Beyond this, heterogeneity also\nraises conceptual issues: naively mixing data across embodiments can induce negative transfer, as control strategies\ndeveloped in isolation for different robot systems in different environments may even conflict when combined. Thus,\nthe high degree of fragmentation of robotics datasets and tasks has traditionally led to the development of specialist\npolicies, trained on small, task-specific datasets, developed to perfor",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f8ceeff3ea86462aac219d8ddf94c727": {
    "id": "parent_f8ceeff3ea86462aac219d8ddf94c727",
    "metadata": {
      "content": "he development of specialist\npolicies, trained on small, task-specific datasets, developed to perform well at their designated task but that fail to\ngeneralize to new deployment scenarios (Figure 34).\nDriven by the goal of developing generalist robot policies, the research community has increasingly explored how\ninsights and techniques from other areas of ML can be integrated into robotics. Figure 35 shows a timeline of some\nof the most popular contributions attempting at developing generalist policies. Starting from BC-Zero, a latent\nvariable model trained on 25k+ demonstrations, the field has now evolved into \u03c00, a transformer-based model trained\non 10M+ demonstrations and exhibiting strong few-shot capabilities across tasks and embodiments. In between,\nRobotics Transformer 1 (RT-1) (Brohan et al., 2023b) represented a significant step in the direction of developing a\ngeneralist robot policies over prior work including (1) BC-Zero (Jang et al., 2022) and (2) Gato (Reed et al., 2022),",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_044896256dda4b7cb85b0d7bdde4685b": {
    "id": "parent_044896256dda4b7cb85b0d7bdde4685b",
    "metadata": {
      "content": "policies over prior work including (1) BC-Zero (Jang et al., 2022) and (2) Gato (Reed et al., 2022), in\nthat Brohan et al. (2023b) use a much larger and diverse set of training tasks compared to both BC-Zero and Gato.\nIn particular, RT-1 uses a transformer architecture, and is trained on as many as 130k human-recorded trajectories\ncollected over 13 robots and over 17 months. RT-1 learns to process a history of camera images and a natural language\ninstruction, and feeds the resulting sequence of high-dimensional tokens to a transformer, trained using a classification\nloss on a discretized actions space consisting of six different 256-bins, one for each joint of a 6-dof robotic arm.\nIn a follow-up work, the same group of authors propose a modified method to learn generalist models, leveraging (1)\na more powerful architecture and (2) scaling up the dataset used (Brohan et al., 2023a, RT-2). In RT-2, Brohan et al.\n(2023a) propose inheriting internet-scale semantic knowledge from large-scal",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3baebb778b2044968b15cbd290ec8e64": {
    "id": "parent_3baebb778b2044968b15cbd290ec8e64",
    "metadata": {
      "content": "In RT-2, Brohan et al.\n(2023a) propose inheriting internet-scale semantic knowledge from large-scale multi-modal datasets to learn a single,\nunified model for robotics control. Such a model, termed Vision-Language-Action (VLA) in the original RT-2 paper,\neffectively casts robot control as a language-modeling problem, and in particular as a Visual Question-Answering\n(VQ&A) task, in which the output token space used to represent textual tokens is shared with the 8-bits tokens used\n\n58\n\n\n\nFigure 36 | Robot learning is undergoing a paradigmatic shift: centralized data collections (A, left) are increasingly larger,\noften comprising millions of demonstrations, while (A, right) decentralized data collection efforts are becoming an alternative for\nlarge scale data collection. (B) Generalist models are also becoming increasingly smaller and easier to run on limited hardware.\n\nto represent the 256 (28) actuation levels of a 6-dof robot. In their work, Brohan et al. (2023a) propose co-fine-tunin",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_dfb7d403ad7e4d6391aa9160e8c0d6c6": {
    "id": "parent_dfb7d403ad7e4d6391aa9160e8c0d6c6",
    "metadata": {
      "content": "6 (28) actuation levels of a 6-dof robot. In their work, Brohan et al. (2023a) propose co-fine-tuning\nlarge-scale VLMs such as PaLIX (Chen et al., 2023) or PaLM-E (Driess et al., 2023) on a mix of (1) web and (2)\nrobotics data, complementing VQ&A training with robotics-specific signal, and learning to directly output robot\nactions in a shared token space for visual and language inputs. In their work, the authors claim using large models\ntrained on internet-scale data as backbones for VLAs allows models to tap into the rich semantic knowledge embedded\nin the VLM\u2019s parameters, interpreting instructions and unseen objects by connecting them to concepts acquired while\npre-training. For instance, Brohan et al. (2023a) show that while RT-2 has never been explicitly trained to repurpose\ntools for a hammering task, it can still combine its semantic understanding of images, so that when asked which\nobject between (1) a piece of paper, (2) a pair of headphones or (3) a rock may be used instead o",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a7dab526894f4d39ac5b500e70f95d30": {
    "id": "parent_a7dab526894f4d39ac5b500e70f95d30",
    "metadata": {
      "content": "ch\nobject between (1) a piece of paper, (2) a pair of headphones or (3) a rock may be used instead of a hammer, it\ncorrectly answers (3).\nTraditionally, research efforts revolved around not only training models, but also proposing datasets for the community,\na costly and time-consuming process. Due to the aforementioned embodiment gap, the data used in research efforts in\nrobot learning have traditionally proved rather fragmented, tailored to the specific task considered by the specific group\nof researchers who collected it, which ultimately hindered integration. The Open X-Embodiment project (O\u2019Neill et al.,\n2025) was a landmark collaboration effort to address data fragmentation, by curating the aggregation of 60 existing\nrobotics datasets from 22 different robot embodiments and 21 institutions across the world, and resulted in a total 1.4M\nof cross-embodiments, cross-tasks, openly-available trajectories. Besides the contribution of an aggregate, large scale\ndataset, O\u2019Neill et al. (2",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d05559c0daf64d089cad44505b1d15bf": {
    "id": "parent_d05559c0daf64d089cad44505b1d15bf",
    "metadata": {
      "content": "lable trajectories. Besides the contribution of an aggregate, large scale\ndataset, O\u2019Neill et al. (2025) also demonstrated significant positive transfer across tasks and embodiments, showing\nthat a single model trained on multi-embodiment data can outperform specialist models trained on their respective\nsingle-embodiment datasets. The Distributed Robot Interaction Dataset (DROID) (Khazatsky et al., 2025) represents\nanother significant step towards addressing the problem of scarse and disaggregated data in robot learning, providing\na unique dataset consisting of 75k+ human demonstrations collected in realistic (in-the-wild) manipulation settings,\nproviding another cornerstone for building general-purpose robot policies. Recently, foundational datasets curated\nthrough large, centralized efforts, are increasingly complemented by decentralized, community-driven contributions of\nrobotics data. Software libraries like lerobot have been instrumental in enabling decentralized collection of lar",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f7926509b70e454e8c983d3007c523f7": {
    "id": "parent_f7926509b70e454e8c983d3007c523f7",
    "metadata": {
      "content": ". Software libraries like lerobot have been instrumental in enabling decentralized collection of large\namounts of data, providing the infrastructure for researchers and practitioners to easily contribute trajectories from a\nwide range of embodiments, democratizing data access via distributed collection.\nDespite these advancements, the success of large, proprietary models like RT-1 and RT-2, highlighted a growing\naccessibility gap in robotics research, as training and deploying large-scale robotics foundation models requires\ncomputational resources simply unattainable for most research institutions. The OpenVLA project (Kim et al.,\n2024) emerged in direct contrast to traditionally closed-source efforts to develop VLAs. In particular, Kim et al.\n(2024) trained OpenVLA by exclusively leveraging openly available data (970k+ trajectories from the Open-X\ndataset), and openly shared their training recipes alongside the model weights. Architecturally, OpenVLA integrates\na pre-trained vision en",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_658b2a677f294e5aacf21d879308ba88": {
    "id": "parent_658b2a677f294e5aacf21d879308ba88",
    "metadata": {
      "content": "ing recipes alongside the model weights. Architecturally, OpenVLA integrates\na pre-trained vision encoder to project visual tokens into the embedding space of the Llama2-7B (Touvron et al.,\n2023) language-model backbone. The language model backbone is then used to predict discrete action tokens over\n256 activation levels.\nFigure 36 shows the current trends in robot learning in terms of size and nature of the robotics datasets contributed,\ntogether with the size and accessibility of the available models. As datasets collected via centralized, cross-institutions\ncooperation of increasing size are made available for the research community, decentralized datasets collected by\nindividual researchers and practitioners also gained traction, closing the gap with academic benchmarks thanks to\n\n59\n\n\n\ncommunity-contributed datasets. Further, models used across tasks and embodiments are increasingly becoming much\nmore compute-efficient, and as a result the models\u2019 size has been consistently reduci",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f2c4a6d289144cc6a9c5534e2480eeac": {
    "id": "parent_f2c4a6d289144cc6a9c5534e2480eeac",
    "metadata": {
      "content": "becoming much\nmore compute-efficient, and as a result the models\u2019 size has been consistently reducing over time, with consequent\ngains for autonomous robots in real-world, resource-constrained environments.\n\n5.2 VLAs\nModern recipes to train large scale VLAs extend early efforts to learn foundation models from large amounts of data via\nBC, introducing significant advancements concerning both architectural and procedural aspects. From an architectural\nperspective, modern VLAs such as \u03c00 (Black et al., 2024) leverage a unified transformer model for efficiency of\ncomputation, while maintaining specialized sub-components within the model for visual perception and action\nprediction, enabling cross-task performance via language conditioning. Crucially, modern VLAs including\u03c00 (Black\net al., 2024) and SmolVLA (Shukor et al., 2025) adopt unified transformer models employing disjoint set of weights\n(experts) for both compute-efficient visual-semantic understanding as well as control. Procedural",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e6f663274c294204b8f0ca6634edece5": {
    "id": "parent_e6f663274c294204b8f0ca6634edece5",
    "metadata": {
      "content": "ts\n(experts) for both compute-efficient visual-semantic understanding as well as control. Procedurally, VLAs complement\nadvanced Vision-Language Model (VLM) backbones with action-specific modules (1) adopting mid-sized action experts\nto model continuous actions distributions p(at:t+Ha |ot)\u2014avoiding discrete action tokens entirely\u2014and (2) relying\non action chunking (Zhao et al., 2023, Section 4) as a strategy to reduce error compounding when predicting multiple\nactions learning from inherently non-i.i.d. data, such as demonstration data.\nThese architectural and procedural innovations present three benefits over task-specific methods. First, developing\narchitectures that exploit internet-scale pre-trained backbones allows to fully capitalize on the vast world knowledge\nand skills state-of-the-art VLMs exhibit, preventig models from needing to learn visual, linguistic and semantic\nconcepts from scratch. Second, using generative models for continuous action distributions allows to learn ri",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b7489383ee7d46249609dfdd298eddaa": {
    "id": "parent_b7489383ee7d46249609dfdd298eddaa",
    "metadata": {
      "content": "from scratch. Second, using generative models for continuous action distributions allows to learn rich,\nmultimodal data distributions, a much more likely scenario in the big-data regime which is typically tackled while\ndeveloping generalist policies. Further, introducing separate components for perception and action planning enable\nusing Mixture of Experts (MoE) architectures (Fedus et al., 2022), which are often more efficient to run\u2014a key\nfeature for models deployed in real-world scenarios. This new paradigm has been at the core of some of the most\ncapable generalist policies developed to date, capable to few-shot adapt to novel tasks and to perform highly dexterous\nmanipulation tasks ranging from end-to-end folding laundry to bussing tables (Black et al., 2024).\n\n5.2.1 VLMs for VLAs\nVLMs are designed to handle both visual and textual modalities, most commonly by taking both images and text as\ninputs, generating text conditioned on the visual context. Recent advances in VLMs have bee",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2aa7e0af9bda4e36bd76270d1d396de8": {
    "id": "parent_2aa7e0af9bda4e36bd76270d1d396de8",
    "metadata": {
      "content": "text as\ninputs, generating text conditioned on the visual context. Recent advances in VLMs have been driven by the success\nof LLMs, with many approaches building upon pretrained LLMs and adopting similar training paradigms to the\nones used in language modeling. Typically, VLMs (Alayrac et al., 2022; Lauren\u00e7on et al., 2024; Lin et al., 2024) are\nconstructed by integrating a pretrained vision encoder (Radford et al., 2021; Zhai et al., 2023; Fini et al., 2024) with\na pretrained LLM (Grattafiori et al., 2024; Jiang et al., 2023). Training then proceeds in multiple multimodal stages,\nbeginning with a large-scale pretraining on datasets containing image-text pairs (Schuhmann et al., 2022; Byeon et al.,\n2022) and interleaved vision-language corpora (Lauren\u00e7on et al., 2023; Zhu et al., 2023), all followed by a supervised\nfine-tuning stage on instruction-tuning datasets (Liu et al., 2023; Tong et al., 2024; Lauren\u00e7on et al., 2024). The\ninherent multimodal nature of VLMs enables them to jointl",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c64d5bd834d344fca4a8e2eacfe421ee": {
    "id": "parent_c64d5bd834d344fca4a8e2eacfe421ee",
    "metadata": {
      "content": "et al., 2024; Lauren\u00e7on et al., 2024). The\ninherent multimodal nature of VLMs enables them to jointly reason over vision and language. Pre-training on vast\ninternet-scale datasets allows these models to associate visual patterns with textual descriptions, thereby acquiring a\nrich semantic understanding of the world\u2014knowledge about objects, their properties, and relationships\u2014without\nexplicit supervision for each concept. In turn, integrating VLMs as the perceptual backbone for VLAs allows the\nlatter to inherit rich, contextual world knowledge from the VLM, sidestepping the need to re-learn visual and semantic\nrepresentations. In principle, this also allows the robot to ground high-level natural language instructions in its visual\ncontext, and possibly recognize objects by connecting them to the pre-trained concepts absorbed during pre-training,\nimproving on the possibility to generalize to novel scenarios.\nRecently, compute efficiency has also become a central focus in multi-modal rese",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7622c508a2f34b529e81f350aa6f86c7": {
    "id": "parent_7622c508a2f34b529e81f350aa6f86c7",
    "metadata": {
      "content": "to novel scenarios.\nRecently, compute efficiency has also become a central focus in multi-modal research. Several works aim to reduce\ntraining costs by using smaller, more diverse datasets (Liu et al., 2023; Dai et al., 2023; Bai et al., 2025; Zhu et al.,\n2024; Tong et al., 2024), training smaller-scale models (Marafioti et al., 2025; Korrapati, 2024; Yao et al., 2024), or by\nadapting pretrained unimodal models by tuning only a small subset of parameters (Shukor et al., 2023; Vallaeys et al.,\n2024; Ma\u00f1as et al., 2023; Koh et al., 2023; Tsimpoukelli et al., 2021; Li et al., 2023). While the majority of VLM\nresearch focuses on image and text modalities, recent work has also demonstrated that similar techniques can be\nextended to integrate additional modalities, such as video and audio (Wang et al., 2025; Liu et al., 2024; Zhang et al.,\n2025; Kong et al., 2024)\u2014a particularly promising direction of research for robotics applications, where multiple\nsensor modalities can be integrated effe",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_5163099a1d704b7382a1ca4333da6cee": {
    "id": "parent_5163099a1d704b7382a1ca4333da6cee",
    "metadata": {
      "content": "ction of research for robotics applications, where multiple\nsensor modalities can be integrated effectively. This trend towards efficiency is paramount for robotics applications,\nwhere policies must operate under the stringent constraints of real-world deployment.\n\n60\n\n\n\nFigure 37 | The \u03c00 architecture, as in Black et al. (2024). Vision and language tokens are routed to a VLM backbone which\nis prevented from attending robot proprioperceptive states and action tokens, which are instead routed to a smaller subset\nof weights within the architecture referred to as \"action expert\". The architecture is trained with Flow Matching on 10M+\ntrajectories from a mixture of closed and openly available datasets.\n\n5.3 \u03c00\n\n\u03c00 (Black et al., 2024) introduce a VLA consisting of a MoE architecture consisting of (1) a pre-trained VLM backbone\n(Gemma 2.6B (Team et al., 2024)) and (2) a dedicated action expert used to generate continuous actions via flow\nmatching. Images and language are embedded with PaliG",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d6027722a13b43a49ba7fd81f2cb534c": {
    "id": "parent_d6027722a13b43a49ba7fd81f2cb534c",
    "metadata": {
      "content": "t used to generate continuous actions via flow\nmatching. Images and language are embedded with PaliGemma, a VLM merging independently encoded visual and\ntextual features deep in the network (late-fusion), while proprioceptive state and actions chunks are routed to a\nsmaller action expert, initialized from scratch. The two separate experts communicate via self-attention layers, but\nmaintain disjoint weights to obtain query, key and values matrices at each layer, maintaining specialization while\nefficiently allocating computation.\nConcretely, \u03c00 is a single, unified transformer with two disjoint sets of weights \u03d5, \u03b8. A larger VLM backbone f\u03d5\ninitialized from Gemma 2.6B processes multiple image frames obtained from multiple cameras points [{It}nt=1], as\nwell as a language instruction [\u2113t] used to describe the task considered. Concurrently, a 300M-parameter action expert\nbased on a similar transformer architecture is used to process both the robot proprioperceptive state qt and an action\nc",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_aa4e854a28e9451a97cf5fc076adba9a": {
    "id": "parent_aa4e854a28e9451a97cf5fc076adba9a",
    "metadata": {
      "content": "ransformer architecture is used to process both the robot proprioperceptive state qt and an action\nchunk at:t+H (Figure 37). The different expert networks operate separately in processing the respective inputs and\n\na\n\nturn them into query, key and value matrices, and only share information between each other via self-attention layers.\nThe outputs from the VLM backbone are disregarded, while the vector field regressed by the action expert is used to\niteratively refine the action process. In particular, \u03c00 uses a blockwise causal attention mask over tokens belonging to\nthree separate blocks: (1) image and language tokens Ti obtained from [{It}nt=1, \u2113t], (2) proprioperceptive tokens Tq\nobtained from qt, and (3) the action tokens Ta for items in the chunk a\u03c4t:t+H at time \u03c4 in the flow-matching process.\n\na\n\nNotably, within each block the attention operations are bidirectional, while across blocks, future blocks are masked\nout. Formally, this corresponds to using an attention mask like:\n\n\uf8eb T",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_201fc6150d9e4ee4917a25a8be8b8053": {
    "id": "parent_201fc6150d9e4ee4917a25a8be8b8053",
    "metadata": {
      "content": "ocks, future blocks are masked\nout. Formally, this corresponds to using an attention mask like:\n\n\uf8eb Ti Tq Ta\uf8f6\nTi\n\nA \uf8ed 1 0 0\n= T \uf8f8\n\nq 1 1 0 , 1 : Bidirectional Attention, 0 : Masked Attention\nTa 1 1 1\n\nNote how intra-block directional attention allows tokens to communicate freely, while inter -block communication is\nmediated by the attention mask A. Blockwise causal masking effectively prevents the pre-trained perception-language\ntokens from attending to robotics-tokens, likely out of distribution for VLM backbones traditionally trained on large\ncorpora of internet, non-robotics, data. Crucially, because communication is obstructed between image-language\ntokens, proprioperceptive tokens and action tokens, one can cache keys and values across denoising steps at runtime\ntime, incuring in a reduced computational footprint and faster inference.\n\n61\n\n\n\nIn \u03c00, both the VLM backbone and action expert are update using a flow matching loss, and in particular are updated\nminimizing: [\u2225\n\nL(\u03d5, \u03b8) =",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d7e8c12a4880437da9e44c5909c40b43": {
    "id": "parent_d7e8c12a4880437da9e44c5909c40b43",
    "metadata": {
      "content": "pert are update using a flow matching loss, and in particular are updated\nminimizing: [\u2225\n\nL(\u03d5, \u03b8) = E \u2225 \u2225 ]\n\u03c4,\u03f5,o v\n\nt,at:t+Ha \u03b8(\ufe38\u03c4at:t+H \ufe37+\ufe37 (1\u2212 \u03c4)\u03f5, o \u2212 2\n(\u03f5\u2212 a \u2225\n\na \ufe38 t, \u03c4) t:t+H ) , (52)\na\n\na\u0303t:t+Ha\n\n\u03c4 \u223c Beta[0,s](1.5, 1), \u03f5 \u223c N (0, I), ot, at:t+Ha \u223c D\nwhere the two experts parametrized by the separate weights \u03d5, \u03b8 interact with each other via self-attention layers only, so\nthat the action expert v\u03b8 internal computations also depend on the VLM backbone\u2019s parameters \u03d5. Importantly, Black\net al. (2024) minimize eq. 52 over both the multimodal backbone and action expert parameters, thus updating both\nthe internal representations of the VLM and action-expert weights using BC-specific gradients. In contrast, Driess\net al. (2025) later show that failing to insulate the VLM knowledge from the flow matching gradients actually harms\nperformance.\nAt runtime, inference is performed iteratively refining action chunks while numerically forward-integrating the vector\nfield predicted by the actio",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d8b9d410f1c54868ac70fdf6ed814354": {
    "id": "parent_d8b9d410f1c54868ac70fdf6ed814354",
    "metadata": {
      "content": "refining action chunks while numerically forward-integrating the vector\nfield predicted by the action expert,\n\na\u03c4+\u03b4\nt:t+H = a\u03c4 , o ) (53)\n\na t:t+H + \u03b4v (a\u03c4\na \u03b8 t:t+Ha t\n\nFlow matching (Lipman et al., 2023, Section4.1.3) can be seen as a continuous time, deterministic generalization\nof diffusion processes, and has proven effective in modeling highly complex multi-modal distributions, including\nthose over images and video. In turn, the application of flow matching to large-scale datasets of multiple human\nbehaviors across tasks and embodiments appears rather consequential, particularly considering how it can enable\nfaster inference via a limited number of denoising steps at test time\u2014as few as 10, in \u03c00. In particular, the action\nexpert is implemented as a conditional flow matching model. Each action token embeds a noisy action a\u03c4i \u2208 a\u03c4t:t+H ,\n\na\n\nalongside a sinusoidal encoding of the flow process timestep \u03c4 . The action expert then leverages full bidirectional\nattention across the Ha a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_3b6340870d454ceb97f2d8aea28b9f6d": {
    "id": "parent_3b6340870d454ceb97f2d8aea28b9f6d",
    "metadata": {
      "content": "w process timestep \u03c4 . The action expert then leverages full bidirectional\nattention across the Ha action tokens provided, and also attends to previous proprioperceptive and image-language\ntokens. Interestingly, differently from a standard flow matching pipeline (Lipman et al., 2023), \u03c4 is not sampled from\na uniform distribution \u03c4 \u223c U([0, 1]), but rather obtained from \u03c4 \u223c Beta(1.5, 1) defined on the [0, s], s < 1 support\n(Figure 38).\nUsing such Beta distribution emphasizes higher noise levels dur-\ning training, a choice Black et al. (2024) argue allows \u03c00 to fo-\ncus on learning to reconstruct the mean of the data distribution\nE[at:t+Ha |ot] over an identity map during training, in keeping\nwith Esser et al. (2024). To further optimize performance and\nreduce inference time, Black et al. (2024) propose reducing the\nsupport of the timestep distribution to [0, s], s < 1, as for any\nforward-integration step size \u03b4 = 1\u2212 s timesteps above s are never\nsampled at inference time.\nBesides adopting",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7a4e60d6459f47d7bdd8619eb3942f95": {
    "id": "parent_7a4e60d6459f47d7bdd8619eb3942f95",
    "metadata": {
      "content": "tegration step size \u03b4 = 1\u2212 s timesteps above s are never\nsampled at inference time.\nBesides adopting a MoE architecture with a VLM backbone initial-\nized from a pre-trained model and trained jointly with an action\nexpert via flow matching, \u03c00 also relies on a unique pre-training\ncorpus comprising of a mix of proprietary and open data totaling Figure 38 | Unlike more traditional flow-matching\n10M+ trajectories, which in their work Black et al. (2024) claim algorithms, \u03c00 uses a modified distribution to sam-\nto be the largest dataset used to develop a foundational robotics ple the timestep \u03c4 from during training and infer-\nmodel to date. The dataset used to train \u03c00\u2014referred to as \"the ence, favouring earlier timestamps corresponding\n\u03c0 dataset\"\u2014comprises a private, undisclosed portion obtained via to noisier chunks.\nexpert teleoperation as well as openly available datasets including\nOpen-X and DROID, with only \u2248 9.1% of the \u03c0 being openly\navailable. In the \u03c0 dataset, open datasets such a",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_add6dbdd5842482a89e0e096e0a0cf0c": {
    "id": "parent_add6dbdd5842482a89e0e096e0a0cf0c",
    "metadata": {
      "content": "and DROID, with only \u2248 9.1% of the \u03c0 being openly\navailable. In the \u03c0 dataset, open datasets such as DROID and Open-X are complemeneted with expert trajectories\nconsisting of dexterous demonstrations tasks spanning 7 robot configurations and 68 different tasks. Crucially, Black\net al. (2024) show that pre-training on the \u03c0 dataset yields a broadly capable base model, which can be adapted\nvia fine-tuning on narrower, higher-quality task data, which induces a fluent multi-stage behavior while retaining\nrobustness. In particular, Black et al. (2024) report that, across a variety of benchmarks, the version of \u03c00 pretrained\non the \u03c0 dataset and fine-tuned on extra high-quality data demonstrations consistently outperforms a \u03c0scratch\n\n0 baseline\ntrained entirely from scratch for a given specific task, which further underscores the relevance of pretraining on the \u03c0\ndataset. Black et al. (2024) do also offer an intuition behind this finding: high-quality demonstrations of a given task\n\n62\n\n\n\nt",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2eaf671f342a4da1a7b06bbaebc8e966": {
    "id": "parent_2eaf671f342a4da1a7b06bbaebc8e966",
    "metadata": {
      "content": "do also offer an intuition behind this finding: high-quality demonstrations of a given task\n\n62\n\n\n\ntend to omit failure data, which inherently prevents an autonomous agent to learn how to recover from near-failure\nstates. In turn, robot trained on high-quality data exclusively with BC may as well be entirely incapable to recover\nfrom failure. Conversely, large scale collections of human demonstrations are typically much more diverse (if anything,\nfor their sheer scale), and typically contain rich and diverse information, which may prove suboptimal for any given\ntask when considered in isolation but which proves invaluable in coupling with a small, narrower set of demonstrations.\nLastly, Black et al. (2024) present cross-embodiment experiments where they demonstrate \u03c00\u2019s ability to control\nboth mobile and static manipulator robots with varying arm embodiments. The emergence of cross-embodiment\ncapabilities is largely to be attributed to the presence of large scale cross-embodiment data",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e215b99ab041408bb1b3d0ee7c2cdb01": {
    "id": "parent_e215b99ab041408bb1b3d0ee7c2cdb01",
    "metadata": {
      "content": "iment\ncapabilities is largely to be attributed to the presence of large scale cross-embodiment data in \u03c0 data mixture, which\nis in practice handled by \u03c00 outputting actions with maximal configuration size across the whole \u03c0 dataset, and\nzero-padding robots with fewer dofs. \u03c00 does also rely on exactly three camera views at both training and test time,\nand uses masked image slots for training and deployment scenarios with fewer cameras.\n\n5.3.1 Code Example: Using \u03c00\n\nCode 13: Using \u03c00\n\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch5/01_using_pi0.py\n\n1 import torch\n2\n3 from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig\n4 from lerobot.datasets.utils import hw_to_dataset_features\n5 from lerobot.policies.factory import make_pre_post_processors\n6 from lerobot.policies.pi0.modeling_pi0 import PI0Policy\n7 from lerobot.policies.utils import build_inference_frame , make_robot_action\n8 from lerobot.robots.so100_follower.config_so100_follower im",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d6a81b0852534b6e9996f4bfa33cf78c": {
    "id": "parent_d6a81b0852534b6e9996f4bfa33cf78c",
    "metadata": {
      "content": "ld_inference_frame , make_robot_action\n8 from lerobot.robots.so100_follower.config_so100_follower import SO100FollowerConfig\n9 from lerobot.robots.so100_follower.so100_follower import SO100Follower\n\n10\n11 MAX_EPISODES = 5\n12 MAX_STEPS_PER_EPISODE = 20\n13\n14 device = torch.device(\"mps\") # or \"cuda\" or \"cpu\"\n15 model_id = \"lerobot/pi0_base\"\n16\n17 model = PI0Policy.from_pretrained(model_id)\n18\n19 preprocess , postprocess = make_pre_post_processors(\n20 model.config ,\n21 model_id ,\n22 # This overrides allows to run on MPS , otherwise defaults to CUDA (if available)\n23 preprocessor_overrides ={\"device_processor\": {\"device\": \"mps\"}},\n24 )\n25\n26 # find ports using lerobot -find -port\n27 follower_port = ... # something like \"/dev/tty.usbmodem58760431631\"\n28\n29 # the robot ids are used the load the right calibration files\n30 follower_id = ... # something like \"follower_so100\"\n31\n32 # Robot and environment configuration\n33 # Camera keys must match the name and resolutions of the ones used for tra",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d39b12aa3bbb45a989f3c46e093999f9": {
    "id": "parent_d39b12aa3bbb45a989f3c46e093999f9",
    "metadata": {
      "content": "ironment configuration\n33 # Camera keys must match the name and resolutions of the ones used for training!\n34 # You can check the camera keys expected by a model in the info.json card on the Hub\n35 camera_config = {\n36 \"base_0_rgb\": OpenCVCameraConfig(index_or_path =0, width =640, height =480, fps=30),\n37 \"left_wrist_0_rgb\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps=30),\n38 \"right_wrist_0_rgb\": OpenCVCameraConfig(index_or_path =2, width =640, height =480, fps=30),\n39 }\n40\n41 robot_cfg = SO100FollowerConfig(port=follower_port , id=follower_id , cameras=camera_config)\n42 robot = SO100Follower(robot_cfg)\n43 robot.connect ()\n44\n45 task = ... # something like \"pick the red block\"\n46 robot_type = ... # something like \"so100_follower\" for multi -embodiment datasets\n47\n\n63\n\n\n\nFigure 39 | The SmolVLA architecture, as in Shukor et al. (2025). SmolVLA is a compact MoE model trained with flow\nmatching to denoise action chunks. Vision and language tokens are fed to a VLM bac",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_9624b39663894c2986edd88dee105dca": {
    "id": "parent_9624b39663894c2986edd88dee105dca",
    "metadata": {
      "content": "trained with flow\nmatching to denoise action chunks. Vision and language tokens are fed to a VLM backbone, and share information with the\nproprioperceptive and action tokens via the attention mechanism. The attention expert interleaves SA and CA layers for\nfurther conditioning on the visual features from the VLM backbone. SmolVLA skips computations and reduces the visual\ntokens, resulting in 7x less memory usage than \u03c00 (450M parameters vs. \u03c00\u2019s 3.3B).\n\n48 # This is used to match the raw observation keys to the keys expected by the policy\n49 action_features = hw_to_dataset_features(robot.action_features , \"action\")\n50 obs_features = hw_to_dataset_features(robot.observation_features , \"observation\")\n51 dataset_features = {** action_features , ** obs_features}\n52\n53 for _ in range(MAX_EPISODES ):\n54 for _ in range(MAX_STEPS_PER_EPISODE ):\n55 obs = robot.get_observation ()\n56 obs_frame = build_inference_frame(\n57 obs , dataset_features , device , task=task , robot_type=robot_type\n58 )\n59",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_89d9dccdfbef4f73bb0486eb8e325564": {
    "id": "parent_89d9dccdfbef4f73bb0486eb8e325564",
    "metadata": {
      "content": "ild_inference_frame(\n57 obs , dataset_features , device , task=task , robot_type=robot_type\n58 )\n59\n60 obs = preprocess(obs_frame)\n61\n62 action = model.select_action(obs)\n63 action = postprocess(action)\n64 action = make_robot_action(action , dataset_features)\n65 robot.send_action(action)\n66\n67 print(\"Episode finished! Starting new episode ...\")\n\n5.4 SmolVLA\nWith VLAs in the early stage of development compared to more mature LLMs and VLMs, much of the progress\nmade on VLAs remains proprietary, with many releases exclusively sharing the weights while withholding the data\nused, full experimental details and essential methodological components of training. In constrast with this closed\napproach, SmolVLA (Shukor et al., 2025) is an entirely open-source research effort, which aims at democratizing\nthe developments of robotics foundation models by open sourcing the model alongside the data used as well as the\ntraining recipes.\nWhile encouraging efforts like \u03c00 (Black et al., 2024) demonstrate",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_5052b8be78f44d5db069f999a0f871f2": {
    "id": "parent_5052b8be78f44d5db069f999a0f871f2",
    "metadata": {
      "content": "as well as the\ntraining recipes.\nWhile encouraging efforts like \u03c00 (Black et al., 2024) demonstrate the feasibility of open VLA systems, they remain\n(1) large and compute-intensive and (2) dependent on closed datasets collected via centralized efforts on costly robotic\nplatforms, which ultimately hinders the accessibility of the method altogether. SmolVLA mitigates both these issues\nby (1) prioritizing a compact, compute-efficient VLA design and (2) targeting community-contributed datasets on\n\n64\n\n\n\naccessible robotic platforms such as the SO-100 and SO-101 arms. Similarly to \u03c00, SmolVLA (Figure 39) employs\na MoE architecture combining a pretrained VLM backbone with a dedicated action expert, and trains with flow\nmatching. To ensure efficiency and accessibility, SmolVLA adopts SmolVLM-2 (Marafioti et al., 2025) as its VLM\nbackbone, considering SmolVLM-2\u2019s reduced size and capability to process multiple image inputs alongside text items.\nSmolVLM-2 uses SigLIP (Zhai et al., 2023) as vis",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_56449c994a184ae6b5de6bfc74d3020e": {
    "id": "parent_56449c994a184ae6b5de6bfc74d3020e",
    "metadata": {
      "content": "process multiple image inputs alongside text items.\nSmolVLM-2 uses SigLIP (Zhai et al., 2023) as vision encoder, producing visual features for a SmolLM2 language\ndecoder (Allal et al., 2025). Further, SmolVLA adopts a smaller action expert consisting of \u223c100M parameters and\nan interleaved stack of self and cross-attention layers. To improve efficiency, the action expert adopts a reduced\nembedding dimension compared to the VLM backbone, resulting in dv = 0.75dVLM. Shukor et al. (2025)\u2019s design\n\n\u03b8\n\nchoices thus result in a much smaller size model compared to \u03c00, consisting of ca. 450M parameters versus \u03c00\u2019s 3.3B\nparameters.\nIn practice, SmolVLA consumes multi-view RGB images, a natural-language instruction, and projected sensorimotor\nstate token as inputs, together with the noised action chunk a\u0303t:t+Ha the action expert v\u03b8 is trained to denoise. The\nrobot proprioperceptive states are projected to a shared token space with the VLM to match dVLM, and successively\nprojected into the expert\u2019",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_53ba824fb63041bcb8306b511e888558": {
    "id": "parent_53ba824fb63041bcb8306b511e888558",
    "metadata": {
      "content": "cted to a shared token space with the VLM to match dVLM, and successively\nprojected into the expert\u2019s token space. Similarily to \u03c00, SmolVLA adopts separate experts communicating exclusively\nthrough self-attention layers, which however do not employ blockwise causal attention masking and rather favour\nsimple causal masking.\nIn contrast with \u03c00, the action expert interleaves cross-attention (CA) and self-attention (SA) layers, a choice shown\nto yield higher success and smoother action chunks in practice. While in the expert SA layers tokens are used to\nobtain queries, keys and values, CA layers use action tokens only as queries, and instead project visual, language\nand proprioperceptive tokens from the VLM backbone to a shared embedding space to then obtain keys and values.\nNotably, keys and values can be cached here as well, resulting in performance gains at inference time.\nSmolVLA also trims down both token and layer compute. First, it reduces visual tokens via pixel shuffling to a\nfi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_88d6a60a84144324b0aafe52808b91ec": {
    "id": "parent_88d6a60a84144324b0aafe52808b91ec",
    "metadata": {
      "content": "trims down both token and layer compute. First, it reduces visual tokens via pixel shuffling to a\nfixed budget of 64 tokens per frame, foregoing the tiling used during VLM pretraining for the sake of runtime\nefficiency. Second, it skips upper VLM layers, as only features from the first N decoder layers, with N = L/2, are\nconsumed, which provides a good speed-performance trade-off and effectively halves compute needs for the larger\npart of SmolVLA. Beyond model compactness, SmolVLA also contributes an inference stack that decouples action\nprediction from execution for responsiveness on modest hardware (Section 4.4).\nDeparting from reliance on proprietary datasets, SmolVLA pretrains exclusively on 450+ community datasets, totaling\n20k+ trajectories. Because instructions in community contributed dataset can be noisy or missing, the authors\nre-annotate tasks with a small off-the-shelf VLM using frames sampled from the dataset, and standardize camera\nviewpoints by mapping sources to a consi",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c771d6c05cff4ac18b8e183a125d4b4b": {
    "id": "parent_c771d6c05cff4ac18b8e183a125d4b4b",
    "metadata": {
      "content": "ing frames sampled from the dataset, and standardize camera\nviewpoints by mapping sources to a consistent top/wrist/side ordering. At test time, similarily to \u03c00, SmolVLA\nforward-integrates flow over 10 steps, resulting in fast inference. SmolVLA proves effective across a range of both real-\nworld and simulated environments, rivaling \u03c00 while being close to 40% faster and consuming 6x less memory (Shukor\net al., 2025).\n\n5.4.1 Code Example: Using SmolVLA\n\nCode 14: Using SmolVLA\nhttps://github.com/fracapuano/robot-learning-tutorial/blob/main/snippets/ch5/02_using_smolvla.py\n\n1 import torch\n2\n3 from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig\n4 from lerobot.datasets.utils import hw_to_dataset_features\n5 from lerobot.policies.factory import make_pre_post_processors\n6 from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n7 from lerobot.policies.utils import build_inference_frame , make_robot_action\n8 from lerobot.robots.so100_follower.config_so100_fol",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1708e3ad24ca4817adc5c28b300b2122": {
    "id": "parent_1708e3ad24ca4817adc5c28b300b2122",
    "metadata": {
      "content": "port build_inference_frame , make_robot_action\n8 from lerobot.robots.so100_follower.config_so100_follower import SO100FollowerConfig\n9 from lerobot.robots.so100_follower.so100_follower import SO100Follower\n\n10\n11 MAX_EPISODES = 5\n12 MAX_STEPS_PER_EPISODE = 20\n13\n14 device = torch.device(\"mps\") # or \"cuda\" or \"cpu\"\n15 model_id = \"lerobot/smolvla_base\"\n16\n\n65\n\n\n\n17 model = SmolVLAPolicy.from_pretrained(model_id)\n18\n19 preprocess , postprocess = make_pre_post_processors(\n20 model.config ,\n21 model_id ,\n22 # This overrides allows to run on MPS , otherwise defaults to CUDA (if available)\n23 preprocessor_overrides ={\"device_processor\": {\"device\": \"mps\"}},\n24 )\n25\n26 # find ports using lerobot -find -port\n27 follower_port = ... # something like \"/dev/tty.usbmodem58760431631\"\n28\n29 # the robot ids are used the load the right calibration files\n30 follower_id = ... # something like \"follower_so100\"\n31\n32 # Robot and environment configuration\n33 # Camera keys must match the name and resolutions o",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_8c06153e2d024b4dbb179e4173e90f27": {
    "id": "parent_8c06153e2d024b4dbb179e4173e90f27",
    "metadata": {
      "content": "\"\n31\n32 # Robot and environment configuration\n33 # Camera keys must match the name and resolutions of the ones used for training!\n34 # You can check the camera keys expected by a model in the info.json card on the Hub\n35 camera_config = {\n36 \"camera1\": OpenCVCameraConfig(index_or_path =0, width =640, height =480, fps=30),\n37 \"camera2\": OpenCVCameraConfig(index_or_path =1, width =640, height =480, fps=30),\n38 }\n39\n40 robot_cfg = SO100FollowerConfig(port=follower_port , id=follower_id , cameras=camera_config)\n41 robot = SO100Follower(robot_cfg)\n42 robot.connect ()\n43\n44 task = ... # something like \"pick the red block\"\n45 robot_type = ... # something like \"so100_follower\" for multi -embodiment datasets\n46\n47 # This is used to match the raw observation keys to the keys expected by the policy\n48 action_features = hw_to_dataset_features(robot.action_features , \"action\")\n49 obs_features = hw_to_dataset_features(robot.observation_features , \"observation\")\n50 dataset_features = {** action_featu",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_723386a113b2429aac38c17a60eb2432": {
    "id": "parent_723386a113b2429aac38c17a60eb2432",
    "metadata": {
      "content": "_dataset_features(robot.observation_features , \"observation\")\n50 dataset_features = {** action_features , ** obs_features}\n51\n52 for _ in range(MAX_EPISODES ):\n53 for _ in range(MAX_STEPS_PER_EPISODE ):\n54 obs = robot.get_observation ()\n55 obs_frame = build_inference_frame(\n56 obs , dataset_features , device , task=task , robot_type=robot_type\n57 )\n58\n59 obs = preprocess(obs_frame)\n60\n61 action = model.select_action(obs)\n62 action = postprocess(action)\n63 action = make_robot_action(action , dataset_features)\n64 robot.send_action(action)\n65\n66 print(\"Episode finished! Starting new episode ...\")\n\n66\n\n\n\n6 Conclusions\nThis tutorial has charted the paradigmatic shift transforming robotics, tracing the evolution of robotics from\nstructured, model-based methods to the dynamic, data-driven approaches that define modern robot learning. We\nbegan by examining the limitations of traditional dynamics-based control, namely its brittleness and significant\nengineering overhead, which motivate the adop",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a4b44ccdd9704ae1a4287496449188df": {
    "id": "parent_a4b44ccdd9704ae1a4287496449188df",
    "metadata": {
      "content": "-based control, namely its brittleness and significant\nengineering overhead, which motivate the adoption of more flexible, learning-based alternatives. Unlike scalable,\ndata-driven techniques, conventional explicit models demand extensive human expertise, hindering wider accessibility\nand scalability of robotics.\nOur exploration traced a clear trajectory of progress, beginning with Reinforcement Learning (RL). While RL offers\na powerful paradigm for learning through interaction, its application in robotics is complicated by challenges such\nas sample inefficiency, safety concerns in real-world training, and the complexities of reward design. We saw how\nmodern approaches like HIL-SERL make real-world RL more feasible by incorporating training-time human guidance,\ndatasets of previously collected data as well as learned reward classifiers.\nNonetheless, the inherent difficulties of RL increasingly motivate approaches based on imitation learning, capable to\nsafely learns from limited number",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f666444b16f4421fa12f4890defaf80d": {
    "id": "parent_f666444b16f4421fa12f4890defaf80d",
    "metadata": {
      "content": "singly motivate approaches based on imitation learning, capable to\nsafely learns from limited numbers of real-world, reward-free expert demonstrations. In turn, the wider adoption of\nimitation learning led to the development of single-task policies, where advanced Behavioral Cloning techniques\u2014\nimplemented as state-conditioned generative models like Action Chunking with Transformers and Diffusion Policy\u2014have\ndemonstrated the ability to learn complex, multimodal behaviors from human demonstrations. These advancements\nlaid the groundwork for the current frontier: generalist, language-conditioned Vision-Language-Action models capable\nto perform few- and zero-shot a variety of different real-world tasks. By leveraging powerful pre-trained backbones\nand sophisticated generative methods like flow matching, models such as \u03c00 and SmolVLA represent a significant leap\ntowards foundational models for robotics capable of generalizing across diverse tasks, and even robot embodiments.\nA central them",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_935d4f5cb4c54cf2bc39e69cd57a24b5": {
    "id": "parent_935d4f5cb4c54cf2bc39e69cd57a24b5",
    "metadata": {
      "content": "or robotics capable of generalizing across diverse tasks, and even robot embodiments.\nA central theme of this work is the critical role of openness in accelerating this progress. The recent explosion in\ncapability is inseparable from the advent of large-scale, openly available datasets, standardized, stable and accessible\nmodel architectures, and accessible, open-source software like lerobot. We argue this convergence on open-source\nrobotics is not a mere trend but a fundamental enabler, democratizing access to research and unlocking the potential\nof large, decentralized efforts to advance the field.\nThe journey detailed in this tutorial, from first principles to the state-of-the-art, aims to equip researchers and\npractitioners with the context and tools to begin their own explorations in open-source robot learning.\n\nReferences\nJoshua Achiam. Spinning up in deep reinforcement learning. 2018.\n\nPulkit Agrawal. Computational Sensorimotor Learning.\n\nIlge Akkaya, Marcin Andrychowicz, Maciek",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_53a7616816b6418e85d97913a8bbaccb": {
    "id": "parent_53a7616816b6418e85d97913a8bbaccb",
    "metadata": {
      "content": "018.\n\nPulkit Agrawal. Computational Sensorimotor Learning.\n\nIlge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias\nPlappert, Glenn Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming\nYuan, Wojciech Zaremba, and Lei Zhang. Solving Rubik\u2019s Cube with a Robot Hand, October 2019.\n\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katie\nMillican, Malcolm Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei,\nMarianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj\nBinkowski, Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan. Flamingo: A Visual Language Model\nfor Few-Shot Learning, November 2022.\n\nJorge Aldaco, Travis Armstrong, Robert Baruch, Jeff Bingham, Sanky Chan, Debidatta Dwibedi, Chelsea Finn, Pet",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_675a9bdce3be4253959ac85c216ce846": {
    "id": "parent_675a9bdce3be4253959ac85c216ce846",
    "metadata": {
      "content": "aco, Travis Armstrong, Robert Baruch, Jeff Bingham, Sanky Chan, Debidatta Dwibedi, Chelsea Finn, Pete Florence,\nSpencer Goodrich, Wayne Gramlich, Alexander Herzog, Jonathan Hoech, Thinh Nguyen, Ian Storz, Baruch Tabanpour,\nJonathan Tompson, Ayzaan Wahid, Ted Wahrburg, Sichun Xu, Sergey Yaroshenko, and Tony Z Zhao. ALOHA 2: An\nEnhanced Low-Cost Hardware for Bimanual Teleoperation.\n\nMohammad Alizadeh and Zheng H. Zhu. A comprehensive survey of space robotic manipulators for on-orbit servicing. Frontiers\nin Robotics and AI, 11, October 2024. ISSN 2296-9144. doi: 10.3389/frobt.2024.1470950.\n\nLoubna Ben Allal, Anton Lozhkov, Elie Bakouch, Gabriel Mart\u00edn Bl\u00e1zquez, Guilherme Penedo, Lewis Tunstall, Andr\u00e9s\nMarafioti, Hynek Kydl\u00ed\u010dek, Agust\u00edn Piqueres Lajar\u00edn, Vaibhav Srivastav, Joshua Lochner, Caleb Fahlgren, Xuan-Son Nguyen,\nCl\u00e9mentine Fourrier, Ben Burtenshaw, Hugo Larcher, Haojun Zhao, Cyril Zakka, Mathieu Morlon, Colin Raffel, Leandro von\nWerra, and Thomas Wolf. SmolLM2: When Smol Goes Big",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_8655eb1eab58487bbf8659bb2cc113b5": {
    "id": "parent_8655eb1eab58487bbf8659bb2cc113b5",
    "metadata": {
      "content": "akka, Mathieu Morlon, Colin Raffel, Leandro von\nWerra, and Thomas Wolf. SmolLM2: When Smol Goes Big \u2013 Data-Centric Training of a Small Language Model, February\n2025.\n\n67\n\n\n\nRika Antonova, Silvia Cruciani, Christian Smith, and Danica Kragic. Reinforcement Learning for Pivoting Task, March 2017.\n\nShuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang,\nHumen Zhong, Yuanzhi Zhu, Mingkun Yang, Zhaohai Li, Jianqiang Wan, Pengfei Wang, Wei Ding, Zheren Fu, Yiheng Xu,\nJiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, Haiyang Xu, and Junyang Lin. Qwen2.5-VL\ntechnical report, 2025.\n\nPhilip J. Ball, Laura Smith, Ilya Kostrikov, and Sergey Levine. Efficient Online Reinforcement Learning with Offline Data,\nMay 2023.\n\nKostas E. Bekris, Joe Doerr, Patrick Meng, and Sumanth Tangirala. The State of Robot Motion Generation, October 2024.\n\nMarc G. Bellemare, Salvatore Candido, Pablo Samuel Castro, Jun Gong, Marlos C. Machado,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_404a6c616b104f0ab85482d367b1656c": {
    "id": "parent_404a6c616b104f0ab85482d367b1656c",
    "metadata": {
      "content": "ober 2024.\n\nMarc G. Bellemare, Salvatore Candido, Pablo Samuel Castro, Jun Gong, Marlos C. Machado, Subhodeep Moitra, Sameera S.\nPonda, and Ziyu Wang. Autonomous navigation of stratospheric balloons using reinforcement learning. Nature, 588(7836):\n77\u201382, December 2020. ISSN 1476-4687. doi: 10.1038/s41586-020-2939-8.\n\nRichard Bellman. A Markovian Decision Process. Journal of Mathematics and Mechanics, 6(5):679\u2013684, 1957. ISSN 0095-9057.\n\nJohan Bjorck, Fernando Casta\u00f1eda, Nikita Cherniadev, Xingye Da, Runyu Ding, Linxi \"Jim\" Fan, Yu Fang, Dieter Fox,\nFengyuan Hu, Spencer Huang, Joel Jang, Zhenyu Jiang, Jan Kautz, Kaushil Kundalia, Lawrence Lao, Zhiqi Li, Zongyu\nLin, Kevin Lin, Guilin Liu, Edith Llontop, Loic Magne, Ajay Mandlekar, Avnish Narayan, Soroush Nasiriany, Scott Reed,\nYou Liang Tan, Guanzhi Wang, Zu Wang, Jing Wang, Qi Wang, Jiannan Xiang, Yuqi Xie, Yinzhen Xu, Zhenjia Xu,\nSeonghyeon Ye, Zhiding Yu, Ao Zhang, Hao Zhang, Yizhou Zhao, Ruijie Zheng, and Yuke Zhu. GR00T N1: An Open",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_e98b78241c774a3ea5810c9581cde07a": {
    "id": "parent_e98b78241c774a3ea5810c9581cde07a",
    "metadata": {
      "content": "eon Ye, Zhiding Yu, Ao Zhang, Hao Zhang, Yizhou Zhao, Ruijie Zheng, and Yuke Zhu. GR00T N1: An Open\nFoundation Model for Generalist Humanoid Robots, March 2025.\n\nKevin Black, Noah Brown, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Lachy Groom, Karol\nHausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri,\nSuraj Nair, Karl Pertsch, Lucy Xiaoyang Shi, James Tanner, Quan Vuong, Anna Walling, Haohuan Wang, and Ury Zhilinsky.\n$\u03c0_0$: A Vision-Language-Action Flow Model for General Robot Control, October 2024.\n\nAnthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, Krzysztof Choromanski, Tianli Ding, Danny\nDriess, Avinava Dubey, Chelsea Finn, Pete Florence, Chuyuan Fu, Montse Gonzalez Arenas, Keerthana Gopalakrishnan,\nKehang Han, Karol Hausman, Alexander Herzog, Jasmine Hsu, Brian Ichter, Alex Irpan, Nikhil Joshi, Ryan Julian, Dmitry\nKalashnikov, Yuheng Kuang, Isabel Leal, Lisa Lee, Tsang-Wei",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_dfc0b7bffaa045b39257aa6c262a0c44": {
    "id": "parent_dfc0b7bffaa045b39257aa6c262a0c44",
    "metadata": {
      "content": "rpan, Nikhil Joshi, Ryan Julian, Dmitry\nKalashnikov, Yuheng Kuang, Isabel Leal, Lisa Lee, Tsang-Wei Edward Lee, Sergey Levine, Yao Lu, Henryk Michalewski,\nIgor Mordatch, Karl Pertsch, Kanishka Rao, Krista Reymann, Michael Ryoo, Grecia Salazar, Pannag Sanketi, Pierre\nSermanet, Jaspiar Singh, Anikait Singh, Radu Soricut, Huong Tran, Vincent Vanhoucke, Quan Vuong, Ayzaan Wahid,\nStefan Welker, Paul Wohlhart, Jialin Wu, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Tianhe Yu, and Brianna Zitkovich. RT-2:\nVision-Language-Action Models Transfer Web Knowledge to Robotic Control, July 2023a.\n\nAnthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Keerthana Gopalakrishnan,\nKarol Hausman, Alex Herzog, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan, Tomas Jackson, Sally Jesmonth, Nikhil J.\nJoshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Isabel Leal, Kuang-Huei Lee, Sergey Levine, Yao Lu, Utsav Malla,\nDeeksha Manjunath, Igor Mordatch, Ofir Nachum, Carolina Pa",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b29a17283c2345ed991b2519c30b2dc0": {
    "id": "parent_b29a17283c2345ed991b2519c30b2dc0",
    "metadata": {
      "content": "Lee, Sergey Levine, Yao Lu, Utsav Malla,\nDeeksha Manjunath, Igor Mordatch, Ofir Nachum, Carolina Parada, Jodilyn Peralta, Emily Perez, Karl Pertsch, Jornell\nQuiambao, Kanishka Rao, Michael Ryoo, Grecia Salazar, Pannag Sanketi, Kevin Sayed, Jaspiar Singh, Sumedh Sontakke,\nAustin Stone, Clayton Tan, Huong Tran, Vincent Vanhoucke, Steve Vega, Quan Vuong, Fei Xia, Ted Xiao, Peng Xu, Sichun\nXu, Tianhe Yu, and Brianna Zitkovich. RT-1: Robotics Transformer for Real-World Control at Scale, August 2023b.\n\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav\nShyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon\nChild, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz\nLitwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and\nDario Amodei. Language Model",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_a0ebf9d3d40d44afa3f2518f2b501330": {
    "id": "parent_a0ebf9d3d40d44afa3f2518f2b501330",
    "metadata": {
      "content": ", Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and\nDario Amodei. Language Models are Few-Shot Learners, July 2020.\n\nMinwoo Byeon, Beomhee Park, Haecheon Kim, Sungjun Lee, Woonhyuk Baek, and Saehoon Kim. COYO-700M: Image-text\npair dataset, 2022.\n\nYevgen Chebotar, Ankur Handa, Viktor Makoviychuk, Miles Macklin, Jan Issac, Nathan Ratliff, and Dieter Fox. Closing\nthe sim-to-real loop: Adapting simulation randomization with real world experience. In 2019 International Conference on\nRobotics and Automation (ICRA), pages 8973\u20138979. IEEE, 2019.\n\nXi Chen, Josip Djolonga, Piotr Padlewski, Basil Mustafa, Soravit Changpinyo, Jialin Wu, Carlos Riquelme Ruiz, Sebastian\nGoodman, Xiao Wang, Yi Tay, Siamak Shakeri, Mostafa Dehghani, Daniel Salz, Mario Lucic, Michael Tschannen, Arsha\nNagrani, Hexiang Hu, Mandar Joshi, Bo Pang, Ceslee Montgomery, Paulina Pietrzyk, Marvin Ritter, A. J. Piergiovanni,\nMatthias Minderer, Filip Pavetic, Austin Waters, Gang Li, Ibrahim Alabdulmohsin, Lucas",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_f74c2ba4a1f64c1cb9f93723363c233b": {
    "id": "parent_f74c2ba4a1f64c1cb9f93723363c233b",
    "metadata": {
      "content": "Piergiovanni,\nMatthias Minderer, Filip Pavetic, Austin Waters, Gang Li, Ibrahim Alabdulmohsin, Lucas Beyer, Julien Amelot, Kenton Lee,\nAndreas Peter Steiner, Yang Li, Daniel Keysers, Anurag Arnab, Yuanzhong Xu, Keran Rong, Alexander Kolesnikov, Mojtaba\nSeyedhosseini, Anelia Angelova, Xiaohua Zhai, Neil Houlsby, and Radu Soricut. PaLI-X: On Scaling up a Multilingual Vision\nand Language Model, May 2023.\n\n68\n\n\n\nCheng Chi, Zhenjia Xu, Siyuan Feng, Eric Cousineau, Yilun Du, Benjamin Burchfiel, Russ Tedrake, and Shuran Song. Diffusion\nPolicy: Visuomotor Policy Learning via Action Diffusion, March 2024.\n\nJonathan H. Connell and Sridhar Mahadevan, editors. Robot Learning. Springer US, Boston, MA, 1993. ISBN 978-1-4613-6396-5\n978-1-4615-3184-5. doi: 10.1007/978-1-4615-3184-5.\n\nWenliang Dai, Junnan Li, Dongxu Li, Anthony Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi.\nInstructBLIP: Towards general-purpose vision-language models with instruction tuning. In Thirty-Sevent",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_093e68c482f54bada99cef99914d6010": {
    "id": "parent_093e68c482f54bada99cef99914d6010",
    "metadata": {
      "content": "structBLIP: Towards general-purpose vision-language models with instruction tuning. In Thirty-Seventh Conference on\nNeural Information Processing Systems, 2023.\n\nJonas Degrave, Federico Felici, Jonas Buchli, Michael Neunert, Brendan Tracey, Francesco Carpanese, Timo Ewalds, Roland\nHafner, Abbas Abdolmaleki, Diego de las Casas, Craig Donner, Leslie Fritz, Cristian Galperti, Andrea Huber, James Keeling,\nMaria Tsimpoukelli, Jackie Kay, Antoine Merle, Jean-Marc Moret, Seb Noury, Federico Pesamosca, David Pfau, Olivier\nSauter, Cristian Sommariva, Stefano Coda, Basil Duval, Ambrogio Fasoli, Pushmeet Kohli, Koray Kavukcuoglu, Demis\nHassabis, and Martin Riedmiller. Magnetic control of tokamak plasmas through deep reinforcement learning. Nature, 602\n(7897):414\u2013419, February 2022. ISSN 1476-4687. doi: 10.1038/s41586-021-04301-9.\n\nJ. Deng, K. Li, M. Do, H. Su, and L. Fei-Fei. Construction and analysis of a large scale image ontology. Vision Sciences Society,\n2009.\n\nJacob Devlin, Ming-Wei Chang, K",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_bfc3fecef9b84f29b5752e096bb96ded": {
    "id": "parent_bfc3fecef9b84f29b5752e096bb96ded",
    "metadata": {
      "content": "sis of a large scale image ontology. Vision Sciences Society,\n2009.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers\nfor Language Understanding, May 2019.\n\nDanny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan\nTompson, Quan Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth, Sergey Levine,\nVincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, and Pete Florence. PaLM-E:\nAn Embodied Multimodal Language Model, March 2023.\n\nDanny Driess, Jost Tobias Springenberg, Brian Ichter, Lili Yu, Adrian Li-Bell, Karl Pertsch, Allen Z. Ren, Homer Walke, Quan\nVuong, Lucy Xiaoyang Shi, and Sergey Levine. Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast,\nGeneralize Better, May 2025.\n\nPatrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M\u00fcller, Harry Saini, Yam Levi,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1c8f4a91e14c422c957833ff229672e2": {
    "id": "parent_1c8f4a91e14c422c957833ff229672e2",
    "metadata": {
      "content": "atrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M\u00fcller, Harry Saini, Yam Levi, Dominik Lorenz,\nAxel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, and\nRobin Rombach. Scaling Rectified Flow Transformers for High-Resolution Image Synthesis, March 2024.\n\nWilliam Fedus, Jeff Dean, and Barret Zoph. A Review of Sparse Expert Models in Deep Learning, September 2022.\n\nEnrico Fini, Mustafa Shukor, Xiujun Li, Philipp Dufter, Michal Klein, David Haldimann, Sai Aitharaju, Victor Guilherme Turrisi\nda Costa, Louis B\u00e9thune, Zhe Gan, Alexander T. Toshev, Marcin Eichner, Moin Nabi, Yinfei Yang, Joshua M. Susskind, and\nAlaaeldin El-Nouby. Multimodal Autoregressive Pre-training of Large Vision Encoders, November 2024.\n\nPete Florence, Corey Lynch, Andy Zeng, Oscar A. Ramirez, Ayzaan Wahid, Laura Downs, Adrian Wong, Johnny Lee, Igor\nMordatch, and Jonathan Tompson. Implicit Behavioral Cloning. In Proceedings of the 5th Conferen",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_9024328ef78a44bb8eef561f04a65a2d": {
    "id": "parent_9024328ef78a44bb8eef561f04a65a2d",
    "metadata": {
      "content": "Igor\nMordatch, and Jonathan Tompson. Implicit Behavioral Cloning. In Proceedings of the 5th Conference on Robot Learning,\npages 158\u2013168. PMLR, January 2022.\n\nJun Fujita, Daisuke Soda, Chotaro Murata, and Hiroyuki Tsuhari. Development of Robots for Nuclear Power Plants and Their\nApplication to New Fields. 57(4), 2020.\n\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,\nAkhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang,\nArchi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen\nGregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak,\nChloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton\nFerrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, Danny Wyatt,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1fcebccced37427eb31aed5ba6f7e75f": {
    "id": "parent_1fcebccced37427eb31aed5ba6f7e75f",
    "metadata": {
      "content": "rrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, Danny Wyatt, David Esiobu,\nDhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy,\nElina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Francisco Guzm\u00e1n, Frank Zhang, Gabriel Synnaeve,\nGabrielle Lee, Georgia Lewis Anderson, Govind Thattai, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell,\nHailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan\nMisra, Ivan Evtimov, Jack Zhang, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet\nShah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu,\nJie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng\nJia, Kalyan Vasuden Alwala, Karthik Prasad, Kartikeya Upasani, Kate Plawiak, Ke Li",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_64b37a6dc0824f958a53adee49244261": {
    "id": "parent_64b37a6dc0824f958a53adee49244261",
    "metadata": {
      "content": "hua Saxe, Junteng\nJia, Kalyan Vasuden Alwala, Karthik Prasad, Kartikeya Upasani, Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone,\nKhalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Kushal Lakhotia, Lauren Rantala-Yeary, Laurens\nvan der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo, Lukas Blecher, Lukas\nLandzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Maria\n\n69\n\n\n\nTsimpoukelli, Mathew Oldham, Mathieu Rita, Maya Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh,\nMona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Ning Zhang, Olivier\nDuchenne, Onur \u00c7elebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic, Peter Weng, Prajjwal Bhargava, Pratik\nDubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy,\nRamon Calderer, Ricardo Silveira Cabral, R",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_13e53a856f314811ab59b32edf00b7fa": {
    "id": "parent_13e53a856f314811ab59b32edf00b7fa",
    "metadata": {
      "content": "ing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy,\nRamon Calderer, Ricardo Silveira Cabral, Robert Stojnic, Roberta Raileanu, Rohan Maheswari, Rohit Girdhar, Rohit Patel,\nRomain Sauvestre, Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini, Sahana\nChennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan Narang, Sharath\nRaparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman,\nSten Sootla, Stephane Collot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas\nGeorgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta,\nVignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Virginie Do, Vish Vogeti, V\u00edtor Albiero, Vladan Petrovic, Weiwei\nChu, Wenhan Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaofang Wang, Xiaoqing Ellen Tan,\nXide Xia, Xinfe",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_9b901f84bf0c418397d4d3ac120e3ddd": {
    "id": "parent_9b901f84bf0c418397d4d3ac120e3ddd",
    "metadata": {
      "content": "u, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaofang Wang, Xiaoqing Ellen Tan,\nXide Xia, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei, Yi Wen, Yiwen Song,\nYuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya\nSingh, Aayushi Srivastava, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand,\nAjay Menon, Ajay Sharma, Alex Boesenberg, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Amos Teo,\nAnam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan,\nAnkit Ramchandani, Annie Dong, Annie Franco, Anuj Goyal, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel,\nAshwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang, Beth\nLoyd, Beto De Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence,\nBrani Stojko",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4de000b45eef4a0ba8390e0e3d4a8d8b": {
    "id": "parent_4de000b45eef4a0ba8390e0e3d4a8d8b",
    "metadata": {
      "content": "argavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence,\nBrani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Ce Liu, Changhan Wang,\nChangkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Cynthia\nGao, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, David Adkins, David Xu, Davide Testuggine, Delia David,\nDevi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine\nMontgomery, Eleonora Presani, Emily Hahn, Emily Wood, Eric-Tuan Le, Erik Brinkman, Esteban Arcaute, Evan Dunbar,\nEvan Smothers, Fei Sun, Felix Kreuk, Feng Tian, Filippos Kokkinos, Firat Ozgenel, Francesco Caggioni, Frank Kanayet,\nFrank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil Halpern, Grant Herman, Grigory\nSizov, Guangyi, Zhang, Guna Lakshminarayanan, Hakan Inan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zh",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_975f9fc9aebe4164acc719d4507096db": {
    "id": "parent_975f9fc9aebe4164acc719d4507096db",
    "metadata": {
      "content": "uangyi, Zhang, Guna Lakshminarayanan, Hakan Inan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha,\nHaroun Habeeb, Harrison Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Hongyuan Zhan, Ibrahim Damlaj, Igor\nMolybog, Igor Tufanov, Ilias Leontiadis, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli, Janice\nLam, Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy\nTeboul, Jessica Zhong, Jian Jin, Jingyi Yang, Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres,\nJosh Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Kartikay Khandelwal, Katayoun Zand, Kathy Matosich,\nKaushik Veeraraghavan, Kelly Michelena, Keqian Li, Kiran Jagadeesh, Kun Huang, Kunal Chawla, Kyle Huang, Lailin\nChen, Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng Yu, Liron Moshkovich, Luca\nWehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt, Martynas Mankus, Matan Hasso",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_0a5889e3b9ef45689d20655968830a9b": {
    "id": "parent_0a5889e3b9ef45689d20655968830a9b",
    "metadata": {
      "content": "Moshkovich, Luca\nWehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias\nReso, Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Miao Liu, Michael L. Seltzer, Michal Valko, Michelle\nRestrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan, Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso,\nMo Metanat, Mohammad Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White, Navyata Bawa,\nNayan Singhal, Nick Egebo, Nicolas Usunier, Nikhil Mehta, Nikolay Pavlovich Laptev, Ning Dong, Norman Cheng, Oleg\nChernoguz, Olivia Hart, Omkar Salpekar, Ozlem Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner,\nPhilip Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani, Pritish Yuvraj, Qian Liang, Rachad\nAlao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra, Rangaprabhu Parthasarathy, Raymond\nLi, Rebekkah Hogan, Robin Battey, Rocky Wang, Russ Howes,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_ea30b4df29f94bdfb30e79785f2c3950": {
    "id": "parent_ea30b4df29f94bdfb30e79785f2c3950",
    "metadata": {
      "content": "Mitra, Rangaprabhu Parthasarathy, Raymond\nLi, Rebekkah Hogan, Robin Battey, Rocky Wang, Russ Howes, Ruty Rinott, Sachin Mehta, Sachin Siby, Sai Jayesh Bondu,\nSamyak Datta, Sara Chugh, Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Mahajan, Saurabh Verma,\nSeiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao Lin, Shengxin Cindy Zha,\nShishir Patil, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang, Sinong Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith\nChintala, Stephanie Max, Stephen Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Summer\nDeng, Sungmin Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez, Tamar Glaser, Tamara\nBest, Thilo Koehler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim Matthews, Timothy Chou, Tzook Shaked, Varun\nVontimitta, Victoria Ajayi, Victoria Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad\nPoenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_0a19508cd83d4457bdd660faaa7ba723": {
    "id": "parent_0a19508cd83d4457bdd660faaa7ba723",
    "metadata": {
      "content": "ay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad\nPoenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable,\nXiaocheng Tang, Xiaojian Wu, Xiaolan Wang, Xilun Wu, Xinbo Gao, Yaniv Kleinman, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi,\nYenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu, Wang, Yu Zhao, Yuchen Hao, Yundi Qian, Yunlu Li,\nYuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao, and Zhiyu Ma. The Llama 3\nHerd of Models, November 2024.\n\nRobert J. Griffin, Georg Wiedebach, Sylvain Bertrand, Alexander Leonessa, and Jerry Pratt. Walking Stabilization Using\nStep Timing and Location Adjustment on the Humanoid Robot, Atlas. In 2017 IEEE/RSJ International Conference on\nIntelligent Robots and Systems (IROS), pages 667\u2013673, September 2017. doi: 10.1109/IROS.2017.8202223.\n\nTuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine. Reinforcement Learning with Deep Energy-Based Policies.\nIn P",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_88702346e124450a895f39adeced1f63": {
    "id": "parent_88702346e124450a895f39adeced1f63",
    "metadata": {
      "content": "Tang, Pieter Abbeel, and Sergey Levine. Reinforcement Learning with Deep Energy-Based Policies.\nIn Proceedings of the 34th International Conference on Machine Learning, pages 1352\u20131361. PMLR, July 2017.\n\n70\n\n\n\nTuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft Actor-Critic: Off-Policy Maximum Entropy Deep\nReinforcement Learning with a Stochastic Actor, August 2018.\n\nNicklas Hansen, Xiaolong Wang, and Hao Su. Temporal Difference Learning for Model Predictive Control, July 2022.\n\nNicolas Heess, Dhruva TB, Srinivasan Sriram, Jay Lemmon, Josh Merel, Greg Wayne, Yuval Tassa, Tom Erez, Ziyu Wang,\nS. M. Ali Eslami, Martin Riedmiller, and David Silver. Emergence of Locomotion Behaviours in Rich Environments, July\n2017.\n\nIrina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and\nAlexander Lerchner. Beta-vae: Learning basic visual concepts with a constrained variational framework. In International\nConference on Learning Rep",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_789c59959da243efb07a5e397647e67b": {
    "id": "parent_789c59959da243efb07a5e397647e67b",
    "metadata": {
      "content": "isual concepts with a constrained variational framework. In International\nConference on Learning Representations, 2017.\n\nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models, December 2020.\n\nEric Jang, Alex Irpan, Mohi Khansari, Daniel Kappler, Frederik Ebert, Corey Lynch, Sergey Levine, and Chelsea Finn. BC-Z:\nZero-Shot Task Generalization with Robotic Imitation Learning, February 2022.\n\nMichael Janner, Yilun Du, Joshua B. Tenenbaum, and Sergey Levine. Planning with Diffusion for Flexible Behavior Synthesis,\nDecember 2022.\n\nYandong Ji, Gabriel B. Margolis, and Pulkit Agrawal. DribbleBot: Dynamic Legged Manipulation in the Wild, April 2023.\n\nAlbert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian\nBressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L\u00e9lio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock,\nTeven Le Scao, Thibaut Lavril, Thomas Wang, Timoth\u00e9e Lacroix, and William El Say",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4a95034ec24e455d9291c9ca756410a5": {
    "id": "parent_4a95034ec24e455d9291c9ca756410a5",
    "metadata": {
      "content": "haux, Pierre Stock,\nTeven Le Scao, Thibaut Lavril, Thomas Wang, Timoth\u00e9e Lacroix, and William El Sayed. Mistral 7B, October 2023.\n\nLiyiming Ke, Jingqiang Wang, Tapomayukh Bhattacharjee, Byron Boots, and Siddhartha Srinivasa. Grasping with Chopsticks:\nCombating Covariate Shift in Model-free Imitation Learning for Fine Manipulation, November 2020.\n\nAlexander Khazatsky, Karl Pertsch, Suraj Nair, Ashwin Balakrishna, Sudeep Dasari, Siddharth Karamcheti, Soroush Nasiriany,\nMohan Kumar Srirama, Lawrence Yunliang Chen, Kirsty Ellis, Peter David Fagan, Joey Hejna, Masha Itkina, Marion Lepert,\nYecheng Jason Ma, Patrick Tree Miller, Jimmy Wu, Suneel Belkhale, Shivin Dass, Huy Ha, Arhan Jain, Abraham Lee,\nYoungwoon Lee, Marius Memmel, Sungjae Park, Ilija Radosavovic, Kaiyuan Wang, Albert Zhan, Kevin Black, Cheng Chi,\nKyle Beltran Hatch, Shan Lin, Jingpei Lu, Jean Mercat, Abdul Rehman, Pannag R. Sanketi, Archit Sharma, Cody Simpson,\nQuan Vuong, Homer Rich Walke, Blake Wulfe, Ted Xiao, Jonathan Heew",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c549baadc63943f0aed849273e005a34": {
    "id": "parent_c549baadc63943f0aed849273e005a34",
    "metadata": {
      "content": "eti, Archit Sharma, Cody Simpson,\nQuan Vuong, Homer Rich Walke, Blake Wulfe, Ted Xiao, Jonathan Heewon Yang, Arefeh Yavary, Tony Z. Zhao, Christopher\nAgia, Rohan Baijal, Mateo Guaman Castro, Daphne Chen, Qiuyu Chen, Trinity Chung, Jaimyn Drake, Ethan Paul Foster,\nJensen Gao, Vitor Guizilini, David Antonio Herrera, Minho Heo, Kyle Hsu, Jiaheng Hu, Muhammad Zubair Irshad, Donovon\nJackson, Charlotte Le, Yunshuang Li, Kevin Lin, Roy Lin, Zehan Ma, Abhiram Maddukuri, Suvir Mirchandani, Daniel\nMorton, Tony Nguyen, Abigail O\u2019Neill, Rosario Scalise, Derick Seale, Victor Son, Stephen Tian, Emi Tran, Andrew E.\nWang, Yilin Wu, Annie Xie, Jingyun Yang, Patrick Yin, Yunchu Zhang, Osbert Bastani, Glen Berseth, Jeannette Bohg, Ken\nGoldberg, Abhinav Gupta, Abhishek Gupta, Dinesh Jayaraman, Joseph J. Lim, Jitendra Malik, Roberto Mart\u00edn-Mart\u00edn,\nSubramanian Ramamoorthy, Dorsa Sadigh, Shuran Song, Jiajun Wu, Michael C. Yip, Yuke Zhu, Thomas Kollar, Sergey\nLevine, and Chelsea Finn. DROID: A Large-Scale In-",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_bb2b4ba48bc64e58bc639a9cd2dff256": {
    "id": "parent_bb2b4ba48bc64e58bc639a9cd2dff256",
    "metadata": {
      "content": ", Michael C. Yip, Yuke Zhu, Thomas Kollar, Sergey\nLevine, and Chelsea Finn. DROID: A Large-Scale In-The-Wild Robot Manipulation Dataset, April 2025.\n\nMoo Jin Kim, Karl Pertsch, Siddharth Karamcheti, Ted Xiao, Ashwin Balakrishna, Suraj Nair, Rafael Rafailov, Ethan Foster,\nGrace Lam, Pannag Sanketi, Quan Vuong, Thomas Kollar, Benjamin Burchfiel, Russ Tedrake, Dorsa Sadigh, Sergey Levine,\nPercy Liang, and Chelsea Finn. OpenVLA: An Open-Source Vision-Language-Action Model, September 2024.\n\nDiederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.\n\nRob Knight, Pepijn Kooijmans, Thomas Wolf, Simon Alibert, Michel Aractingi, Dana Aubakirova, Adil Zouitine, Russi Martino,\nSteven Palma, Caroline Pascal, and Remi Cadene. Standard Open SO-100 & SO-101 Arms.\n\nJens Kober, J Andrew Bagnell, and Jan Peters. Reinforcement Learning in Robotics: A Survey.\n\nJing Yu Koh, Ruslan Salakhutdinov, and Daniel Fried. Grounding language models to images for multimod",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_796b2a7e852448019cb311cd0e20d1d3": {
    "id": "parent_796b2a7e852448019cb311cd0e20d1d3",
    "metadata": {
      "content": "ing Yu Koh, Ruslan Salakhutdinov, and Daniel Fried. Grounding language models to images for multimodal inputs and\noutputs, 2023.\n\nZhifeng Kong, Arushi Goel, Rohan Badlani, Wei Ping, Rafael Valle, and Bryan Catanzaro. Audio flamingo: A novel audio\nlanguage model with few-shot learning and dialogue abilities. In International Conference on Machine Learning, pages\n25125\u201325148. PMLR, 2024.\n\nVik Korrapati. Moondream. Online, 2024.\n\nHugo Lauren\u00e7on, Lucile Saulnier, Leo Tronchon, Stas Bekman, Amanpreet Singh, Anton Lozhkov, Thomas Wang, Siddharth\nKaramcheti, Alexander M Rush, Douwe Kiela, Matthieu Cord, and Victor Sanh. OBELICS: An open web-scale filtered\ndataset of interleaved image-text documents. In Thirty-Seventh Conference on Neural Information Processing Systems\nDatasets and Benchmarks Track, 2023.\n\n71\n\n\n\nHugo Lauren\u00e7on, L\u00e9o Tronchon, Matthieu Cord, and Victor Sanh. What matters when building vision-language models?, May\n2024.\n\nJoonho Lee, Jemin Hwangbo, Lorenz Wellhausen, Vladlen Koltu",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4026e28e8b604e41b5e418a1ec50c2aa": {
    "id": "parent_4026e28e8b604e41b5e418a1ec50c2aa",
    "metadata": {
      "content": "ding vision-language models?, May\n2024.\n\nJoonho Lee, Jemin Hwangbo, Lorenz Wellhausen, Vladlen Koltun, and Marco Hutter. Learning Quadrupedal Locomotion over\nChallenging Terrain. Science Robotics, 5(47):eabc5986, October 2020. ISSN 2470-9476. doi: 10.1126/scirobotics.abc5986.\n\nSeungjae Lee, Yibin Wang, Haritheja Etukuru, H. Jin Kim, Nur Muhammad Mahi Shafiullah, and Lerrel Pinto. Behavior\nGeneration with Latent Actions, June 2024.\n\nJunnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. BLIP-2: Bootstrapping language-image pre-training with frozen image\nencoders and large language models. In Proceedings of the 40th International Conference on Machine Learning, ICML\u201923, ,\nHonolulu, Hawaii, USA\u201e 2023. JMLR.org.\n\nTimothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan\nWierstra. Continuous control with deep reinforcement learning, July 2019.\n\nJi Lin, Hongxu Yin, Wei Ping, Yao Lu, Pavlo Molchanov, Andrew Tao, Huizi Mao, Jan Kaut",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_d759557aa59c4559acfe9090aaddae2d": {
    "id": "parent_d759557aa59c4559acfe9090aaddae2d",
    "metadata": {
      "content": ", July 2019.\n\nJi Lin, Hongxu Yin, Wei Ping, Yao Lu, Pavlo Molchanov, Andrew Tao, Huizi Mao, Jan Kautz, Mohammad Shoeybi, and Song\nHan. VILA: On Pre-training for Visual Language Models, May 2024.\n\nYaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow Matching for Generative Modeling,\nFebruary 2023.\n\nYaron Lipman, Marton Havasi, Peter Holderrieth, Neta Shaul, Matt Le, Brian Karrer, Ricky T. Q. Chen, David Lopez-Paz,\nHeli Ben-Hamu, and Itai Gat. Flow Matching Guide and Code, December 2024.\n\nHaotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. Improved baselines with visual instruction tuning. In NeurIPS 2023\nWorkshop on Instruction Tuning and Instruction Following, 2023.\n\nJiajun Liu, Yibing Wang, Hanghang Ma, Xiaoping Wu, Xiaoqi Ma, Xiaoming Wei, Jianbin Jiao, Enhua Wu, and Jie Hu.\nKangaroo: A powerful video-language model supporting long-context video input. arXiv preprint arXiv:2408.15542, 2024.\n\nCalvin Luo. Understanding Diffusion Models: A Unified Persp",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_fbd3f32a5eb94433ae0a5738788adfad": {
    "id": "parent_fbd3f32a5eb94433ae0a5738788adfad",
    "metadata": {
      "content": "arXiv preprint arXiv:2408.15542, 2024.\n\nCalvin Luo. Understanding Diffusion Models: A Unified Perspective, August 2022.\n\nJianlan Luo, Charles Xu, Jeffrey Wu, and Sergey Levine. Precise and Dexterous Robotic Manipulation via Human-in-the-Loop\nReinforcement Learning, October 2024.\n\nJianlan Luo, Zheyuan Hu, Charles Xu, You Liang Tan, Jacob Berg, Archit Sharma, Stefan Schaal, Chelsea Finn, Abhishek\nGupta, and Sergey Levine. SERL: A Software Suite for Sample-Efficient Robotic Reinforcement Learning, March 2025.\n\nKevin M. Lynch and Frank C. Park. Modern Robotics: Mechanics, Planning, and Control. Cambridge University Press, 1\nedition, May 2017. ISBN 978-1-316-66123-9 978-1-107-15630-2 978-1-316-60984-2. doi: 10.1017/9781316661239.\n\nOscar Ma\u00f1as, Pau Rodriguez Lopez, Saba Ahmadi, Aida Nematzadeh, Yash Goyal, and Aishwarya Agrawal. MAPL:\nParameter-efficient adaptation of unimodal pre-trained models for vision-language few-shot prompting. In Andreas Vlachos\nand Isabelle Augenstein, editors, Pro",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_c2a8efb00b8a4cad85d2d589767187bd": {
    "id": "parent_c2a8efb00b8a4cad85d2d589767187bd",
    "metadata": {
      "content": "els for vision-language few-shot prompting. In Andreas Vlachos\nand Isabelle Augenstein, editors, Proceedings of the 17th Conference of the European Chapter of the Association for\nComputational Linguistics, pages 2523\u20132548, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. doi:\n10.18653/v1/2023.eacl-main.185.\n\nAndr\u00e9s Marafioti, Orr Zohar, Miquel Farr\u00e9, Merve Noyan, Elie Bakouch, Pedro Cuenca, Cyril Zakka, Loubna Ben Allal, Anton\nLozhkov, Nouamane Tazi, Vaibhav Srivastav, Joshua Lochner, Hugo Larcher, Mathieu Morlon, Lewis Tunstall, Leandro von\nWerra, and Thomas Wolf. SmolVLM: Redefining small and efficient multimodal models, April 2025.\n\nGabriel B. Margolis, Ge Yang, Kartik Paigwar, Tao Chen, and Pulkit Agrawal. Rapid Locomotion via Reinforcement Learning,\nMay 2022.\n\nJohn McCormac, Ankur Handa, Andrew Davison, and Stefan Leutenegger. SemanticFusion: Dense 3D Semantic Mapping with\nConvolutional Neural Networks, September 2016.\n\nVolodymyr Mnih, Koray Kavukcuoglu, Da",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_2966414bbaa94fb4ab5b4c2671fac004": {
    "id": "parent_2966414bbaa94fb4ab5b4c2671fac004",
    "metadata": {
      "content": "c Mapping with\nConvolutional Neural Networks, September 2016.\n\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller.\nPlaying Atari with Deep Reinforcement Learning, December 2013.\n\nPreetum Nakkiran, Arwen Bradley, Hattie Zhou, and Madhu Advani. Step-by-Step Diffusion: An Elementary Tutorial, June\n2024.\n\n72\n\n\n\nAbby O\u2019Neill, Abdul Rehman, Abhinav Gupta, Abhiram Maddukuri, Abhishek Gupta, Abhishek Padalkar, Abraham Lee,\nAcorn Pooley, Agrim Gupta, Ajay Mandlekar, Ajinkya Jain, Albert Tung, Alex Bewley, Alex Herzog, Alex Irpan, Alexander\nKhazatsky, Anant Rai, Anchit Gupta, Andrew Wang, Andrey Kolobov, Anikait Singh, Animesh Garg, Aniruddha Kembhavi,\nAnnie Xie, Anthony Brohan, Antonin Raffin, Archit Sharma, Arefeh Yavary, Arhan Jain, Ashwin Balakrishna, Ayzaan\nWahid, Ben Burgess-Limerick, Beomjoon Kim, Bernhard Sch\u00f6lkopf, Blake Wulfe, Brian Ichter, Cewu Lu, Charles Xu,\nCharlotte Le, Chelsea Finn, Chen Wang, Chenfeng Xu, Cheng",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_8fc4161504e94571823338f5cbe86f79": {
    "id": "parent_8fc4161504e94571823338f5cbe86f79",
    "metadata": {
      "content": "Wulfe, Brian Ichter, Cewu Lu, Charles Xu,\nCharlotte Le, Chelsea Finn, Chen Wang, Chenfeng Xu, Cheng Chi, Chenguang Huang, Christine Chan, Christopher Agia,\nChuer Pan, Chuyuan Fu, Coline Devin, Danfei Xu, Daniel Morton, Danny Driess, Daphne Chen, Deepak Pathak, Dhruv\nShah, Dieter B\u00fcchler, Dinesh Jayaraman, Dmitry Kalashnikov, Dorsa Sadigh, Edward Johns, Ethan Foster, Fangchen Liu,\nFederico Ceola, Fei Xia, Feiyu Zhao, Felipe Vieira Frujeri, Freek Stulp, Gaoyue Zhou, Gaurav S. Sukhatme, Gautam Salhotra,\nGe Yan, Gilbert Feng, Giulio Schiavi, Glen Berseth, Gregory Kahn, Guangwen Yang, Guanzhi Wang, Hao Su, Hao-Shu\nFang, Haochen Shi, Henghui Bao, Heni Ben Amor, Henrik I. Christensen, Hiroki Furuta, Homanga Bharadhwaj, Homer\nWalke, Hongjie Fang, Huy Ha, Igor Mordatch, Ilija Radosavovic, Isabel Leal, Jacky Liang, Jad Abou-Chakra, Jaehyung Kim,\nJaimyn Drake, Jan Peters, Jan Schneider, Jasmine Hsu, Jay Vakil, Jeannette Bohg, Jeffrey Bingham, Jeffrey Wu, Jensen\nGao, Jiaheng Hu, Jiajun Wu, Jialin",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4ad10c17d47b4c33b4b7b0019d88bf4e": {
    "id": "parent_4ad10c17d47b4c33b4b7b0019d88bf4e",
    "metadata": {
      "content": ", Jay Vakil, Jeannette Bohg, Jeffrey Bingham, Jeffrey Wu, Jensen\nGao, Jiaheng Hu, Jiajun Wu, Jialin Wu, Jiankai Sun, Jianlan Luo, Jiayuan Gu, Jie Tan, Jihoon Oh, Jimmy Wu, Jingpei\nLu, Jingyun Yang, Jitendra Malik, Jo\u00e3o Silv\u00e9rio, Joey Hejna, Jonathan Booher, Jonathan Tompson, Jonathan Yang, Jordi\nSalvador, Joseph J. Lim, Junhyek Han, Kaiyuan Wang, Kanishka Rao, Karl Pertsch, Karol Hausman, Keegan Go, Keerthana\nGopalakrishnan, Ken Goldberg, Kendra Byrne, Kenneth Oslund, Kento Kawaharazuka, Kevin Black, Kevin Lin, Kevin\nZhang, Kiana Ehsani, Kiran Lekkala, Kirsty Ellis, Krishan Rana, Krishnan Srinivasan, Kuan Fang, Kunal Pratap Singh,\nKuo-Hao Zeng, Kyle Hatch, Kyle Hsu, Laurent Itti, Lawrence Yunliang Chen, Lerrel Pinto, Li Fei-Fei, Liam Tan, Linxi \"Jim\"\nFan, Lionel Ott, Lisa Lee, Luca Weihs, Magnum Chen, Marion Lepert, Marius Memmel, Masayoshi Tomizuka, Masha\nItkina, Mateo Guaman Castro, Max Spero, Maximilian Du, Michael Ahn, Michael C. Yip, Mingtong Zhang, Mingyu Ding,\nMinho Heo, Mohan K",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_7ae1d22945fe42b4983cfae0936899ee": {
    "id": "parent_7ae1d22945fe42b4983cfae0936899ee",
    "metadata": {
      "content": "x Spero, Maximilian Du, Michael Ahn, Michael C. Yip, Mingtong Zhang, Mingyu Ding,\nMinho Heo, Mohan Kumar Srirama, Mohit Sharma, Moo Jin Kim, Muhammad Zubair Irshad, Naoaki Kanazawa, Nicklas\nHansen, Nicolas Heess, Nikhil J. Joshi, Niko Suenderhauf, Ning Liu, Norman Di Palo, Nur Muhammad Mahi Shafiullah,\nOier Mees, Oliver Kroemer, Osbert Bastani, Pannag R. Sanketi, Patrick \"Tree\" Miller, Patrick Yin, Paul Wohlhart, Peng\nXu, Peter David Fagan, Peter Mitrano, Pierre Sermanet, Pieter Abbeel, Priya Sundaresan, Qiuyu Chen, Quan Vuong, Rafael\nRafailov, Ran Tian, Ria Doshi, Roberto Mart\u00edn-Mart\u00edn, Rohan Baijal, Rosario Scalise, Rose Hendrix, Roy Lin, Runjia Qian,\nRuohan Zhang, Russell Mendonca, Rutav Shah, Ryan Hoque, Ryan Julian, Samuel Bustamante, Sean Kirmani, Sergey\nLevine, Shan Lin, Sherry Moore, Shikhar Bahl, Shivin Dass, Shubham Sonawani, Shubham Tulsiani, Shuran Song, Sichun\nXu, Siddhant Haldar, Siddharth Karamcheti, Simeon Adebola, Simon Guist, Soroush Nasiriany, Stefan Schaal, Stefan W",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_66f82e850da34c679a2c841eeb27fa00": {
    "id": "parent_66f82e850da34c679a2c841eeb27fa00",
    "metadata": {
      "content": "aldar, Siddharth Karamcheti, Simeon Adebola, Simon Guist, Soroush Nasiriany, Stefan Schaal, Stefan Welker,\nStephen Tian, Subramanian Ramamoorthy, Sudeep Dasari, Suneel Belkhale, Sungjae Park, Suraj Nair, Suvir Mirchandani,\nTakayuki Osa, Tanmay Gupta, Tatsuya Harada, Tatsuya Matsushima, Ted Xiao, Thomas Kollar, Tianhe Yu, Tianli Ding,\nTodor Davchev, Tony Z. Zhao, Travis Armstrong, Trevor Darrell, Trinity Chung, Vidhi Jain, Vikash Kumar, Vincent\nVanhoucke, Vitor Guizilini, Wei Zhan, Wenxuan Zhou, Wolfram Burgard, Xi Chen, Xiangyu Chen, Xiaolong Wang, Xinghao\nZhu, Xinyang Geng, Xiyuan Liu, Xu Liangwei, Xuanlin Li, Yansong Pang, Yao Lu, Yecheng Jason Ma, Yejin Kim, Yevgen\nChebotar, Yifan Zhou, Yifeng Zhu, Yilin Wu, Ying Xu, Yixuan Wang, Yonatan Bisk, Yongqiang Dou, Yoonyoung Cho,\nYoungwoon Lee, Yuchen Cui, Yue Cao, Yueh-Hua Wu, Yujin Tang, Yuke Zhu, Yunchu Zhang, Yunfan Jiang, Yunshuang Li,\nYunzhu Li, Yusuke Iwasawa, Yutaka Matsuo, Zehan Ma, Zhuo Xu, Zichen Jeff Cui, Zichen Zhang, Zipeng F",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_089302239c6e48c5834d1c9b0f53359a": {
    "id": "parent_089302239c6e48c5834d1c9b0f53359a",
    "metadata": {
      "content": "Yunzhu Li, Yusuke Iwasawa, Yutaka Matsuo, Zehan Ma, Zhuo Xu, Zichen Jeff Cui, Zichen Zhang, Zipeng Fu, and Zipeng\nLin. Open X-Embodiment: Robotic Learning Datasets and RT-X Models, May 2025.\n\nMaxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel\nHaziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao\nHuang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herv\u00e9 Jegou, Julien Mairal,\nPatrick Labatut, Armand Joulin, and Piotr Bojanowski. DINOv2: Learning Robust Visual Features without Supervision,\nFebruary 2024.\n\nFrank Permenter and Chenyang Yuan. Interpreting and Improving Diffusion Models from an Optimization Perspective, June\n2024.\n\nAdam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, Apoorv Vyas, Bowen Shi, Chih-Yao\nMa, Ching-Yao Chuang, David Yan, Dhruv Choudhary, Dingkang Wang, Geet Sethi, Guan Pang, Haoyu",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b075c0f019704799b02721aeab29f57d": {
    "id": "parent_b075c0f019704799b02721aeab29f57d",
    "metadata": {
      "content": "h-Yao\nMa, Ching-Yao Chuang, David Yan, Dhruv Choudhary, Dingkang Wang, Geet Sethi, Guan Pang, Haoyu Ma, Ishan Misra,\nJi Hou, Jialiang Wang, Kiran Jagadeesh, Kunpeng Li, Luxin Zhang, Mannat Singh, Mary Williamson, Matt Le, Matthew Yu,\nMitesh Kumar Singh, Peizhao Zhang, Peter Vajda, Quentin Duval, Rohit Girdhar, Roshan Sumbaly, Sai Saketh Rambhatla,\nSam Tsai, Samaneh Azadi, Samyak Datta, Sanyuan Chen, Sean Bell, Sharadh Ramaswamy, Shelly Sheynin, Siddharth\nBhattacharya, Simran Motwani, Tao Xu, Tianhe Li, Tingbo Hou, Wei-Ning Hsu, Xi Yin, Xiaoliang Dai, Yaniv Taigman,\nYaqiao Luo, Yen-Cheng Liu, Yi-Chiao Wu, Yue Zhao, Yuval Kirstain, Zecheng He, Zijian He, Albert Pumarola, Ali Thabet,\nArtsiom Sanakoyeu, Arun Mallya, Baishan Guo, Boris Araya, Breena Kerr, Carleigh Wood, Ce Liu, Cen Peng, Dimitry\nVengertsev, Edgar Schonfeld, Elliot Blanchard, Felix Juefei-Xu, Fraylie Nord, Jeff Liang, John Hoffman, Jonas Kohler, Kaolin\nFire, Karthik Sivakumar, Lawrence Chen, Licheng Yu, Luya Gao, Markos Geor",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_275a215d47df4c5687e1e602e82c9683": {
    "id": "parent_275a215d47df4c5687e1e602e82c9683",
    "metadata": {
      "content": "fman, Jonas Kohler, Kaolin\nFire, Karthik Sivakumar, Lawrence Chen, Licheng Yu, Luya Gao, Markos Georgopoulos, Rashel Moritz, Sara K. Sampson,\nShikai Li, Simone Parmeggiani, Steve Fine, Tara Fowler, Vladan Petrovic, and Yuming Du. Movie Gen: A Cast of Media\nFoundation Models, February 2025.\n\nDean A. Pomerleau. ALVINN: An Autonomous Land Vehicle in a Neural Network. In Advances in Neural Information\nProcessing Systems, volume 1. Morgan-Kaufmann, 1988.\n\n73\n\n\n\nSimon J.D. Prince. Understanding Deep Learning. The MIT Press, 2023.\n\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell,\nPamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning Transferable Visual Models From Natural\nLanguage Supervision, February 2021.\n\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J.\nLiu. Exploring the Limits of Transfer Learning with a Unified Text-to-Text",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_99ff023f03234152a4ad4cf513962a1b": {
    "id": "parent_99ff023f03234152a4ad4cf513962a1b",
    "metadata": {
      "content": "ou, Wei Li, and Peter J.\nLiu. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, September 2023.\n\nScott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai\nGimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas\nHeess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A Generalist Agent, November\n2022.\n\nOlaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional Networks for Biomedical Image Segmentation,\nMay 2015.\n\nStephane Ross, Geoffrey J. Gordon, and J. Andrew Bagnell. A Reduction of Imitation Learning and Structured Prediction to\nNo-Regret Online Learning, March 2011.\n\nLindsay Sanneman, Christopher Fourie, and Julie A. Shah. The State of Industrial Robotics: Emerging Technologies, Challenges,\nand Key Research Directions, October 2020.\n\nC Schuhmann, A K\u00f6pf, R Vencu, T Coombes, and R Beaumon",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_06de3a1ede754fe4a7902b6869dc491a": {
    "id": "parent_06de3a1ede754fe4a7902b6869dc491a",
    "metadata": {
      "content": ",\nand Key Research Directions, October 2020.\n\nC Schuhmann, A K\u00f6pf, R Vencu, T Coombes, and R Beaumont. Laion coco: 600m synthetic captions from laion2b-en. URL\nhttps://laion.ai/blog/laion-coco, 2022.\n\nJohn Schulman, Sergey Levine, Philipp Moritz, Michael I. Jordan, and Pieter Abbeel. Trust Region Policy Optimization, April\n2017a.\n\nJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal Policy Optimization Algorithms,\nAugust 2017b.\n\nShai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning: From Theory to Algorithms. Cambridge University\nPress, 1 edition, May 2014. ISBN 978-1-107-05713-5 978-1-107-29801-9. doi: 10.1017/CBO9781107298019.\n\nMustafa Shukor, Corentin Dancette, and Matthieu Cord. Ep-alm: Efficient perceptual augmentation of language models. In\nProceedings of the IEEE/CVF International Conference on Computer Vision, pages 22056\u201322069, 2023.\n\nMustafa Shukor, Dana Aubakirova, Francesco Capuano, Pepijn Kooijmans, Steven Palma, Adil Zou",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_13439985a9dd43c589317d53cf2af3a5": {
    "id": "parent_13439985a9dd43c589317d53cf2af3a5",
    "metadata": {
      "content": "2023.\n\nMustafa Shukor, Dana Aubakirova, Francesco Capuano, Pepijn Kooijmans, Steven Palma, Adil Zouitine, Michel Aractingi,\nCaroline Pascal, Martino Russi, Andres Marafioti, Simon Alibert, Matthieu Cord, Thomas Wolf, and Remi Cadene. SmolVLA:\nA Vision-Language-Action Model for Affordable and Efficient Robotics, June 2025.\n\nBruno Siciliano and Oussama Khatib, editors. Springer Handbook of Robotics. Springer Handbooks. Springer International\nPublishing, Cham, 2016. ISBN 978-3-319-32550-7 978-3-319-32552-1. doi: 10.1007/978-3-319-32552-1.\n\nDavid Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and Martin Riedmiller. Deterministic policy gradient\nalgorithms. In Eric P. Xing and Tony Jebara, editors, Proceedings of the 31st International Conference on Machine Learning,\nvolume 32 of Proceedings of Machine Learning Research, pages 387\u2013395, Bejing, China, June 2014. PMLR.\n\nKihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning Structured Output Representation using Deep Conditiona",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_1783c8959cc940a483929521f5dd3db4": {
    "id": "parent_1783c8959cc940a483929521f5dd3db4",
    "metadata": {
      "content": "Sohn, Honglak Lee, and Xinchen Yan. Learning Structured Output Representation using Deep Conditional Generative\nModels. In Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015.\n\nJiaming Song, Chenlin Meng, and Stefano Ermon. Denoising Diffusion Implicit Models, October 2022.\n\nRichard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. Adaptive Computation and Machine\nLearning Series. The MIT Press, Cambridge, Massachusetts, second edition edition, 2018. ISBN 978-0-262-03924-6.\n\nMatthew Tancik, Pratul P. Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ra-\nmamoorthi, Jonathan T. Barron, and Ren Ng. Fourier Features Let Networks Learn High Frequency Functions in Low\nDimensional Domains, June 2020.\n\nChen Tang, Ben Abbatematteo, Jiaheng Hu, Rohan Chandra, Roberto Mart\u00edn-Mart\u00edn, and Peter Stone. Deep Reinforcement\nLearning for Robotics: A Survey of Real-World Successes. Annual Review of Contro",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_317e665b0d494362abaeb34f7869ce18": {
    "id": "parent_317e665b0d494362abaeb34f7869ce18",
    "metadata": {
      "content": "Deep Reinforcement\nLearning for Robotics: A Survey of Real-World Successes. Annual Review of Control, Robotics, and Autonomous Systems, 8\n(Volume 8, 2025):153\u2013188, May 2025. ISSN 2573-5144. doi: 10.1146/annurev-control-030323-022510.\n\nYang Tang, Chaoqiang Zhao, Jianrui Wang, Chongzhen Zhang, Qiyu Sun, Weixing Zheng, Wenli Du, Feng Qian, and Juergen\nKurths. Perception and Navigation in Autonomous Systems in the Era of Learning: A Survey. IEEE Transactions on Neural\nNetworks and Learning Systems, 34(12):9604\u20139624, December 2023. ISSN 2162-237X, 2162-2388. doi: 10.1109/TNNLS.2022.\n3167688.\n\n74\n\n\n\nGemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, L\u00e9onard Hussenot,\nThomas Mesnard, Bobak Shahriari, Alexandre Ram\u00e9, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon,\nSabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan\nGirgin, Nikola Momchev, Matt Hoffman, Shantanu Th",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4b8b0c25722842c8b0936b07a0cd18b7": {
    "id": "parent_4b8b0c25722842c8b0936b07a0cd18b7",
    "metadata": {
      "content": "Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan\nGirgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier Bachem,\nAlanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen,\nAndy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie\nChen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger,\nDimple Vijaykumar, Dominika Rogozi\u0144ska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan\nSenter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna\nKlimczak-Pluci\u0144ska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway,\nJetha Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh\nGordon, Josh Lipschultz",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_92e614fae7b444a6abc363fa720a9d09": {
    "id": "parent_92e614fae7b444a6abc363fa720a9d09",
    "metadata": {
      "content": "ira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh\nGordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin\nMcDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren Usui, Laurent Sifre, Lena Heuermann,\nLeticia Lago, Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick, Lucas Dixon, Luciano Martins, Machel Reid, Manvinder\nSingh, Mark Iverson, Martin G\u00f6rner, Mat Velloso, Mateo Wirth, Matt Davidow, Matt Miller, Matthew Rahtz, Matthew\nWatson, Meg Risdal, Mehran Kazemi, Michael Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park, Mofi Rahman, Mohit\nKhatwani, Natalie Dao, Nenshad Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay Chauhan, Oscar Wahltinez, Pankil\nBotarda, Parker Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko Georgiev, Phil Culliton, Pradeep Kuppala,\nRamona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_6f1b13f51a484f97a3642b698e5c12f1": {
    "id": "parent_6f1b13f51a484f97a3642b698e5c12f1",
    "metadata": {
      "content": "scu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat,\nSara Mc Carthy, Sarah Perrin, S\u00e9bastien M. R. Arnold, Sebastian Krause, Shengyang Dai, Shruti Garg, Shruti Sheth, Sue\nRonstrom, Susan Chan, Timothy Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas Kocisky, Tulsee Doshi, Vihan Jain,\nVikas Yadav, Vilobh Meshram, Vishal Dharmadhikari, Warren Barkley, Wei Wei, Wenming Ye, Woohyun Han, Woosuk\nKwon, Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic\nPeran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks, Anca Dragan,\nSlav Petrov, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Sebastian\nBorgeaud, Noah Fiedel, Armand Joulin, Kathleen Kenealy, Robert Dadashi, and Alek Andreev. Gemma 2: Improving Open\nLanguage Models at a Practical Size, August 2024.\n\nRuss Tedrake. Robotic Manipulation. Per",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_4d49d70c0b404b2db2c10034fdf2921c": {
    "id": "parent_4d49d70c0b404b2db2c10034fdf2921c",
    "metadata": {
      "content": "ving Open\nLanguage Models at a Practical Size, August 2024.\n\nRuss Tedrake. Robotic Manipulation. Perception, Planning and Control., a.\n\nRuss Tedrake. Underactuated Robotics. Algorithms for Walking, Running, Swimming, Flying, and Manipulation, b.\n\nGabriele Tiboni, Karol Arndt, and Ville Kyrki. DROPO: Sim-to-Real Transfer with Offline Domain Randomization, January\n2023.\n\nGabriele Tiboni, Pascal Klink, Jan Peters, Tatiana Tommasi, Carlo D\u2019Eramo, and Georgia Chalvatzaki. Domain Randomization\nvia Entropy Maximization, March 2024.\n\nJosh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and Pieter Abbeel. Domain Randomization for\nTransferring Deep Neural Networks from Simulation to the Real World, March 2017.\n\nPeter Tong, Ellis Brown, Penghao Wu, Sanghyun Woo, Adithya Jairam Vedagiri IYER, Sai Charitha Akula, Shusheng Yang,\nJihan Yang, Manoj Middepogu, Ziteng Wang, et al. Cambrian-1: A fully open, vision-centric exploration of multimodal llms.\nAdvances in Neural Information Pro",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_8c30b5954da24e2caabd7eba1f606ab2": {
    "id": "parent_8c30b5954da24e2caabd7eba1f606ab2",
    "metadata": {
      "content": "n-1: A fully open, vision-centric exploration of multimodal llms.\nAdvances in Neural Information Processing Systems, 37:87310\u201387356, 2024.\n\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra,\nPrajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David\nEsiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony\nHartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem\nKorenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao,\nXavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi\nRungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh\nTang, Ross Taylor, Adina Williams, Jian Xian",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_b5a78df7e0f443e98ba7a21e656617b4": {
    "id": "parent_b5a78df7e0f443e98ba7a21e656617b4",
    "metadata": {
      "content": "ael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh\nTang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2:\nOpen Foundation and Fine-Tuned Chat Models, July 2023.\n\nMaria Tsimpoukelli, Jacob L Menick, Serkan Cabi, SM Eslami, Oriol Vinyals, and Felix Hill. Multimodal few-shot learning\nwith frozen language models. Advances in Neural Information Processing Systems, 34:200\u2013212, 2021.\n\nTh\u00e9ophane Vallaeys, Mustafa Shukor, Matthieu Cord, and Jakob Verbeek. Improved baselines for data-efficient perceptual\naugmentation of llms. arXiv preprint arXiv:2403.13499, 2024.\n\nYi Wang, Xinhao Li, Ziang Yan, Yinan He, Jiashuo Yu, Xiangyu Zeng, Chenting Wang, Changlian Ma, Haian Huang, Jianfei\nGao, et al. InternVideo2. 5: Empowering video mllms with long and rich context modeling. arXiv preprint arXiv:2501.12386,\n2025.\n\n75\n\n\n\nYuan Yao,",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_5b32cc4788f744cbb514031192549007": {
    "id": "parent_5b32cc4788f744cbb514031192549007",
    "metadata": {
      "content": "mllms with long and rich context modeling. arXiv preprint arXiv:2501.12386,\n2025.\n\n75\n\n\n\nYuan Yao, Tianyu Yu, Ao Zhang, Chongyi Wang, Junbo Cui, Hongji Zhu, Tianchi Cai, Haoyu Li, Weilin Zhao, Zhihui He,\nQianyu Chen, Huarong Zhou, Zhensheng Zou, Haoye Zhang, Shengding Hu, Zhi Zheng, Jie Zhou, Jie Cai, Xu Han, Guoyang\nZeng, Dahai Li, Zhiyuan Liu, and Maosong Sun. MiniCPM-v: A GPT-4V level MLLM on your phone, 2024.\n\nXiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and Lucas Beyer. Sigmoid Loss for Language Image Pre-Training,\nSeptember 2023.\n\nBoqiang Zhang, Kehan Li, Zesen Cheng, Zhiqiang Hu, Yuqian Yuan, Guanzheng Chen, Sicong Leng, Yuming Jiang, Hang\nZhang, Xin Li, et al. VideoLLaMA 3: Frontier multimodal foundation models for image and video understanding. arXiv\npreprint arXiv:2501.13106, 2025.\n\nChong Zhang, Wenli Xiao, Tairan He, and Guanya Shi. WoCoCo: Learning Whole-Body Humanoid Control with Sequential\nContacts, November 2024.\n\nTony Z. Zhao, Vikash Kumar, Sergey Levine, and Che",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_93ca948a2ba6423da820f477cb11753c": {
    "id": "parent_93ca948a2ba6423da820f477cb11753c",
    "metadata": {
      "content": "Control with Sequential\nContacts, November 2024.\n\nTony Z. Zhao, Vikash Kumar, Sergey Levine, and Chelsea Finn. Learning Fine-Grained Bimanual Manipulation with Low-Cost\nHardware, April 2023.\n\nDeyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. MiniGPT-4: Enhancing vision-language understanding\nwith advanced large language models. In The Twelfth International Conference on Learning Representations, 2024.\n\nWanrong Zhu, Jack Hessel, Anas Awadalla, Samir Yitzhak Gadre, Jesse Dodge, Alex Fang, Youngjae Yu, Ludwig Schmidt,\nWilliam Yang Wang, and Yejin Choi. Multimodal C4: An open, billion-scale corpus of images interleaved with text. In\nThirty-Seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2023.\n\n76",
      "title": "ROBOT LEARNING"
    }
  },
  "parent_66dba0d295094d1e82346c0cd46b1d9d": {
    "id": "parent_66dba0d295094d1e82346c0cd46b1d9d",
    "metadata": {
      "content": "172\t Chapter \t4\t \u2022\t Data\tMining\nQuestiOns fOr the Opening vignette\n 1. Why should retailers, especially omni-channel retailers, pay extra attention to \nadvanced analytics and data mining?\n 2. What are the top challenges for multi-channel retailers? Can you think of other \nindustry segments that face similar problems?\n 3. What are the sources of data that retailers such as Cabela\u2019s use for their data mining \nprojects?\n 4. What does it mean to have a \u201csingle view of the customer\u201d? How can it be \naccomplished?\n 5. What type of analytics help did Cabela\u2019s get from their efforts? Can you think of any \nother potential benefits of analytics for large-scale retailers like Cabela\u2019s?\n 6. What was the reason for Cabela\u2019s to bring together SAS and Teradata, the two \nleading vendors in the analytics marketplace?\n 7. What is in-database analytics, and why would you need it?\nWhat We can Learn frOm this vignette\nThe retail industry is among the most challenging because of the change that they have \nto",
      "title": "unit2ii"
    }
  },
  "parent_c464179f8c564cc785d42e83cf701501": {
    "id": "parent_c464179f8c564cc785d42e83cf701501",
    "metadata": {
      "content": "vignette\nThe retail industry is among the most challenging because of the change that they have \nto deal with constantly. Understanding customer needs and wants, likes and dislikes, is \nan ongoing challenge. Ones who are able to create an intimate relationship through a \n\u201cholistic view of the customer\u201d will be the beneficiaries of this seemingly chaotic environ-\nment. In the midst of these challenges, what works in favor of these retailers is the avail-\nability of the technologies to collect and analyze data about their customers. Applying \nadvanced analytics tools (i.e., knowledge discovery techniques) to these data sources \nprovides them with the insight that they need for better decision making. Therefore, the \nretail industry has become one of the leading users of the new face of analytics. Data \nmining is the prime candidate for better management of this data-rich, knowledge-poor \nbusiness environment. The study described in the opening vignette clearly illustrates the \npower of",
      "title": "unit2ii"
    }
  },
  "parent_67efa6b0129241118ca077f35f87d35c": {
    "id": "parent_67efa6b0129241118ca077f35f87d35c",
    "metadata": {
      "content": "business environment. The study described in the opening vignette clearly illustrates the \npower of analytics and data mining to create a holistic view of the customer for better \ncustomer relationship management. In this chapter, you will see a wide variety of data \nmining applications solving complex problems in a variety of industries where the data is \nused to leverage competitive business advantage.\nSources: SAS, Customer Case Studies, sas.com/success/cabelas.html; and Retail Information Systems  \nNews, April 3, 2012, http://risnews.edgl.com/retail-best-practices/Why-cabela-s-has-emerged-as-the-\ntop-Omni-channel-retailer79470.\n4.2 Data Mining ConCepts anD appliCations\nIn an interview with Computerworld magazine in January 1999, Dr. Arno Penzias (Nobel \nlaureate and former chief scientist of Bell Labs) identified data mining from  organizational \ndatabases as a key application for corporations of the near future. In response to \nComputerworld\u2019s age-old question of \u201cWhat will be the",
      "title": "unit2ii"
    }
  },
  "parent_97d26ef414f84b23ab5569cad0c1ecb3": {
    "id": "parent_97d26ef414f84b23ab5569cad0c1ecb3",
    "metadata": {
      "content": "rporations of the near future. In response to \nComputerworld\u2019s age-old question of \u201cWhat will be the killer applications in the corpo -\nration?\u201d Dr. Penzias replied: \u201cData mining.\u201d He then added, \u201cData mining will become \nmuch more important and companies will throw away nothing about their customers \nbecause it will be so valuable. If you\u2019re not doing this, you\u2019re out of business.\u201d Similarly, \nin an article in Harvard Business Review, Thomas Davenport (2006) argued that the  latest \n strategic weapon for companies is analytical decision making, providing examples of \n companies such as Amazon.com, Capital One, Marriott International, and others that have \nused analytics to better understand their customers and optimize their extended supply \nchains to maximize their returns on investment while providing the best customer service.  \nM04_SHAR4877_03_PIE_C04.indd   172 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 173\nThis level of success is highly dependent on a company understanding i",
      "title": "unit2ii"
    }
  },
  "parent_b43324b9a32043c9bde378a7a270171c": {
    "id": "parent_b43324b9a32043c9bde378a7a270171c",
    "metadata": {
      "content": "Chapter\t4\t \u2022\t Data\tMining 173\nThis level of success is highly dependent on a company understanding its customers, \nvendors, business processes, and the extended supply chain very well.\nA large portion of \u201cunderstanding the customer\u201d can come from analyzing the vast \namount of data that a company collects. The cost of storing and processing data has decreased \ndramatically in the recent past, and, as a result, the amount of data stored in electronic form \nhas grown at an explosive rate. With the creation of large databases, the  possibility of ana-\nlyzing the data stored in them has emerged. The term data mining was originally used to \ndescribe the process through which previously unknown patterns in data were discovered. \nThis definition has since been stretched beyond those limits by some software vendors to \ninclude most forms of data analysis in order to increase sales with the popularity of the data \nmining label. In this chapter, we accept the original definition of data mining.\nA",
      "title": "unit2ii"
    }
  },
  "parent_c1d86bfa830e4851a1cbaa23df980325": {
    "id": "parent_c1d86bfa830e4851a1cbaa23df980325",
    "metadata": {
      "content": "rity of the data \nmining label. In this chapter, we accept the original definition of data mining.\nAlthough the term data mining is relatively new, the ideas behind it are not. Many \nof the techniques used in data mining have their roots in traditional statistical analysis \nand artificial intelligence work done since the early part of the 1980s. Why, then, has it \nsuddenly gained the attention of the business world? Following are some of most pro -\nnounced reasons:\n\u2022\tMore\tintense\tcompetition\tat\tthe\tglobal\tscale\tdriven\tby\tcustomers\u2019\tever-changing\t\nneeds and wants in an increasingly saturated marketplace.\n\u2022\tGeneral\trecognition\tof\tthe\tuntapped\tvalue\thidden\tin\tlarge\tdata\tsources.\n\u2022\tConsolidation\tand\tintegration\tof\tdatabase\trecords,\twhich\tenables\ta\tsingle\tview\tof\t\ncustomers, vendors, transactions, etc.\n\u2022\tConsolidation\tof\tdatabases\tand\tother\tdata\trepositories\tinto\ta\tsingle\tlocation\tin\tthe\t\nform of a data warehouse.\n\u2022\tThe\texponential\tincrease\tin\tdata\tprocessing\tand\tstorage\ttechnologies.\n\u2022\tSig",
      "title": "unit2ii"
    }
  },
  "parent_c13b279b149241ed88d42e1c3064bb43": {
    "id": "parent_c13b279b149241ed88d42e1c3064bb43",
    "metadata": {
      "content": "m of a data warehouse.\n\u2022\tThe\texponential\tincrease\tin\tdata\tprocessing\tand\tstorage\ttechnologies.\n\u2022\tSignificant\t reduction\t in\t the\t cost\t of\t hardware\t and\t software\t for\t data\t storage\t and\t\nprocessing.\n\u2022\tMovement\ttoward\tthe\tde-massification\t(conversion\tof\tinformation\tresources\tinto\t\nnonphysical form) of business practices.\nData generated by the Internet is increasing rapidly in both volume and complexity. \nLarge amounts of genomic data are being generated and accumulated all over the world. \nDisciplines such as astronomy and nuclear physics create huge quantities of data on a \nregular basis. Medical and pharmaceutical researchers constantly generate and store data \nthat can then be used in data mining applications to identify better ways to accurately \ndiagnose and treat illnesses and to discover new and improved drugs.\nOn the commercial side, perhaps the most common use of data mining has been in the \nfinance, retail, and healthcare sectors. Data mining is used to detect and reduce fr",
      "title": "unit2ii"
    }
  },
  "parent_15bdbf22b2a94157915a37cb61d74f97": {
    "id": "parent_15bdbf22b2a94157915a37cb61d74f97",
    "metadata": {
      "content": "as been in the \nfinance, retail, and healthcare sectors. Data mining is used to detect and reduce fraudulent \nactivities, especially in insurance claims and credit card use (Chan et al., 1999); to  identify \ncustomer buying patterns (Hoffman, 1999); to reclaim profitable customers (Hoffman, 1998); \nto identify trading rules from historical data; and to aid in increased profitability using \n market-basket analysis. Data mining is already widely used to  better  target clients, and with \nthe widespread development of e-commerce, this can only become more imperative with \ntime. See Application Case 4.1 for information on how Infinity P&C has used predictive \nanalytics and data mining to improve customer service, combat fraud, and increase profit.\nDefinitions, Characteristics, and Benefits\nSimply defined, data mining is a term used to describe discovering or \u201cmining\u201d knowl -\nedge from large amounts of data. When considered by analogy, one can easily realize \nthat the term data mining is a",
      "title": "unit2ii"
    }
  },
  "parent_ff5ddb94f9e44102b0d31b84301a93e6": {
    "id": "parent_ff5ddb94f9e44102b0d31b84301a93e6",
    "metadata": {
      "content": "amounts of data. When considered by analogy, one can easily realize \nthat the term data mining is a misnomer; that is, mining of gold from within rocks or \ndirt is referred to as \u201cgold\u201d mining rather than \u201crock\u201d or \u201cdirt\u201d mining. Therefore, data \n mining perhaps should have been named \u201cknowledge mining\u201d or \u201cknowledge  discovery.\u201d \nM04_SHAR4877_03_PIE_C04.indd   173 1/23/14   10:01 AM174\t Chapter \t4\t \u2022\t Data\tMining\nApplication Case 4.1\nSmarter Insurance: Infinity P&C Improves Customer Service and Combats Fraud  \nwith Predictive Analytics\nInfinity Property & Casualty Corporation, a provider \nof nonstandard personal automobile insurance with \nan emphasis on higher-risk drivers, depends on its \nability to identify fraudulent claims for sustained \nprofitability. As a result of implementing analytics \ntools (from IBM SPSS), Infinity P&C has doubled the \naccuracy of its fraud identification, contributing to a \nreturn on investment of 403 percent per a Nucleus \nResearch study. And the benefits",
      "title": "unit2ii"
    }
  },
  "parent_4e1b5c210b2f4692a3618cb904996f32": {
    "id": "parent_4e1b5c210b2f4692a3618cb904996f32",
    "metadata": {
      "content": "ntributing to a \nreturn on investment of 403 percent per a Nucleus \nResearch study. And the benefits don\u2019t stop there: \nAccording to Bill Dibble, senior vice president in \nClaims Operations at Infinity P&C, the use of pre -\ndictive analytics in serving the company\u2019s legitimate \nclaimants is of equal or even greater importance.\nLow-hanging fruit\nInitially, Dibble focused the power of predictive ana-\nlytics (i.e., data mining) to assist the company\u2019s Special \nInvestigative Unit (SIU). \u201cIn the early days of SIU, \nadjusters would use laminated cards with \u2018red flags\u2019 to \nindicate potential fraud. Taking those \u2018red flags\u2019 and \ndeveloping rules seemed like an area of low-hanging \nfruit where we could quickly demonstrate the benefit \nof our investment in predictive analytics.\u201d\nDibble then leveraged a successful approach \nfrom another part of the business. \u201cWe recognized \nhow important credit was in the underwriting arena, \nand I thought, \u2018Let\u2019s score our claims in the same \nway, to give us an",
      "title": "unit2ii"
    }
  },
  "parent_b96bd8e1c1274b65af83bf2913c26f88": {
    "id": "parent_b96bd8e1c1274b65af83bf2913c26f88",
    "metadata": {
      "content": "in the underwriting arena, \nand I thought, \u2018Let\u2019s score our claims in the same \nway, to give us an indicator of potential fraud.\u2019 The \nlarger the number we attach to a case, the more apt \nwe are to have a fraud situation. Lower number, get \nthe claim paid.\u201d Dibble notes that fraud represents \na $20 billion exposure to the insurance industry and \nin certain venues could be an element in around \n40\u00a0percent of claims. \u201cA key benefit of the IBM SPSS \nsystem is its ability to continually analyze and score \nthese claims, which helps ensure that we get the \nclaim to the right adjuster at the right time,\u201d he says.\nAdds Tony Smarrelli, vice president of National \nOperations: \u201cIndustry reports estimate one out of five \nclaims is pure fraud\u2014either opportunity fraud, where \nsomeone exaggerates an injury or vehicle damage, or \nthe hard-core criminal rings that work with unethi -\ncal clinics and attorneys. Rather than putting all five \ncustomers through an investigatory process, SPSS \nhelps us \u2018fas",
      "title": "unit2ii"
    }
  },
  "parent_b7dec6feda5f4fb9b93c365130672da4": {
    "id": "parent_b7dec6feda5f4fb9b93c365130672da4",
    "metadata": {
      "content": "rneys. Rather than putting all five \ncustomers through an investigatory process, SPSS \nhelps us \u2018fast-track\u2019 four of them and close their cases \nwithin a matter of days. This results in much happier \ncustomers, contributes to a more efficient workflow \nwith improved cycle times, and improves retention \ndue to an overall better claims experience.\u201d\nan unexpected benefit\nDibble saw subrogation, the process of collecting \ndamages from the at-fault driver\u2019s insurance com -\npany, as another piece of low-hanging fruit\u2014and he \nwas right. In the first month of using SPSS, Infinity \nP&C saw record recovery on paid collision claims, \nadding about $1 million directly to the company\u2019s \nbottom line and virtually eliminating the third-party \ncollection fees of more than $70,000 per month \nthat the company was used to paying. What\u2019s more, \neach of the following 4 or 5 months was even better \nthan the previous one. \u201cI never thought we would \nrecover the money that we\u2019ve recovered with SPSS \nin the subr",
      "title": "unit2ii"
    }
  },
  "parent_d65051b6c5044b468da9786f432d156a": {
    "id": "parent_d65051b6c5044b468da9786f432d156a",
    "metadata": {
      "content": "evious one. \u201cI never thought we would \nrecover the money that we\u2019ve recovered with SPSS \nin the subrogation area,\u201d he says. \u201cThat was a real \nsurprise to us. It brought a lot of attention to SPSS \nwithin the company, and to the value of predictive \nanalytics in general.\u201d\nThe rules-based IBM SPSS solution is well \nsuited to Infinity P&C\u2019s business. For example, in \nstates that have no-fault benefits, an insurance com-\npany can recover commercial vehicles or vehicles \nover a certain gross vehicle weight. \u201cWe can put a \nrule in IBM SPSS that if medical expenses are paid \non a claim involving this type of vehicle, it is imme-\ndiately referred to the subrogation department,\u201d \nexplains Dibble. \u201cThis is a real-time ability that \nkeeps us from missing potentially valuable subro -\ngation opportunities, which used to happen a lot \nwhen we relied solely on adjuster intuition.\u201d\nThe rules are just as important on the fraud \ninvestigation side. Continues Dibble: \u201cIf we see \nan accident that happened",
      "title": "unit2ii"
    }
  },
  "parent_9a88f4c9d85f4ebe95865bc17ecac305": {
    "id": "parent_9a88f4c9d85f4ebe95865bc17ecac305",
    "metadata": {
      "content": "important on the fraud \ninvestigation side. Continues Dibble: \u201cIf we see \nan accident that happened around 1:00 a.m. and \ninvolved a gas-guzzling GMC Suburban, we need to \nstart looking for fraud. So we dig a little deeper: \nIs this guy upside-down on his loan, such that \nhe owes more money than the car is worth? Did \nthe accident happen in a remote spot, suggesting \nthat it may have been staged? Does the individual \nmove frequently or list multiple addresses? As these \n elements are added to the equation, the score keeps \nM04_SHAR4877_03_PIE_C04.indd   174 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 175\nbuilding, and the case is more and more likely to be \nreferred to one of our SIU investigators.\u201d\nWith SPSS, Infinity P&C has reduced SIU refer-\nral time from an average of 45\u201360 days to approxi -\nmately 1\u20133 days, which means that investigators can \nget to work on the case before memories and stories \nstart to change, rental and storage charges mount, \nand the likelihood of getting a",
      "title": "unit2ii"
    }
  },
  "parent_ed0f2916c3cd455d8139b45932ce0912": {
    "id": "parent_ed0f2916c3cd455d8139b45932ce0912",
    "metadata": {
      "content": "ies and stories \nstart to change, rental and storage charges mount, \nand the likelihood of getting an attorney involved \nincreases. The company is also creating a better \nclaim for the SIU to investigate; a higher score cor -\nrelates to a higher probability of fraud.\nmaking us smarter\nSPSS rules start to score the claim immediately \non first notice of loss (FNOL) when the claimant \nreports the accident. \u201cWe have completely revised \nour FNOL screens to collect more data points,\u201d says \nDibble. \u201cSPSS has made us much smarter in asking \nquestions.\u201d Currently SPSS collects data mainly from \nthe company\u2019s claims and policy systems; a future \ninitiative to leverage the product\u2019s text mining capa-\nbilities will make the information in claims notes \navailable as well.\nHaving proven its value in subrogation and \nSIU, the SPSS solution is poised for expansion within \nInfinity P&C. \u201cOne of our key objectives moving for-\nward will be what we call \u2018right scripting,\u2019 where \nwe can script the appropri",
      "title": "unit2ii"
    }
  },
  "parent_a64f21aa3abd496da8c4b87a6a8d2b68": {
    "id": "parent_a64f21aa3abd496da8c4b87a6a8d2b68",
    "metadata": {
      "content": "bjectives moving for-\nward will be what we call \u2018right scripting,\u2019 where \nwe can script the appropriate questions for call cen-\nter agents based on the answers they get from the \nclaimant,\u201d says Dibble. \u201cWe\u2019ll also be instituting a \nprocess to flag claims with high litigation potential. \nBy reviewing past litigation claims, we can identify \npredictive traits and handle those cases on a priority \nbasis.\u201d Decision management, customer retention, \npricing analysis, and dashboards are also potential \nfuture applications of SPSS technology.\nBut at the end of the day, excellent customer \nservice remains the driving force behind Infinity \nP&C\u2019s use of predictive analytics. Concludes Dibble: \n\u201cMy goal is to pay the legitimate customer very \nquickly and get him on his way. People who are \nmore economically challenged need their car; they \ntypically don\u2019t have a spare vehicle. This is the car \nthey use to go back and forth to work, so I want to \nget them out and on the road without delay. IBM \nS",
      "title": "unit2ii"
    }
  },
  "parent_803c8d949a2c4c46b937ea510a3c7d6b": {
    "id": "parent_803c8d949a2c4c46b937ea510a3c7d6b",
    "metadata": {
      "content": "y use to go back and forth to work, so I want to \nget them out and on the road without delay. IBM \nSPSS makes this possible.\u201d\nQuestions for Discussion\n 1. How did Infinity P&C improve customer service \nwith data mining?\n 2. What were the challenges, the proposed  solution, \nand the obtained results?\n 3. What was their implementation strategy? Why \nis it important to produce results as early as \n possible in data mining studies?\nSource: public.dhe.ibm.com/common/ssi/ecm/en/ytc03160 \nusen/ytc03160usen.pdf.\nDespite the mismatch between the term and its meaning, data mining has become the \nchoice of the community. Many other names that are associated with data mining include \nknowledge extraction, pattern analysis, data archaeology, information harvesting, pattern \nsearching, and data dredging.\nTechnically speaking, data mining is a process that uses statistical, mathematical, \nand artificial intelligence techniques to extract and identify useful information and subse-\nquent knowledge (or",
      "title": "unit2ii"
    }
  },
  "parent_ee1356c859cf49d69d3663447bceffe7": {
    "id": "parent_ee1356c859cf49d69d3663447bceffe7",
    "metadata": {
      "content": "l intelligence techniques to extract and identify useful information and subse-\nquent knowledge (or patterns) from large sets of data. These patterns can be in the form \nof business rules, affinities, correlations, trends, or prediction models (see Nemati and \nBarko, 2001). Most literature defines data mining as \u201cthe nontrivial process of identifying \nvalid, novel, potentially useful, and ultimately understandable patterns in data stored in \nstructured databases,\u201d where the data are organized in records structured by categorical, \nordinal, and continuous variables (Fayyad et al., 1996). In this definition, the meanings of \nthe key term are as follows:\n\u2022\tProcess implies that data mining comprises many iterative steps.\n\u2022\tNontrivial means that some experimentation-type search or inference is involved; \nthat is, it is not as straightforward as a computation of predefined quantities.\n\u2022\tValid means that the discovered patterns should hold true on new data with \n sufficient degree of certaint",
      "title": "unit2ii"
    }
  },
  "parent_6b8c13e96c324efbad4091bf33183afd": {
    "id": "parent_6b8c13e96c324efbad4091bf33183afd",
    "metadata": {
      "content": "means that the discovered patterns should hold true on new data with \n sufficient degree of certainty.\nM04_SHAR4877_03_PIE_C04.indd   175 1/23/14   10:01 AM176\t Chapter \t4\t \u2022\t Data\tMining\n\u2022\tNovel means that the patterns are not previously known to the user within the \n context of the system being analyzed.\n\u2022\tPotentially useful means that the discovered patterns should lead to some benefit to \nthe user or task.\n\u2022\tUltimately understandable means that the pattern should make business sense that \nleads to the user saying \u201cmmm! It makes sense; why didn\u2019t I think of that\u201d if not \nimmediately, at least after some postprocessing.\nData mining is not a new discipline, but rather a new definition for the use of \nmany disciplines. Data mining is tightly positioned at the intersection of many disciplines, \nincluding statistics, artificial intelligence, machine learning, management science, infor -\nmation systems, and databases (see Figure 4.1). Using advances in all of these disciplines, \ndata mini",
      "title": "unit2ii"
    }
  },
  "parent_02ef1e843c804173aa2f2aaf4cab9cea": {
    "id": "parent_02ef1e843c804173aa2f2aaf4cab9cea",
    "metadata": {
      "content": "tion systems, and databases (see Figure 4.1). Using advances in all of these disciplines, \ndata mining strives to make progress in extracting useful information and knowledge \nfrom large databases. It is an emerging field that has attracted much attention in a very \nshort time.\nThe following are the major characteristics and objectives of data mining:\n\u2022\tData\tare\toften\tburied\tdeep\twithin\tvery\tlarge\tdatabases,\twhich\tsometimes\tcontain\t\ndata from several years. In many cases, the data are cleansed and consolidated into \na data warehouse. Data may be presented in a variety of formats (see Technology \nInsights 4.1 for a brief taxonomy if data).\n\u2022\tThe\tdata\tmining\tenvironment\tis\tusually\ta\tclient/server\tarchitecture\tor\ta\tWeb-based\t\ninformation systems architecture.\n\u2022\tSophisticated\t new\t tools,\t including\t advanced\t visualization\t tools,\t help\t to\t remove\t\nthe information ore buried in corporate files or archival public records. Finding \nit involves massaging and synchronizing the data to get th",
      "title": "unit2ii"
    }
  },
  "parent_1a4b7150ebb5448cbdcd5fdcc8f2f1da": {
    "id": "parent_1a4b7150ebb5448cbdcd5fdcc8f2f1da",
    "metadata": {
      "content": "iles or archival public records. Finding \nit involves massaging and synchronizing the data to get the right results. Cutting-\nedge data miners are also exploring the usefulness of soft data (i.e., unstructured \ntext stored in such places as Lotus Notes databases, text files on the Internet, or \nenterprise-wide intranets).\n\u2022\tThe\tminer\tis\toften\tan\tend\tuser,\tempowered\tby\tdata\tdrills\tand\tother\tpower\tquery\ttools\t\nto ask ad hoc questions and obtain answers quickly, with little or no programming skill.\n\u2022\tStriking\tit\trich\toften\tinvolves\tfinding\tan\tunexpected\tresult\tand\trequires\tend\tusers\tto\t\nthink creatively throughout the process, including the interpretation of the findings.\nAr\ntificial Intelligence\nStatistics\nManagement Science\nand Information Systems\nData\nMining\nPattern\nRecognition\nMathematical\nModeling\nDatabases\nMachine\nLearning\nFigure 4.1 Data Mining as a Blend of Multiple Disciplines.\nM04_SHAR4877_03_PIE_C04.indd   176 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 177\ntechnOLOgy insight",
      "title": "unit2ii"
    }
  },
  "parent_d9e931f3f6fa46a9b0893670e778b53a": {
    "id": "parent_d9e931f3f6fa46a9b0893670e778b53a",
    "metadata": {
      "content": "_SHAR4877_03_PIE_C04.indd   176 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 177\ntechnOLOgy insights 4.1 a simple taxonomy of data\nData refers to a collection of facts usually obtained as the result of experiences, observations, or \nexperiments. Data may consist of numbers, letters, words, images, voice recording, and so on as \nmeasurements of a set of variables. Data are often viewed as the lowest level of abstraction from \nwhich information and then knowledge is derived.\nAt the highest level of abstraction, one can classify data as structured and unstructured (or \nsemi-structured).\tUnstructured/semi-structured\tdata\tis\tcomposed\tof\tany\tcombination\tof\ttextual,\t\nimagery,\tvoice,\tand\tWeb\tcontent.\tUnstructured/semi-structured\tdata\twill\tbe\tcovered\tin\tmore\t\ndetail in the text mining and web mining chapter. Structured data is what data mining algorithms \nuse and can be classified as categorical or numeric. The categorical data can be subdivided into \nnominal or ordinal data, whereas numeric d",
      "title": "unit2ii"
    }
  },
  "parent_c817f241820c4c429e6c992901a70556": {
    "id": "parent_c817f241820c4c429e6c992901a70556",
    "metadata": {
      "content": "or numeric. The categorical data can be subdivided into \nnominal or ordinal data, whereas numeric data can be subdivided into interval or ratio. Figure \n4.2 shows a simple taxonomy of data.\n\u2022\tcategorical data represent the labels of multiple classes used to divide a variable into \nspecific groups. Examples of categorical variables include race, sex, age group, and edu -\ncational level. Although the latter two variables may also be considered in a numerical \nmanner by using exact values for age and highest grade completed, it is often more \ninformative to categorize such variables into a relatively small number of ordered classes. \nThe categorical data may also be called discrete data, implying that it represents a finite \n number of values with no continuum between them. Even if the values used for the \n categorical (or discrete) variables are numeric, these numbers are nothing more than \n symbols and do not imply the possibility of calculating fractional values.\nData\nStructured\nCateg",
      "title": "unit2ii"
    }
  },
  "parent_a54dec64e8b944c48f3219ea7d568d28": {
    "id": "parent_a54dec64e8b944c48f3219ea7d568d28",
    "metadata": {
      "content": "n \n symbols and do not imply the possibility of calculating fractional values.\nData\nStructured\nCategorical Numerical Textual Multimedia HTML/XML\nUnstructured or\nSemi-structured\nNominal Ordinal Interval Ratio\nFigure 4.2 A Simple Taxonomy of Data in Data Mining.\n\u2022\tData\t mining\t tools\t are\t readily\t combined\t with\t spreadsheets\t and\t other\t software\t\ndevelopment tools. Thus, the mined data can be analyzed and deployed quickly \nand easily.\n\u2022\tBecause\tof\tthe\tlarge\tamounts\tof\tdata\tand\tmassive\tsearch\tefforts,\tit\tis\tsometimes\t\nnecessary to use parallel processing for data mining.\nA company that effectively leverages data mining tools and technologies can acquire \nand maintain a strategic competitive advantage. Data mining offers organizations an indis-\npensable decision-enhancing environment to exploit new opportunities by transforming \ndata into a strategic weapon. See Nemati and Barko (2001) for a more detailed discussion \non the strategic benefits of data mining.\nM04_SHAR4877_03_PIE_C04.indd",
      "title": "unit2ii"
    }
  },
  "parent_602d89ed834a42c5a116c7930025f51b": {
    "id": "parent_602d89ed834a42c5a116c7930025f51b",
    "metadata": {
      "content": "r a more detailed discussion \non the strategic benefits of data mining.\nM04_SHAR4877_03_PIE_C04.indd   177 1/23/14   10:01 AM178\t Chapter \t4\t \u2022\t Data\tMining\n\u2022\tnominal data  contain measurements of simple codes assigned to objects as labels, \nwhich are not measurements. For example, the variable marital status can be generally \n categorized as (1) single, (2) married, and (3) divorced. Nominal data can be represented \nwith\tbinomial\tvalues\thaving\ttwo\tpossible\tvalues\t(e.g.,\tyes/no,\ttrue/false,\tgood/bad),\tor\t\nmultinomial\tvalues\thaving\tthree\tor\tmore\tpossible\tvalues\t(e.g.,\tbrown/green/blue,\twhite/\t\nblack/Latino/Asian,\tsingle/married/divorced).\n\u2022\tOrdinal data contain codes assigned to objects or events as labels that also represent \nthe rank order among them. For example, the variable credit score  can be generally \n categorized as (1) low, (2) medium, or (3) high. Similar ordered relationships can be seen \nin variables such as age group (i.e., child, young, middle-aged, elderly) and educatio",
      "title": "unit2ii"
    }
  },
  "parent_24a96e4b2b634401993eea310ed392b1": {
    "id": "parent_24a96e4b2b634401993eea310ed392b1",
    "metadata": {
      "content": "can be seen \nin variables such as age group (i.e., child, young, middle-aged, elderly) and educational \nlevel (i.e., high school, college, graduate school). Some data mining algorithms, such as \nordinal multiple logistic regression,  take into account this additional rank-order informa -\ntion to build a better classification model.\n\u2022\tnumeric data represent the numeric values of specific variables. Examples of numerically \nvalued variables include age, number of children, total household income (in U.S. dol -\nlars), travel distance (in miles), and temperature (in Fahrenheit degrees). Numeric  values \nrepresenting a variable can be integer (taking only whole numbers) or real (taking also \nthe fractional number). The numeric data may also be called continuous data,  implying \nthat the variable contains continuous measures on a specific scale that allows insertion \nof interim values. Unlike a discrete variable, which represents finite, countable data, a \ncontinuous variable represents sca",
      "title": "unit2ii"
    }
  },
  "parent_628e3945b3ad4484b9723481a3697ae4": {
    "id": "parent_628e3945b3ad4484b9723481a3697ae4",
    "metadata": {
      "content": "a discrete variable, which represents finite, countable data, a \ncontinuous variable represents scalable measurements, and it is possible for the data to \ncontain an infinite number of fractional values.\n\u2022\tinterval data are variables that can be measured on interval scales. A common example of \ninterval scale measurement is temperature on the Celsius scale. In this particular scale, the unit \nof\tmeasurement\tis\t1/100\tof\tthe\tdifference\tbetween\tthe\tmelting\ttemperature\tand\tthe\t\tboiling\t\ntemperature of water in atmospheric pressure; that is, there is not an absolute zero value.\n\u2022\tratio data include measurement variables commonly found in the physical sciences and \nengineering. Mass, length, time, plane angle, energy, and electric charge are examples of \nphysical measures that are ratio scales. The scale type takes its name from the fact that \nmeasurement is the estimation of the ratio between a magnitude of a continuous quantity \nand a unit magnitude of the same kind. Informally, the disti",
      "title": "unit2ii"
    }
  },
  "parent_e9971902002b4973a18fb57f5fcac259": {
    "id": "parent_e9971902002b4973a18fb57f5fcac259",
    "metadata": {
      "content": "n a magnitude of a continuous quantity \nand a unit magnitude of the same kind. Informally, the distinguishing feature of a ratio \nscale is the possession of a nonarbitrary zero value. For example, the Kelvin temperature \nscale has a nonarbitrary zero point of absolute zero, which is equal to \u2013273.15 degrees \nCelsius. This zero point is nonarbitrary because the particles that comprise matter at this \ntemperature have zero kinetic energy.\nOther data types, including textual, spatial, imagery, and voice, need to be converted \ninto some form of categorical or numeric representation before they can be processed by data \n mining algorithms. Data can also be classified as static or dynamic (i.e., temporal or time series).\nSome data mining methods and algorithms are very selective about the type of data that \nthey can handle. Providing them with incompatible data types may lead to incorrect models \nor (more often) halt the model development process. For example, some data mining meth -\nods nee",
      "title": "unit2ii"
    }
  },
  "parent_39cdb370b5794d46b87c3351f4119f0f": {
    "id": "parent_39cdb370b5794d46b87c3351f4119f0f",
    "metadata": {
      "content": "ls \nor (more often) halt the model development process. For example, some data mining meth -\nods need all of the variables (both input as well as output) represented as numerically valued \nvariables (e.g., neural networks, support vector machines, logistic regression). The nominal or \nordinal variables are converted into numeric representations using some type of 1-of-N pseudo \nvariables (e.g., a categorical variable with three unique values can be transformed into three \npseudo variables with binary values\u20141 or 0). Because this process may increase the number \nof variables, one should be cautious about the effect of such representations, especially for the \ncategorical variables that have large numbers of unique values.\nSimilarly, some data mining methods, such as ID3 (a classic decision tree algorithm) and \nrough sets (a relatively new rule induction algorithm), need all of the variables represented as \ncategorically valued variables. Early versions of these methods required the user",
      "title": "unit2ii"
    }
  },
  "parent_a5454f104bc24cba9d5c412948afd157": {
    "id": "parent_a5454f104bc24cba9d5c412948afd157",
    "metadata": {
      "content": "es represented as \ncategorically valued variables. Early versions of these methods required the user to discretize \nnumeric variables into categorical representations before they could be processed by the algo -\nrithm. The good news is that most implementations of these algorithms in widely available \nsoftware tools accept a mix of numeric and nominal variables and internally make the necessary \nconversions before processing the data.\nM04_SHAR4877_03_PIE_C04.indd   178 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 179\nHow Data Mining Works\nUsing existing and relevant data, data mining builds models to identify patterns among \nthe attributes presented in the data set. Models are the mathematical representations \n(simple\tlinear\trelationships\tand/or\tcomplex\thighly\tnonlinear\trelationships)\tthat\tidentify\t\nthe patterns among the attributes of the objects (e.g., customers) described in the data set. \nSome of these patterns are explanatory (explaining the interrelationships and affinities \namo",
      "title": "unit2ii"
    }
  },
  "parent_4a904cf88d1a48a1b8738b5226d98f0e": {
    "id": "parent_4a904cf88d1a48a1b8738b5226d98f0e",
    "metadata": {
      "content": "set. \nSome of these patterns are explanatory (explaining the interrelationships and affinities \namong the attributes), whereas others are predictive (foretelling future values of certain \nattributes). In general, data mining seeks to identify four major types of patterns:\n 1. Associations find the commonly co-occurring groupings of things, such as beer and \ndiapers going together in market-basket analysis.\n 2. Predictions tell the nature of future occurrences of certain events based on what has \nhappened in the past, such as predicting the winner of the Super Bowl or forecast-\ning the absolute temperature of a particular day.\nApplication Case 4.2\nHarnessing Analytics to Combat Crime: Predictive Analytics Helps Memphis Police Department \nPinpoint Crime and Focus Police Resources\nWhen Larry Godwin took over as director of the \nMemphis Police Department (MPD) in 2004, crime \nacross the metro area was surging, and city  leaders \nwere growing impatient. \u201cThe mayor told me I want \nthis crim",
      "title": "unit2ii"
    }
  },
  "parent_428571015b364f0eac4e4cab01cd97f4": {
    "id": "parent_428571015b364f0eac4e4cab01cd97f4",
    "metadata": {
      "content": "ro area was surging, and city  leaders \nwere growing impatient. \u201cThe mayor told me I want \nthis crime problem fixed,\u201d recalls Godwin, a 38-year \nveteran of the MPD. But the new director under -\nstood that a business-as-usual approach to crime \nfighting would no longer be good enough. Early \non in his tenure, Godwin convened a  meeting of \ntop law enforcement experts to formulate a fresh \n strategy to turn the tide in the city\u2019s crime war. \nAmong the participants in this mini-summit was \nDr.\u00a0Richard Janikowski, a professor of criminology at \nthe University of Memphis, who specialized in using \npredictive analytics to better understand patterns.\nfighting crime with analytics\nJanikowski proposed the idea of mining MPD\u2019s \ncrime data banks to help zero in on where and \nwhen criminals were hitting hardest and then \u201cfocus \npolice resources intelligently by putting them in the \nright place, on the right day, at the right time.\u201d By \ndoing so, he said, \u201cyou\u2019ll either deter criminal activ-\nity or",
      "title": "unit2ii"
    }
  },
  "parent_7149965ebe8d4595b13a2549d1aca4d1": {
    "id": "parent_7149965ebe8d4595b13a2549d1aca4d1",
    "metadata": {
      "content": "he right day, at the right time.\u201d By \ndoing so, he said, \u201cyou\u2019ll either deter criminal activ-\nity or you\u2019re going to catch people.\u201d The idea made \nsense to Godwin and in short order the MPD and \nthe University of Memphis\u2014along with Project Safe \nNeighborhoods\u2014teamed up in a pilot program that \nlater became known as Operation Blue CRUSH, or \nCrime Reduction Utilizing Statistical History.\nThe data-driven pilot was wildly successful. \nDuring one 2-hour operation, officers arrested more \ncriminals than they normally apprehended over an \nentire weekend. But for Blue CRUSH to be success-\nful on a citywide scale, the MPD would need to align \nits resources and operations to take full advantage \nof the power of predictive analytics. If done right, \na citywide rollout of Blue CRUSH had the potential \nto save money through efficient deployments\u2014a big \nplus in a city facing serious budget pressures\u2014even \nas the intelligence-based approach would help drive \ndown overall crime rates. Shortly after,",
      "title": "unit2ii"
    }
  },
  "parent_ce66ff47e8fd4832955e00e55c2e08b0": {
    "id": "parent_ce66ff47e8fd4832955e00e55c2e08b0",
    "metadata": {
      "content": "even \nas the intelligence-based approach would help drive \ndown overall crime rates. Shortly after, all precincts \nembraced Blue CRUSH, and predictive analytics has \nbecome one of the most potent weapons in MPD\u2019s \ncrime-fighting arsenal. At the heart of the system is a \nversatile statistical analysis tool\u2014IBM SPSS Modeler\u2014\nthat enables officers to unlock the intelligence hid -\nden in the department\u2019s huge digital library of crime \nrecords and police reports going back nearly a decade.\nsafer streets\nAll indications are that Blue CRUSH and its \n intelligence-driven crime-fighting techniques are \nputting a serious dent in Memphis-area crime. Since \nthe program was launched, the number of Part One \ncrimes\u2014a category of serious offenses including \nhomicide, rape, aggravated assault, auto theft, and \nlarceny\u2014has plummeted, dropping 27 percent from \n(Continued )\nM04_SHAR4877_03_PIE_C04.indd   179 1/23/14   10:01 AM180\t Chapter \t4\t \u2022\t Data\tMining\nApplication Case 4.2 (Continued)\n2006 to 2010.",
      "title": "unit2ii"
    }
  },
  "parent_4ef22a74cb71400e97802fcf32dace8c": {
    "id": "parent_4ef22a74cb71400e97802fcf32dace8c",
    "metadata": {
      "content": "79 1/23/14   10:01 AM180\t Chapter \t4\t \u2022\t Data\tMining\nApplication Case 4.2 (Continued)\n2006 to 2010. Intelligent positioning of resources has \nbeen a major factor in the decline, helping to deter \ncriminal activity by having more officers patrolling \nthe right area at the right time on the right day.\nMore intelligent deployments also lead to \nfaster reaction time, since officers are likely to be \nbetter positioned to respond to an unfolding crime. \nIn addition, MPD\u2019s organized crime units are using \ndata from the predictive analytics solution to run \nspecial details that lead to successful multi-agency \ndrug busts and other criminal roundups. Not sur -\nprisingly, arrest rates have been steadily improving \nacross the Memphis area, which has a population of \n680,000.\nToday, the MPD is continuing to explore new \nways to exploit statistical analysis in its crime- fighting \nmission. Of course, predictive analytics and data \nmining is just one part of MPD\u2019s overall strategy for \nkeeping Memph",
      "title": "unit2ii"
    }
  },
  "parent_403051acba9c4f088daedd7ed0fd985a": {
    "id": "parent_403051acba9c4f088daedd7ed0fd985a",
    "metadata": {
      "content": "predictive analytics and data \nmining is just one part of MPD\u2019s overall strategy for \nkeeping Memphis residents safe. Effective liaisons \nwith community groups and businesses, strong part-\nnerships with regional and federal law enforcement \nagencies, and intelligent organizational and opera -\ntional structures all play a part in  continuing MPD\u2019s \nsuccess story. \u201cAt the end of the day, everybody \nwants to reduce crime,\u201d says Godwin. \u201cEverybody \nwants a safe community because without it, you \ndon\u2019t have economic growth, you don\u2019t have \nanything.\u201d\nQuestions for Discussion\n 1. How did the Memphis Police Department used \ndata mining to better combat crime?\n 2. What were the challenges, the proposed solu -\ntion, and the obtained results?\nSource: public.dhe.ibm.com/common/ssi/ecm/en/imc14541 \nusen/imc14541usen.pdf (accessed September 2013).\n 3. Clusters identify natural groupings of things based on their known characteristics, \nsuch as assigning customers in different segments based on thei",
      "title": "unit2ii"
    }
  },
  "parent_9911981bf74342efa37dc674fc73c67f": {
    "id": "parent_9911981bf74342efa37dc674fc73c67f",
    "metadata": {
      "content": "sed on their known characteristics, \nsuch as assigning customers in different segments based on their demographics and \npast purchase behaviors.\n 4. Sequential relationships discover time-ordered events, such as predicting that an \nexisting banking customer who already has a checking account will open a savings \naccount followed by an investment account within a year.\nThese types of patterns have been manually extracted from data by humans for \ncenturies, but the increasing volume of data in modern times has created a need for more \nautomatic approaches. As data sets have grown in size and complexity, direct manual \ndata analysis has increasingly been augmented with indirect, automatic data processing \ntools that use sophisticated methodologies, methods, and algorithms. The manifestation \nof such evolution of automated and semiautomated means of processing large data sets is \nnow commonly referred to as data mining.\nGenerally speaking, data mining tasks can be classified into three mai",
      "title": "unit2ii"
    }
  },
  "parent_35e47f9bafdb4db08983094bd2667232": {
    "id": "parent_35e47f9bafdb4db08983094bd2667232",
    "metadata": {
      "content": "y referred to as data mining.\nGenerally speaking, data mining tasks can be classified into three main catego -\nries: prediction, association, and clustering. Based on the way in which the patterns are \nextracted from the historical data, the learning algorithms of data mining methods can \nbe classified as either supervised or unsupervised. With supervised learning algorithms, \nthe training data includes both the descriptive attributes (i.e., independent variables or \ndecision variables) as well as the class attribute (i.e., output variable or result variable). In \ncontrast, with unsupervised learning the training data includes only the descriptive attri -\nbutes. Figure 4.3 shows a simple taxonomy for data mining tasks, along with the learning \nmethods, and popular algorithms for each of the data mining tasks.\npreDiCtion prediction is commonly referred to as the act of telling about the future. It \ndiffers from simple guessing by taking into account the experiences, opinions, and other",
      "title": "unit2ii"
    }
  },
  "parent_25a09bf3740b4d9d82feab0685ccc584": {
    "id": "parent_25a09bf3740b4d9d82feab0685ccc584",
    "metadata": {
      "content": "uture. It \ndiffers from simple guessing by taking into account the experiences, opinions, and other \nrelevant information in conducting the task of foretelling. A term that is commonly associ-\nated with prediction is forecasting. Even though many believe that these two terms are \nM04_SHAR4877_03_PIE_C04.indd   180 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 181\nsynonymous, there is a subtle but critical difference between the two. Whereas prediction \nis largely experience and opinion based, forecasting is data and model based. That is, in \norder of increasing reliability, one might list the relevant terms as guessing, predicting, \nand forecasting, respectively. In data mining terminology, prediction and forecasting are \nused synonymously, and the term prediction is used as the common representation of the \nact. Depending on the nature of what is being predicted, prediction can be named more \nspecifically as classification (where the predicted thing, such as tomorrow\u2019s forecast, is a",
      "title": "unit2ii"
    }
  },
  "parent_bcd9b0572ece48dbb4b038d5e9b47b97": {
    "id": "parent_bcd9b0572ece48dbb4b038d5e9b47b97",
    "metadata": {
      "content": "more \nspecifically as classification (where the predicted thing, such as tomorrow\u2019s forecast, is a \nclass label such as \u201crainy\u201d or \u201csunny\u201d) or regression (where the predicted thing, such as \ntomorrow\u2019s temperature, is a real number, such as \u201c65\u00b0F\u201d).\nClassiFiCation classification, or supervised induction, is perhaps the most common \nof all data mining tasks. The objective of classification is to analyze the historical data \nstored in a database and automatically generate a model that can predict future behavior. \nThis induced model consists of generalizations over the records of a training data set, \nwhich help distinguish predefined classes. The hope is that the model can then be used \nto predict the classes of other unclassified records and, more important, to accurately \npredict actual future events.\nCommon classification tools include neural networks and decision trees (from \nmachine learning), logistic regression and discriminant analysis (from traditional  statistics), \nand emerg",
      "title": "unit2ii"
    }
  },
  "parent_6c95a4c849e34249ad5b84ba034b49a4": {
    "id": "parent_6c95a4c849e34249ad5b84ba034b49a4",
    "metadata": {
      "content": "learning), logistic regression and discriminant analysis (from traditional  statistics), \nand emerging tools such as rough sets, support vector machines, and genetic algorithms. \nStatistics-based classification techniques (e.g., logistic regression and  discriminant  analysis) \nhave received their share of criticism\u2014that they make unrealistic assumptions about \nData Mining\nPrediction\nAssociation\nClassification\nRegression\nLink\nanalysis\nClustering\nOutlier\nanalysis\nSequence\nanalysis\nLearning Method Popular Algorithms\nSupervised\nSupervised\nSupervised\nUnsupervised\nUnsupervised\nUnsupervised\nUnsupervised\nClassification and Regression Trees,\nANN, SVM, Genetic Algorithms\nDecision Trees, ANN/MLP, SVM, Rough\nSets, Genetic Algorithms\nLinear/Nonlinear Regression, Regression\nTrees, ANN/MLP, SVM\nApriori, OneR, ZeroR, Eclat\nExpectation Maximization Apriori\nAlgorithm, Graph-Based Matching\nApriori Algorithm, FP-Growth technique\nK-means, ANN/SOM\nK-means, Expectation Maximization (EM)\nUnsupervised\nFigure",
      "title": "unit2ii"
    }
  },
  "parent_377ea9c4286b4b2fa8c0035de016139c": {
    "id": "parent_377ea9c4286b4b2fa8c0035de016139c",
    "metadata": {
      "content": "thm, FP-Growth technique\nK-means, ANN/SOM\nK-means, Expectation Maximization (EM)\nUnsupervised\nFigure 4.3 A Simple Taxonomy for Data Mining Tasks.\nM04_SHAR4877_03_PIE_C04.indd   181 1/23/14   10:01 AM182\t Chapter \t4\t \u2022\t Data\tMining\nthe\u00a0data, such as independence and normality\u2014which limit their use in  classification-type \ndata mining projects.\nNeural networks involve the development of mathematical structures (somewhat \nresembling the biological neural networks in the human brain) that have the capability \nto learn from past experiences presented in the form of well-structured data sets. They \ntend to be more effective when the number of variables involved is rather large and the \nrelationships among them are complex and imprecise. Neural networks have disadvan -\ntages as well as advantages. For example, it is usually very difficult to provide a good \nrationale for the predictions made by a neural network. Also, neural networks tend to \nneed considerable training. Unfortunately, the tim",
      "title": "unit2ii"
    }
  },
  "parent_422fdda575df419b8955403cbb6eaa14": {
    "id": "parent_422fdda575df419b8955403cbb6eaa14",
    "metadata": {
      "content": "a neural network. Also, neural networks tend to \nneed considerable training. Unfortunately, the time needed for training tends to increase \nexponentially as the volume of data increases, and, in general, neural networks cannot be \ntrained on very large databases. These and other factors have limited the applicability of \nneural networks in data-rich domains.\nDecision trees classify data into a finite number of classes based on the values of \nthe input variables. Decision trees are essentially a hierarchy of if-then statements and are \nthus significantly faster than neural networks. They are most appropriate for  categorical \nand interval data. Therefore, incorporating continuous variables into a  decision tree \nframework requires discretization; that is, converting continuous valued numerical vari -\nables to ranges and categories.\nA related category of classification tools is rule induction. Unlike with a decision \ntree, with rule induction the if-then statements are induced from the",
      "title": "unit2ii"
    }
  },
  "parent_eab193ab7a2e4f0697579078955f6eaa": {
    "id": "parent_eab193ab7a2e4f0697579078955f6eaa",
    "metadata": {
      "content": "tion. Unlike with a decision \ntree, with rule induction the if-then statements are induced from the training data directly, \nand they need not be hierarchical in nature. Other, more recent techniques such as SVM, \nrough sets, and genetic algorithms are gradually finding their way into the arsenal of clas-\nsification algorithms.\nClustering clustering partitions a collection of things (e.g., objects, events, etc., \npresented in a structured data set) into segments (or natural groupings) whose mem -\nbers share similar characteristics. Unlike in classification, in clustering the class labels are \nunknown. As the selected algorithm goes through the data set, identifying the common -\nalities of things based on their characteristics, the clusters are established. Because the \nclusters are determined using a heuristic-type algorithm, and because different algorithms \nmay end up with different sets of clusters for the same data set, before the results of \n clustering techniques are put to actua",
      "title": "unit2ii"
    }
  },
  "parent_fdfd020324bc4bf68b7f29cfc9587ba1": {
    "id": "parent_fdfd020324bc4bf68b7f29cfc9587ba1",
    "metadata": {
      "content": "ts of clusters for the same data set, before the results of \n clustering techniques are put to actual use it may be necessary for an expert to inter -\npret, and potentially modify, the suggested clusters. After reasonable clusters have been \n identified, they can be used to classify and interpret new data.\nNot surprisingly, clustering techniques include optimization. The goal of clustering \nis to create groups so that the members within each group have maximum similarity and \nthe members across groups have minimum similarity. The most commonly used cluster -\ning techniques include k-means (from statistics) and self-organizing maps (from machine \nlearning), which is a unique neural network architecture developed by Kohonen (1982).\nFirms often effectively use their data mining systems to perform market segmenta -\ntion with cluster analysis. Cluster analysis is a means of identifying classes of items so that \nitems in a cluster have more in common with each other than with items in other",
      "title": "unit2ii"
    }
  },
  "parent_75519c225903478ba5b077fa87c15674": {
    "id": "parent_75519c225903478ba5b077fa87c15674",
    "metadata": {
      "content": "s of items so that \nitems in a cluster have more in common with each other than with items in other clusters. \nIt can be used in segmenting customers and directing appropriate marketing products to \nthe segments at the right time in the right format at the right price. Cluster analysis is also \nused to identify natural groupings of events or objects so that a common set of character-\nistics of these groups can be identified to describe them.\nassoCiations associations, or association rule learning in data mining,  is a popu -\nlar and well-researched technique for discovering interesting relationships among vari -\nables in large databases. Thanks to automated data-gathering technologies such as bar \ncode scanners, the use of association rules for discovering regularities among products \nM04_SHAR4877_03_PIE_C04.indd   182 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 183\nin large-scale transactions recorded by point-of-sale systems in supermarkets has become \na common knowledge-discovery",
      "title": "unit2ii"
    }
  },
  "parent_ad888df9a1554e1096ed2c294398b5ec": {
    "id": "parent_ad888df9a1554e1096ed2c294398b5ec",
    "metadata": {
      "content": "sactions recorded by point-of-sale systems in supermarkets has become \na common knowledge-discovery task in the retail industry. In the context of the retail \nindustry, association rule mining is often called market-basket analysis.\nTwo commonly used derivatives of association rule mining are link analysis and \nsequence mining . With link analysis, the linkage among many objects of  interest is \n discovered automatically, such as the link between Web pages and referential  relationships \namong groups of academic publication authors. With sequence mining, relationships \nare examined in terms of their order of occurrence to identify associations over time. \nAlgorithms used in association rule mining include the popular Apriori (where frequent \nitemsets are identified) and FP-Growth, OneR, ZeroR, and Eclat.\nVisualization anD tiMe-series ForeCasting Two techniques often associated with \ndata mining are visualization and time-series forecasting. Visualization can be used in \nconjunction wit",
      "title": "unit2ii"
    }
  },
  "parent_9d8ab0525604483fb5bddde75d15bfed": {
    "id": "parent_9d8ab0525604483fb5bddde75d15bfed",
    "metadata": {
      "content": "mining are visualization and time-series forecasting. Visualization can be used in \nconjunction with other data mining techniques to gain a clearer understanding of under-\nlying relationships. As the importance of visualization has increased in recent years, a \nnew term, visual analytics, has emerged. The idea is to combine analytics and visualiza-\ntion in a single environment for easier and faster knowledge creation. Visual analytics is \ncovered in detail in Chapter 3. In time-series forecasting, the data consists of values of \nthe same variable that is captured and stored over time in regular intervals. These data \nare then used to develop forecasting models to extrapolate the future values of the same \nvariable.\nData Mining Versus statistics\nData mining and statistics have a lot in common. They both look for relationships within \ndata. Most people call statistics the \u201cfoundation of data mining.\u201d The main difference \nbetween the two is that statistics starts with a well-defined prop",
      "title": "unit2ii"
    }
  },
  "parent_6d358f8926154f3e982ef2cae2d6a19b": {
    "id": "parent_6d358f8926154f3e982ef2cae2d6a19b",
    "metadata": {
      "content": "ata mining.\u201d The main difference \nbetween the two is that statistics starts with a well-defined proposition and hypothesis \nwhile data mining starts with a loosely defined discovery statement. Statistics collects \nsample data (i.e., primary data) to test the hypothesis, while data mining and analytics \nuse all of the existing data (i.e., often observational, secondary data) to discover novel \npatterns and relationships. Another difference comes from the size of data that they use. \nData mining looks for data sets that are as \u201cbig\u201d as possible while statistics looks for the \nright\tsize\tof\tdata\t(if\tthe\tdata\tis\tlarger\tthan\twhat\tis\tneeded/required\tfor\tthe\tstatistical\t\nanalysis, a sample of the data is used). The meaning of \u201clarge data\u201d is rather different \nbetween statistics and data mining. While a few hundred to a thousand data points are \nlarge enough to a statistician, several million to a few billion data points are considered \nlarge for data mining studies.\nsectiOn 4.2 revieW Questi",
      "title": "unit2ii"
    }
  },
  "parent_bc228f0a28d0465cb1d2b360ffcc9563": {
    "id": "parent_bc228f0a28d0465cb1d2b360ffcc9563",
    "metadata": {
      "content": "a few billion data points are considered \nlarge for data mining studies.\nsectiOn 4.2 revieW Questi Ons\n 1. Define data mining. Why are there many different names and definitions for data \nmining?\n 2. What recent factors have increased the popularity of data mining?\n 3. Is data mining a new discipline? Explain.\n 4. What are some major data mining methods and algorithms?\n 5. What are the key differences between the major data mining methods?\n4.3 Data Mining appliCations\nData mining has become a popular tool in addressing many complex businesses prob -\nlems and opportunities. It has been proven to be very successful and helpful in many \nareas, some of which are shown by the following representative examples. The goal of \nM04_SHAR4877_03_PIE_C04.indd   183 1/23/14   10:01 AM184\t Chapter \t4\t \u2022\t Data\tMining\nmany of these business data mining applications is to solve a pressing problem or to \nexplore an emerging business opportunity in order to create a sustainable competitive \nadvantage.\n\u2022",
      "title": "unit2ii"
    }
  },
  "parent_40c0ea43b67f41309366c9b86f8cd0d7": {
    "id": "parent_40c0ea43b67f41309366c9b86f8cd0d7",
    "metadata": {
      "content": "explore an emerging business opportunity in order to create a sustainable competitive \nadvantage.\n\u2022\tCustomer relationship management. Customer relationship management (CRM) \nis the extension of traditional marketing. The goal of CRM is to create one-on-one \n relationships with customers by developing an intimate understanding of their needs \nand wants. As businesses build relationships with their customers over time through \na variety of interactions (e.g., product inquiries, sales, service requests,  warranty calls, \nproduct reviews, social media connections), they accumulate  tremendous amounts \nof data. When combined with demographic and socioeconomic attributes, this \n\tinformation-rich\tdata\tcan\tbe\tused\tto\t(1)\tidentify\tmost\tlikely\tresponders/buyers\tof\tnew\t\nproducts/services\t(i.e.,\tcustomer\tprofiling);\t(2)\t\tunderstand\tthe\troot\tcauses\tof\tcustomer\t\nattrition in order to improve customer retention (i.e., churn analysis); (3)\u00a0  discover \n time-variant associations between products and se",
      "title": "unit2ii"
    }
  },
  "parent_a654a7de7a3045b581ee366820c43761": {
    "id": "parent_a654a7de7a3045b581ee366820c43761",
    "metadata": {
      "content": "retention (i.e., churn analysis); (3)\u00a0  discover \n time-variant associations between products and services to maximize sales and \n customer value; and (4) identify the most profitable customers and their preferential \nneeds to strengthen relationships and to maximize sales.\n\u2022\tBanking. Data mining can help banks with the following: (1) automating the \nloan application process by accurately predicting the most probable defaulters; \n(2)\u00a0detecting fraudulent credit card and online-banking transactions; (3) identifying \nways to maximize customer value by selling them products and services that they \nare most likely to buy; and (4) optimizing the cash return by accurately forecasting \nthe cash flow on banking entities (e.g., ATM machines, banking branches).\n\u2022\tRetailing and logistics.  In the retailing industry, data mining can be used to \n(1) predict accurate sales volumes at specific retail locations in order to determine \ncorrect inventory levels; (2) identify sales relationships between d",
      "title": "unit2ii"
    }
  },
  "parent_16cc35f744a74e998c4ff365a3e8d988": {
    "id": "parent_16cc35f744a74e998c4ff365a3e8d988",
    "metadata": {
      "content": "ocations in order to determine \ncorrect inventory levels; (2) identify sales relationships between different products \n(with market-basket analysis) to improve the store layout and optimize sales promo-\ntions; (3) forecast consumption levels of different product types (based on seasonal \nand environmental conditions) to optimize logistics and, hence, maximize sales; and \n(4) discover interesting patterns in the movement of products (especially for the \nproducts that have a limited shelf life because they are prone to expiration, perish-\nability, and contamination) in a supply chain by analyzing sensory and RFID data.\n\u2022\tManufacturing and production.  Manufacturers can use data mining to \n(1)\u00a0 predict machinery failures before they occur through the use of sensory data \n(enabling what is called condition-based maintenance ); (2) identify anomalies \nand commonalities in production systems to optimize manufacturing capacity; and \n(3)\u00a0discover novel patterns to identify and improve product",
      "title": "unit2ii"
    }
  },
  "parent_03c1e700d1884888a845d67cd8421c0d": {
    "id": "parent_03c1e700d1884888a845d67cd8421c0d",
    "metadata": {
      "content": "o optimize manufacturing capacity; and \n(3)\u00a0discover novel patterns to identify and improve product quality.\n\u2022\tBrokerage and securities trading.  Brokers and traders use data mining to \n(1)\u00a0predict when and how much certain bond prices will change; (2) forecast the \nrange and direction of stock fluctuations; (3) assess the effect of particular issues \nand events on overall market movements; and (4) identify and prevent fraudulent \nactivities in securities trading.\n\u2022\tInsurance. The insurance industry uses data mining techniques to (1)  forecast \nclaim amounts for property and medical coverage costs for better business \n planning;\u00a0 (2) determine optimal rate plans based on the analysis of claims and \n customer data; (3) predict which customers are more likely to buy new policies \nwith special features; and (4) identify and prevent incorrect claim payments and \nfraudulent activities.\n\u2022\tComputer hardware and software. Data mining can be used to (1) predict disk \ndrive failures well before",
      "title": "unit2ii"
    }
  },
  "parent_1bf65260749943879ee9767e9e9ff257": {
    "id": "parent_1bf65260749943879ee9767e9e9ff257",
    "metadata": {
      "content": "uter hardware and software. Data mining can be used to (1) predict disk \ndrive failures well before they actually occur; (2) identify and filter unwanted Web \ncontent and e-mail messages; (3) detect and prevent computer network  security \nbridges; and (4) identify potentially unsecure software products.\nM04_SHAR4877_03_PIE_C04.indd   184 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 185\n\u2022\tGovernment and defense.  Data mining also has a number of military \n applications. It can be used to (1) forecast the cost of moving military personnel and \nequipment; (2) predict an adversary\u2019s moves and, hence, develop more  successful \nstrategies for military engagements; (3) predict resource consumption for better \nplanning and budgeting; and (4) identify classes of unique experiences, strategies, \nand lessons learned from military operations for better knowledge sharing through-\nout the organization.\n\u2022\tTravel industry (airlines, hotels/resorts, rental car companies).  Data \n mining has a variety",
      "title": "unit2ii"
    }
  },
  "parent_77012ed0026b4827afa80f0c452663ad": {
    "id": "parent_77012ed0026b4827afa80f0c452663ad",
    "metadata": {
      "content": "n.\n\u2022\tTravel industry (airlines, hotels/resorts, rental car companies).  Data \n mining has a variety of uses in the travel industry. It is successfully used to (1)\u00a0 predict \nsales\tof\tdifferent\tservices\t(seat\ttypes\tin\tairplanes,\troom\ttypes\tin\thotels/resorts,\tcar\t\ntypes in rental car companies) in order to optimally price services to maximize \nrevenues as a function of time-varying transactions (commonly referred to as yield \nmanagement); (2) forecast demand at different locations to better allocate limited \norganizational resources; (3) identify the most profitable customers and provide \nthem with personalized services to maintain their repeat business; and (4) retain \nvaluable employees by identifying and acting on the root causes for attrition.\n\u2022\tHealthcare. Data mining has a number of healthcare applications. It can be used \nto (1) identify people without health insurance and the factors underlying this unde-\nsired phenomenon; (2) identify novel cost\u2013benefit relationships between diff",
      "title": "unit2ii"
    }
  },
  "parent_8f3dfddccf1c43cdaf855fdc1cf12dc9": {
    "id": "parent_8f3dfddccf1c43cdaf855fdc1cf12dc9",
    "metadata": {
      "content": "s underlying this unde-\nsired phenomenon; (2) identify novel cost\u2013benefit relationships between different \ntreatments to develop more effective strategies; (3) forecast the level and the time of \ndemand at different service locations to optimally allocate organizational resources; \nand (4) understand the underlying reasons for customer and employee attrition.\n\u2022\tMedicine. Use of data mining in medicine should be viewed as an invaluable \ncomplement to traditional medical research, which is mainly clinical and biolog -\nical in nature. Data mining analyses can (1) identify novel patterns to improve \nsurvivability of patients with cancer; (2) predict success rates of organ transplan -\ntation patients to develop better donor-organ matching policies; (3) identify the \nfunctions of  different genes in the human chromosome (known as genomics); and \n(4)\u00a0 discover the relationships between symptoms and illnesses (as well as illnesses \nand successful treatments) to help medical professionals make",
      "title": "unit2ii"
    }
  },
  "parent_a82753e0735246b2a2ab6bfa151d9c29": {
    "id": "parent_a82753e0735246b2a2ab6bfa151d9c29",
    "metadata": {
      "content": "and illnesses (as well as illnesses \nand successful treatments) to help medical professionals make informed and correct \ndecisions in a timely manner.\n\u2022\tEntertainment industry. Data mining is successfully used by the  entertainment \nindustry to (1) analyze viewer data to decide what programs to show during \nprime time and how to maximize returns by knowing where to insert advertise -\nments; (2)\u00a0 predict the financial success of movies before they are produced to \nmake investment decisions and to optimize the returns; (3) forecast the demand at \n different  locations and different times to better schedule entertainment events and \nto  optimally allocate resources; and (4) develop optimal pricing policies to maxi -\nmize revenues.\n\u2022\tHomeland security and law enforcement.  Data mining has a number of \nhomeland security and law enforcement applications. Data mining is often used to \n(1) identify patterns of terrorist behaviors (see Application Case 4.3 for an example \nof the use of data mi",
      "title": "unit2ii"
    }
  },
  "parent_8c1f64a432fe40a7ac492b9141b09d50": {
    "id": "parent_8c1f64a432fe40a7ac492b9141b09d50",
    "metadata": {
      "content": "tify patterns of terrorist behaviors (see Application Case 4.3 for an example \nof the use of data mining to track funding of terrorists\u2019 activities); (2) discover crime \npatterns (e.g., locations, timings, criminal behaviors, and other related attributes) \nto help solve criminal cases in a timely manner; (3) predict and eliminate potential \nbiological and chemical attacks to the nation\u2019s critical infrastructure by analyzing \nspecial-purpose sensory data; and (4) identify and stop malicious attacks on critical \ninformation infrastructures (often called information warfare).\n\u2022\tSports. Data mining was used to improve the performance of National Basketball \nAssociation (NBA) teams in the United States. Major League Baseball teams are \ninto predictive analytics and data mining to optimally utilize their limited resources \nfor a winning season (see Moneyball article in Chapter 1). In fact, most, if not all,  \nM04_SHAR4877_03_PIE_C04.indd   185 1/23/14   10:01 AM186\t Chapter \t4\t \u2022\t Data\tMinin",
      "title": "unit2ii"
    }
  },
  "parent_4d88e77853ef431a88b56d6dc3392c29": {
    "id": "parent_4d88e77853ef431a88b56d6dc3392c29",
    "metadata": {
      "content": "t, if not all,  \nM04_SHAR4877_03_PIE_C04.indd   185 1/23/14   10:01 AM186\t Chapter \t4\t \u2022\t Data\tMining\nprofessional sports nowadays employ data crunchers and use data mining to increase \ntheir chances of winning. Data mining applications are not limited to professional \nsports. In a recently published article, Delen at al. (2012) developed  models to \npredict NCAA Bowl Game outcomes using a wide range of variables about the two \nopposing teams\u2019 previous games statistics. Wright (2012) used a variety of predictors \nfor examination of the NCAA men\u2019s basketball championship bracket (a.k.a. March \nMadness).\nsectiOn 4.3 revieW Questi Ons\n 1. What are the major application areas for data mining?\n 2. Identify at least five specific applications of data mining and list five common charac-\nteristics of these applications.\n 3. What do you think is the most prominent application area for data mining? Why?\n 4. Can you think of other application areas for data mining not discussed in this section?",
      "title": "unit2ii"
    }
  },
  "parent_a2a912b1e0234ee0abe68bd001436f4c": {
    "id": "parent_a2a912b1e0234ee0abe68bd001436f4c",
    "metadata": {
      "content": "? Why?\n 4. Can you think of other application areas for data mining not discussed in this section? \nExplain.\nApplication Case 4.3\nA Mine on Terrorist Funding\nThe terrorist attack on the World Trade Center on \nSeptember 11, 2001, underlined the importance \nof open source intelligence. The USA PATRIOT \nAct and the creation of the U.S. Department of \nHomeland Security (DHS) heralded the potential \napplication of information technology and data \nmining  techniques to detect money laundering and \nother forms of terrorist financing. Law enforcement \nagencies have been focusing on money laundering \nactivities via normal transactions through banks and \nother  financial service organizations.\nLaw enforcement agencies are now  focusing \non international trade pricing as a terrorism  funding \ntool. International trade has been used by money \nlaunderers to move money silently out of a  country \nwithout attracting government attention. This  transfer \nis achieved by overvaluing imports and underval",
      "title": "unit2ii"
    }
  },
  "parent_c78cd599eb95468a8c1fb52caa1ee0fd": {
    "id": "parent_c78cd599eb95468a8c1fb52caa1ee0fd",
    "metadata": {
      "content": "out attracting government attention. This  transfer \nis achieved by overvaluing imports and undervalu -\ning exports. For example, a  domestic importer \nand foreign exporter could form a  partnership \nand  overvalue imports, thereby  transferring money \nfrom the home country, resulting in crimes related \nto  customs fraud, income tax evasion, and money \n laundering. The foreign exporter could be a  member \nof a terrorist organization.\nData mining techniques focus on analysis of \ndata on import and export transactions from the \nU.S.\u00a0 Department of Commerce and commerce-\nrelated entities. Import prices that exceed the upper \nquartile import prices and export prices that are \nlower than the lower quartile export prices are \ntracked. The focus is on abnormal transfer prices \nbetween  corporations that may result in shifting \n taxable income and taxes out of the United States. \nAn observed price  deviation may be related to \nincome\ttax\tavoidance/evasion,\tmoney\tlaundering,\tor\t\n terrorist  fin",
      "title": "unit2ii"
    }
  },
  "parent_683a2b992d324ce8946c48c2afaefd25": {
    "id": "parent_683a2b992d324ce8946c48c2afaefd25",
    "metadata": {
      "content": "ce  deviation may be related to \nincome\ttax\tavoidance/evasion,\tmoney\tlaundering,\tor\t\n terrorist  financing. The observed price  deviation may \nalso be due to an error in the U.S. trade database.\nData mining will result in efficient evaluation \nof data, which, in turn, will aid in the fight against \nterrorism. The application of information technology \nand data mining techniques to financial transactions \ncan contribute to better intelligence information.\nQuestions for Discussion\n 1. How can data mining be used to fight terrorism? \nComment on what else can be done beyond \nwhat is covered in this short application case.\n 2. Do you think data mining, while essential for \nfighting terrorist cells, also jeopardizes individu -\nals\u2019 rights of privacy?\nSources: J. S. Zdanowic, \u201cDetecting Money Laundering and \nTerrorist Financing via Data Mining,\u201d Communications of the \nACM, Vol. 47, No. 5, May 2004, p. 53; and R. J. Bolton, \u201cStatistical \nFraud Detection: A Review,\u201d Statistical Science, Vol. 17",
      "title": "unit2ii"
    }
  },
  "parent_99b0ff00bfe94859adb10761a9bbfdc4": {
    "id": "parent_99b0ff00bfe94859adb10761a9bbfdc4",
    "metadata": {
      "content": "004, p. 53; and R. J. Bolton, \u201cStatistical \nFraud Detection: A Review,\u201d Statistical Science, Vol. 17, No. 3, \nJanuary 2002, p. 235.\nM04_SHAR4877_03_PIE_C04.indd   186 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 187\n4.4 Data Mining proCess\nIn order to systematically carry out data mining projects, a general process is usually fol-\nlowed. Based on best practices, data mining researchers and practitioners have proposed \nseveral processes (workflows or simple step-by-step approaches) to maximize the chances \nof success in conducting data mining projects. These efforts have led to several standardized \nprocesses, some of which (a few of the most popular ones) are described in this section.\nOne such standardized process, arguably the most popular one, Cross-Industry \nStandard Process for Data Mining\u2014 crisp-dm\u2014was proposed in the mid-1990s by a \nEuropean consortium of companies to serve as a nonproprietary standard methodology \nfor data mining (CRISP-DM, 2013). Figure 4.4 illustrates this p",
      "title": "unit2ii"
    }
  },
  "parent_366d84ea3a4b4e67a9d3f2b443a75385": {
    "id": "parent_366d84ea3a4b4e67a9d3f2b443a75385",
    "metadata": {
      "content": "nonproprietary standard methodology \nfor data mining (CRISP-DM, 2013). Figure 4.4 illustrates this proposed process, which is a \nsequence of six steps that starts with a good understanding of the business and the need for \nthe data mining project (i.e., the application domain) and ends with the deployment of the \nsolution that satisfied the specific business need. Even though these steps are sequential in \nnature, there is usually a great deal of backtracking. Because the data mining is driven by \nexperience\tand\texperimentation,\tdepending\ton\tthe\tproblem\tsituation\tand\tthe\tknowledge/\nexperience of the analyst, the whole process can be very iterative (i.e., one should expect \nto go back and forth through the steps quite a few times) and time-consuming. Because \nlater steps are built on the outcomes of the former ones, one should pay extra attention to \nthe earlier steps in order not to put the whole study on an incorrect path from the onset.\nstep 1: Business understanding\nThe key element",
      "title": "unit2ii"
    }
  },
  "parent_4dc9da592d1c45559b9f43f7c387cd0f": {
    "id": "parent_4dc9da592d1c45559b9f43f7c387cd0f",
    "metadata": {
      "content": "the whole study on an incorrect path from the onset.\nstep 1: Business understanding\nThe key element of any data mining study is to know what the study is for. Answering \nsuch a question begins with a thorough understanding of the managerial need for new \nknowledge and an explicit specification of the business objective regarding the study to \nBusiness\nUnderstanding\n1\nData\nUnderstanding\n2\nData\nPreparation\n3\nModel\nBuilding\n4\nTesting and\nEvaluation\n5\nDeployment\n6\nData\nSources\nFigure 4.4 The Six-Step CRISP-DM Data Mining Process.\nM04_SHAR4877_03_PIE_C04.indd   187 1/23/14   10:01 AM188\t Chapter \t4\t \u2022\t Data\tMining\nbe\u00a0conducted. Specific goals such as \u201cWhat are the common characteristics of the  customers \nwe have lost to our competitors recently?\u201d or \u201cWhat are typical profiles of our customers, \nand how much value does each of them provide to us?\u201d are needed. Then a project plan for \nfinding such knowledge is developed that specifies the people responsible for collecting the \ndata, analyzin",
      "title": "unit2ii"
    }
  },
  "parent_ab8e196b8d7b4fe08fae80e44054d512": {
    "id": "parent_ab8e196b8d7b4fe08fae80e44054d512",
    "metadata": {
      "content": "such knowledge is developed that specifies the people responsible for collecting the \ndata, analyzing the data, and reporting the findings. At this early stage, a budget to support \nthe study should also be established, at least at a high level with rough numbers.\nstep 2: Data understanding\nA data mining study is specific to addressing a well-defined business task, and  different \nbusiness tasks require different sets of data. Following the business understanding, the \nmain activity of the data mining process is to identify the relevant data from many  available \ndatabases. Some key points must be considered in the data identification and selection \nphase. First and foremost, the analyst should be clear and concise about the description \nof the data mining task so that the most relevant data can be identified. For example, a \nretail data mining project may seek to identify spending behaviors of female shoppers \nwho purchase seasonal clothes based on their demographics, credit card tran",
      "title": "unit2ii"
    }
  },
  "parent_da91036d44c14797b9b92622c15d0ee1": {
    "id": "parent_da91036d44c14797b9b92622c15d0ee1",
    "metadata": {
      "content": "iors of female shoppers \nwho purchase seasonal clothes based on their demographics, credit card transactions, \nand socioeconomic attributes. Furthermore, the analyst should build an intimate under -\nstanding of the data sources (e.g., where the relevant data are stored and in what form; \nwhat the process of collecting the data is\u2014automated versus manual; who the collectors \nof the data are and how often the data are updated) and the variables (e.g., What are the \nmost\trelevant\tvariables?\tAre\tthere\tany\tsynonymous\tand/or\thomonymous\tvariables?\tAre\t\nthe variables independent of each other\u2014do they stand as a complete information source \nwithout overlapping or conflicting information?).\nIn order to better understand the data, the analyst often uses a variety of  statistical \nand graphical techniques, such as simple statistical summaries of each variable (e.g.,\u00a0for \nnumeric\tvariables\tthe\taverage,\tminimum/maximum,\tmedian,\tand\tstandard\tdeviation\tare\t\namong the calculated measures, whereas for c",
      "title": "unit2ii"
    }
  },
  "parent_b46f377bed654461aa148dd7aeb66039": {
    "id": "parent_b46f377bed654461aa148dd7aeb66039",
    "metadata": {
      "content": "e,\tminimum/maximum,\tmedian,\tand\tstandard\tdeviation\tare\t\namong the calculated measures, whereas for categorical variables the mode and  frequency \ntables are calculated), correlation analysis, scatterplots, histograms, and box plots. A care-\nful identification and selection of data sources and the most relevant variables can make it \neasier for data mining algorithms to quickly discover useful knowledge patterns.\nData sources for data selection can vary. Normally, data sources for business appli-\ncations include demographic data (such as income, education, number of households, \nand age), sociographic data (such as hobby, club membership, and entertainment), trans-\nactional data (sales record, credit card spending, issued checks), and so on.\nData can be categorized as quantitative and qualitative. Quantitative data is measured \nusing numeric values. It can be discrete (such as integers) or continuous (such as real num-\nbers). Qualitative data, also known as categorical data, contains bo",
      "title": "unit2ii"
    }
  },
  "parent_4928bfe59f1146beba4f2ac470affae7": {
    "id": "parent_4928bfe59f1146beba4f2ac470affae7",
    "metadata": {
      "content": "r continuous (such as real num-\nbers). Qualitative data, also known as categorical data, contains both nominal and ordinal \ndata. Nominal data has finite nonordered values (e.g., gender data, which has two values: \nmale and female). Ordinal data has finite ordered values. For example, customer credit rat-\nings are considered ordinal data because the ratings can be excellent, fair, and bad.\nQuantitative data can be readily represented by some sort of probability distri -\nbution. A probability distribution describes how the data is dispersed and shaped. For \ninstance, normally distributed data is symmetric and is commonly referred to as being \na bell-shaped curve. Qualitative data may be coded to numbers and then described by \nfrequency distributions. Once the relevant data are selected according to the data mining \nbusiness objective, data preprocessing should be pursued.\nstep 3: Data preparation\nThe purpose of data preparation (more commonly called data preprocessing) is to take the \nd",
      "title": "unit2ii"
    }
  },
  "parent_affd94946e8c4c849515eb1e3887e42a": {
    "id": "parent_affd94946e8c4c849515eb1e3887e42a",
    "metadata": {
      "content": "paration\nThe purpose of data preparation (more commonly called data preprocessing) is to take the \ndata identified in the previous step and prepare it for analysis by data mining  methods. \nCompared to the other steps in CRISP-DM, data preprocessing consumes the most time \nM04_SHAR4877_03_PIE_C04.indd   188 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 189\nand effort; most believe that this step accounts for roughly 80 percent of the total time \nspent on a data mining project. The reason for such an enormous effort spent on this step \nis the fact that real-world data is generally incomplete (lacking attribute values, lacking \ncertain attributes of interest, or containing only aggregate data), noisy (containing errors or \noutliers), and inconsistent (containing discrepancies in codes or names). Figure 4.5 shows \nthe four main steps needed to convert the raw real-world data into minable data sets.\nIn the first phase of data preprocessing, the relevant data is collected from the identi-\nf",
      "title": "unit2ii"
    }
  },
  "parent_4191aee23a49447fb5df5ab1ed4917eb": {
    "id": "parent_4191aee23a49447fb5df5ab1ed4917eb",
    "metadata": {
      "content": "ta sets.\nIn the first phase of data preprocessing, the relevant data is collected from the identi-\nfied sources (accomplished in the previous step\u2014Data Understanding\u2014of the CRISP-DM \nprocess), the necessary records and variables are selected (based on an intimate under -\nstanding of the data the unnecessary sections are filtered out), and the records coming \nfrom multiple data sources are integrated (again, using the intimate understanding of the \ndata, the synonyms and homonyms are to be handled properly).\nIn the second phase of data preprocessing, the data is cleaned (this step is also \nknown as data scrubbing). In this step, the values in the data set are identified and dealt \nwith. In some cases, missing values are an anomaly in the data set, in which case they \nneed to be imputed (filled with a most probable value) or ignored; in other cases, the \nmissing values are a natural part of the data set (e.g., the household income field is often \nleft unanswered by people who are in the",
      "title": "unit2ii"
    }
  },
  "parent_6f724560a12e4ef9bdcf1bb2061cae9c": {
    "id": "parent_6f724560a12e4ef9bdcf1bb2061cae9c",
    "metadata": {
      "content": "f the data set (e.g., the household income field is often \nleft unanswered by people who are in the top income tier). In this step, the analyst \nshould also identify noisy values in the data (i.e., the outliers) and smooth them out. \nAdditionally, inconsistencies (unusual values within a variable) in the data should be \nhandled\tusing\tdomain\tknowledge\tand/or\texpert\topinion.\nIn the third phase of data preprocessing, the data is transformed for better  processing. \nFor instance, in many cases the data is normalized between a certain minimum and maxi-\nmum for all variables in order to mitigate the potential bias of one variable (having large \nnumeric values, such as for household income) dominating other variables (such as number \nData Consolidation\nData Cleaning\nData Transformation\nData Reduction\nReal-World\nData\nWell-Formed\nData\n\u2022 Collect data\n\u2022 Select data\n\u2022 Integrate data\n\u2022 Impute missing values\n\u2022 Reduce noise in data\n\u2022 Eliminate inconsistencies\n\u2022 Normalize data\n\u2022 Discretize/aggregate d",
      "title": "unit2ii"
    }
  },
  "parent_377e4c0579c84f3e9f656ae3f9e758e3": {
    "id": "parent_377e4c0579c84f3e9f656ae3f9e758e3",
    "metadata": {
      "content": "values\n\u2022 Reduce noise in data\n\u2022 Eliminate inconsistencies\n\u2022 Normalize data\n\u2022 Discretize/aggregate data\n\u2022 Construct new attributes\n\u2022 Reduce number of variables\n\u2022 Reduce number of cases\n\u2022 Balance skewed data\nFigure 4.5 Data Preprocessing Steps.\nM04_SHAR4877_03_PIE_C04.indd   189 1/23/14   10:01 AM190\t Chapter \t4\t \u2022\t Data\tMining\nof dependents or years in service, which may potentially be more important) having smaller \nvalues.\tAnother\ttransformation\tthat\ttakes\tplace\tis\tdiscretization\tand/or\taggregation.\tIn\tsome\t\ncases, the numeric variables are converted to categorical values (e.g., low, medium, high); \nin other cases a nominal variable\u2019s unique value range is reduced to a smaller set using \nconcept hierarchies (e.g., as opposed to using the individual states with 50 different values, \none may choose to use several regions for a variable that shows location) in order to have \na data set that is more amenable to computer processing. Still, in other cases one might \nchoose to create new va",
      "title": "unit2ii"
    }
  },
  "parent_c6ab644d77bd4878b6292f4550e73bb2": {
    "id": "parent_c6ab644d77bd4878b6292f4550e73bb2",
    "metadata": {
      "content": "at is more amenable to computer processing. Still, in other cases one might \nchoose to create new variables based on the existing ones in order to magnify the informa-\ntion found in a collection of variables in the data set. For instance, in an organ transplan-\ntation data set one might choose to use a single variable showing the blood-type match  \n(1: match, 0: no-match) as opposed to separate multinominal values for the blood type of \nboth the donor and the recipient. Such simplification may increase the information content \nwhile reducing the complexity of the relationships in the data.\nThe final phase of data preprocessing is data reduction. Even though data miners like \nto have large data sets, too much data is also a problem. In the simplest sense, one can \nvisualize the data commonly used in data mining projects as a flat file consisting of two \ndimensions:\tvariables\t(the\tnumber\tof\tcolumns)\tand\tcases/records\t(the\tnumber\tof\trows).\tIn\t\nsome cases (e.g., image processing and genome",
      "title": "unit2ii"
    }
  },
  "parent_86b57de6ee2248e8b1267b133bbfe0b7": {
    "id": "parent_86b57de6ee2248e8b1267b133bbfe0b7",
    "metadata": {
      "content": "f\tcolumns)\tand\tcases/records\t(the\tnumber\tof\trows).\tIn\t\nsome cases (e.g., image processing and genome projects with complex microarray data), \nthe number of variables can be rather large, and the analyst must reduce the number down \nto a manageable size. Because the variables are treated as different dimensions that describe \nthe phenomenon from different perspectives, in data mining this process is commonly \ncalled dimensional reduction. Even though there is not a single best way to accomplish this \ntask, one can use the findings from previously published literature; consult domain experts; \nrun appropriate statistical tests (e.g., principal component analysis or independent compo-\nnent analysis); and, more preferably, use a combination of these techniques to successfully \nreduce the dimensions in the data into a more manageable and most relevant subset.\nWith respect to the other dimension (i.e., the number of cases), some data sets may \ninclude millions or billions of records. Even th",
      "title": "unit2ii"
    }
  },
  "parent_444a3d573f1b42e492ce4e3d2d34f053": {
    "id": "parent_444a3d573f1b42e492ce4e3d2d34f053",
    "metadata": {
      "content": "on (i.e., the number of cases), some data sets may \ninclude millions or billions of records. Even though computing power is increasing expo-\nnentially, processing such a large number of records may not be practical or feasible. In such \ncases, one may need to sample a subset of the data for analysis. The underlying assumption \nof sampling is that the subset of the data will contain all relevant patterns of the complete \ndata set. In a homogenous data set, such an assumption may hold well, but real-world data \nis hardly ever homogenous. The analyst should be extremely careful in selecting a subset of \nthe data that reflects the essence of the complete data set and is not specific to a subgroup \nor subcategory. The data is usually sorted on some variable, and taking a section of the \ndata from the top or bottom may lead to a biased data set on specific values of the indexed \nvariable; therefore, one should always try to randomly select the records on the sample \nset. For skewed data, str",
      "title": "unit2ii"
    }
  },
  "parent_f46f1e88b19a4efa9599456c0482e5a4": {
    "id": "parent_f46f1e88b19a4efa9599456c0482e5a4",
    "metadata": {
      "content": "efore, one should always try to randomly select the records on the sample \nset. For skewed data, straightforward random sampling may not be sufficient, and stratified \nsampling (a proportional representation of different subgroups in the data is represented in \nthe sample data set) may be required. Speaking of skewed data: It is a good practice to bal-\nance the highly skewed data by either oversampling the less represented or undersampling \nthe more represented classes. Research has shown that balanced data sets tend to produce \n better prediction models than unbalanced ones (Wilson and Sharda, 1994).\nThe essence of data preprocessing is summarized in Table 4.1, which maps the main \nphases (along with their problem descriptions) to a representative list of tasks and algorithms.\nstep 4: Model Building\nIn this step, various modeling techniques are selected and applied to an already pre -\npared data set in order to address the specific business need. The model-building step \nalso encompas",
      "title": "unit2ii"
    }
  },
  "parent_1d0b50dfa0f84eac99f5d23d5f1adaf9": {
    "id": "parent_1d0b50dfa0f84eac99f5d23d5f1adaf9",
    "metadata": {
      "content": "ared data set in order to address the specific business need. The model-building step \nalso encompasses the assessment and comparative analysis of the various models built. \nBecause there is not a universally known best method or algorithm for a data mining task, \nM04_SHAR4877_03_PIE_C04.indd   190 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 191\ntaBle 4.1 A Summary of Data Preprocessing Tasks and Potential Methods\nMain Task Subtasks Popular Methods\nData consolidation Access and collect the data SQL queries, software agents, Web \nservices.\nSelect and filter the data Domain expertise, SQL queries, statistical \ntests.\nIntegrate and unify the \ndata\nSQL queries, domain expertise, ontology-\ndriven data mapping.\nData cleaning Handle missing values in \nthe data\nFill in missing values (imputations) with \nmost appropriate values (mean, median, \nmin/max, mode, etc.); recode the  missing \nvalues with a constant such as \u201cML\u201d; \n remove the record of the missing value; do \nnothing.\nIdentify and red",
      "title": "unit2ii"
    }
  },
  "parent_e66c0bf30cf741cb8100949fa178364b": {
    "id": "parent_e66c0bf30cf741cb8100949fa178364b",
    "metadata": {
      "content": "ith a constant such as \u201cML\u201d; \n remove the record of the missing value; do \nnothing.\nIdentify and reduce noise in \nthe data\nIdentify the outliers in data with simple \nstatistical techniques (such as averages \nand standard deviations) or with cluster \nanalysis; once identified, either remove the \noutliers or smooth them by using binning, \nregression, or simple averages.\nFind and eliminate errone-\nous data\nIdentify the erroneous values in data (other \nthan outliers), such as odd values, incon-\nsistent class labels, odd distributions; once \nidentified, use domain expertise to correct \nthe values or remove the records holding \nthe erroneous values.\nData transformation Normalize the data Reduce the range of values in each numer-\nically valued variable to a standard range \n(e.g., 0 to 1 or \u20131 to +1) by using a variety \nof normalization or scaling techniques.\nDiscretize or aggregate the \ndata\nIf needed, convert the numeric variables \ninto discrete representations using range- \nor frequency-bas",
      "title": "unit2ii"
    }
  },
  "parent_5e8a419fe3884e68808d52b7b9082898": {
    "id": "parent_5e8a419fe3884e68808d52b7b9082898",
    "metadata": {
      "content": "needed, convert the numeric variables \ninto discrete representations using range- \nor frequency-based binning techniques; \nfor categorical variables, reduce the num-\nber of values by applying proper concept \nhierarchies.\nConstruct new attributes Derive new and more informative vari-\nables from the existing ones using a wide \nrange of mathematical functions (as \nsimple as addition and multiplication or as \ncomplex as a hybrid combination of log \ntransformations).\nData reduction Reduce number of \nattributes\nPrincipal component analysis, independent \ncomponent analysis, Chi-square testing, \ncorrelation analysis, and decision tree \ninduction.\nReduce number of records Random sampling, stratified sampling, \nexpert\u2013knowledge-driven purposeful \nsampling.\nBalance skewed data Oversample the less represented or under-\nsample the more represented classes.\nM04_SHAR4877_03_PIE_C04.indd   191 1/23/14   10:01 AM192\t Chapter \t4\t \u2022\t Data\tMining\none should use a variety of viable model types along with",
      "title": "unit2ii"
    }
  },
  "parent_314d7836673c435cbdc144b4c9b93ead": {
    "id": "parent_314d7836673c435cbdc144b4c9b93ead",
    "metadata": {
      "content": "10:01 AM192\t Chapter \t4\t \u2022\t Data\tMining\none should use a variety of viable model types along with a well-defined experimenta -\ntion and assessment strategy to identify the \u201cbest\u201d method for a given purpose. Even for \na single method or algorithm, a number of parameters need to be calibrated to obtain \noptimal results. Some methods may have specific requirements on the way that the data \nis to be formatted; thus, stepping back to the data preparation step is often necessary. \nApplication Case 4.4 presents a research study where a number of model types are devel-\noped and compared to each other.\nDepending on the business need, the data mining task can be of a prediction (either \nclassification or regression), an association, or a clustering type. Each of these data mining \ntasks can use a variety of data mining methods and algorithms. Some of these data mining \nmethods were explained earlier in this chapter, and some of the most popular algorithms, \nincluding decision trees for classif",
      "title": "unit2ii"
    }
  },
  "parent_acda8377bac945e7ae52715bbd9e2e7f": {
    "id": "parent_acda8377bac945e7ae52715bbd9e2e7f",
    "metadata": {
      "content": "lier in this chapter, and some of the most popular algorithms, \nincluding decision trees for classification, k-means for clustering, and the Apriori algo -\nrithm for association rule mining, are described later in this chapter.\nstep 5: testing and evaluation\nIn step 5, the developed models are assessed and evaluated for their accuracy and gen -\nerality. This step assesses the degree to which the selected model (or models) meets the \nbusiness objectives and, if so, to what extent (i.e., do more models need to be developed \nand assessed). Another option is to test the developed model(s) in a real-world scenario \nif time and budget constraints permit. Even though the outcome of the developed models \nis expected to relate to the original business objectives, other findings that are not nec -\nessarily related to the original business objectives but that might also unveil additional \ninformation or hints for future directions often are discovered.\nThe testing and evaluation step is a critica",
      "title": "unit2ii"
    }
  },
  "parent_dd0daaa45092421c8d1be6177d5dcb8c": {
    "id": "parent_dd0daaa45092421c8d1be6177d5dcb8c",
    "metadata": {
      "content": "on or hints for future directions often are discovered.\nThe testing and evaluation step is a critical and challenging task. No value is added by \nthe data mining task until the business value obtained from discovered knowledge patterns \nis identified and recognized. Determining the business value from discovered knowledge \npatterns is somewhat similar to playing with puzzles. The extracted knowledge patterns \nare pieces of the puzzle that need to be put together in the context of the specific business \npurpose. The success of this identification operation depends on the interaction among \ndata analysts, business analysts, and decision makers (such as business managers). Because \ndata analysts may not have the full understanding of the data mining objectives and what \nthey mean to the business and the business analysts and decision makers may not have \nthe technical knowledge to interpret the results of sophisticated mathematical solutions, \ninteraction among them is necessary. In order",
      "title": "unit2ii"
    }
  },
  "parent_58942436b76f4403b4b3e8d843d0fe83": {
    "id": "parent_58942436b76f4403b4b3e8d843d0fe83",
    "metadata": {
      "content": "the results of sophisticated mathematical solutions, \ninteraction among them is necessary. In order to properly interpret knowledge patterns, it is \noften necessary to use a variety of tabulation and visualization techniques (e.g., pivot tables, \ncross-tabulation of findings, pie charts, histograms, box plots, scatterplots).\nstep 6: Deployment\nDevelopment and assessment of the models is not the end of the data mining project. Even if \nthe purpose of the model is to have a simple exploration of the data, the knowledge gained \nfrom such exploration will need to be organized and presented in a way that the end user \ncan understand and benefit from. Depending on the requirements, the deployment phase \ncan be as simple as generating a report or as complex as implementing a repeatable data \nmining process across the enterprise. In many cases, it is the customer, not the data analyst, \nwho carries out the deployment steps. However, even if the analyst will not carry out the \ndeployment effor",
      "title": "unit2ii"
    }
  },
  "parent_ced8f50edc354197b455fd9245f3bf75": {
    "id": "parent_ced8f50edc354197b455fd9245f3bf75",
    "metadata": {
      "content": "ries out the deployment steps. However, even if the analyst will not carry out the \ndeployment effort, it is important for the customer to understand up front what actions need \nto be carried out in order to actually make use of the created models.\nThe deployment step may also include maintenance activities for the deployed \n models. Because everything about the business is constantly changing, the data that reflect \nthe business activities also are changing. Over time, the models (and the patterns  embedded \nwithin them) built on the old data may become obsolete, irrelevant, or misleading. \nM04_SHAR4877_03_PIE_C04.indd   192 1/23/14   10:01 AM\t Chapter\t4\t \u2022\t Data\tMining 193\nTherefore,\u00a0 monitoring and maintenance of the models are important if the data mining \nresults are to become a part of the day-to-day business and its environment. A careful \n preparation of a  maintenance strategy helps to avoid unnecessarily long periods of  incorrect \nusage of data mining results. In order to mo",
      "title": "unit2ii"
    }
  },
  "parent_12e295de845b4536b761fa3ef6d49dd8": {
    "id": "parent_12e295de845b4536b761fa3ef6d49dd8",
    "metadata": {
      "content": "elps to avoid unnecessarily long periods of  incorrect \nusage of data mining results. In order to monitor the deployment of the data mining result(s), \nthe project needs a detailed plan on the monitoring process, which may not be a trivial task \nfor complex data mining\u00a0models.\nApplication Case 4.4\nData Mining in Cancer Research\nAccording to the American Cancer Society, half of \nall men and one-third of all women in the United \nStates will develop cancer during their lifetimes; \napproximately 1.5 million new cancer cases will \nbe  diagnosed in 2013. Cancer is the second most \n common cause of death in the United States and in \nthe world, exceeded only by cardiovascular disease. \nThis year, over 500,000 Americans are expected to \ndie of  cancer\u2014more than 1,300 people a day\u2014\naccounting for nearly 1 of every 4 deaths.\nCancer is a group of diseases generally char -\nacterized by uncontrolled growth and spread of \nabnormal\tcells.\tIf\tthe\tgrowth\tand/or\tspread\tare\tnot\t\ncontrolled, it can result",
      "title": "unit2ii"
    }
  },
  "parent_27fa58a39ce945e6aa3e805f39d5615c": {
    "id": "parent_27fa58a39ce945e6aa3e805f39d5615c",
    "metadata": {
      "content": "rowth and spread of \nabnormal\tcells.\tIf\tthe\tgrowth\tand/or\tspread\tare\tnot\t\ncontrolled, it can result in death. Even though the \nexact reasons are not known, cancer is believed to \nbe caused by both external factors (e.g., tobacco, \ninfectious organisms, chemicals, and radiation) and \ninternal factors (e.g., inherited mutations, hormones, \nimmune conditions, and mutations that occur from \nmetabolism). These causal factors may act together \nor in sequence to initiate or promote carcinogenesis. \nCancer is treated with surgery, radiation, chemo -\ntherapy, hormone therapy, biological therapy, and \ntargeted therapy. Survival statistics vary greatly by \ncancer type and stage at diagnosis.\nThe 5-year relative survival rate for all can -\ncers is improving, and decline in cancer mortality \nhas reached 20 percent in 2013, translating into the \navoidance of about 1.2 million deaths from cancer \nsince 1991. That\u2019s more than 400 lives saved per \nday! The improvement in survival reflects progress \nin",
      "title": "unit2ii"
    }
  },
  "parent_93af0f461560451280247623bbd056b8": {
    "id": "parent_93af0f461560451280247623bbd056b8",
    "metadata": {
      "content": "1991. That\u2019s more than 400 lives saved per \nday! The improvement in survival reflects progress \nin diagnosing certain cancers at an earlier stage and \nimprovements in treatment. Further improvements \nare needed to prevent and treat cancer.\nEven though cancer research has traditionally \nbeen clinical and biological in nature, in recent years \ndata-driven analytic studies have become a common \ncomplement. In medical domains where data- and \nanalytics-driven research have been applied suc -\ncessfully, novel research directions have been iden -\ntified to further advance the clinical and biologi -\ncal studies. Using various types of data, including \nmolecular, clinical, literature-based, and clinical-\ntrial data, along with suitable data mining tools and \ntechniques, researchers have been able to identify \nnovel patterns, paving the road toward a cancer-free \nsociety.\nIn one study, Delen (2009) used three  popular \ndata mining techniques (decision trees, artificial  neural \nnetworks, and s",
      "title": "unit2ii"
    }
  },
  "parent_36feaea44faa490f804dd6d07e07e5cf": {
    "id": "parent_36feaea44faa490f804dd6d07e07e5cf",
    "metadata": {
      "content": "09) used three  popular \ndata mining techniques (decision trees, artificial  neural \nnetworks, and support vector machines) in conjunc-\ntion with logistic regression to develop  prediction \nmodels for prostate cancer  survivability. The data set \ncontained around 120,000 records and 77\u00a0variables. \nA k-fold cross-validation  methodology was used in \nmodel building, evaluation, and  comparison. The \nresults showed that support  vector models are the \nmost accurate predictor (with a test set  accuracy \nof 92.85%) for this domain, followed by artificial \n neural networks and decision trees. Furthermore, \nusing a sensitivity\u2013analysis-based  evaluation method, \nthe study also revealed novel patterns related to \n prognostic factors of prostate cancer.\nIn a related study, Delen et al. (2004) used \ntwo data mining algorithms (artificial neural net -\nworks and decision trees) and logistic regression to \ndevelop prediction models for breast cancer survival \nusing a large data set (more than 200,0",
      "title": "unit2ii"
    }
  },
  "parent_7278b7e245804230a9df0b3b7126669f": {
    "id": "parent_7278b7e245804230a9df0b3b7126669f",
    "metadata": {
      "content": "on to \ndevelop prediction models for breast cancer survival \nusing a large data set (more than 200,000 cases). \nUsing a 10-fold cross-validation method to mea -\nsure the unbiased estimate of the prediction models \nfor performance comparison purposes, the results \nindicated that the decision tree (C5 algorithm) was \nthe best predictor, with 93.6 percent accuracy on \nthe holdout sample (which was the best prediction \naccuracy reported in the literature); followed by \n(Continued )\nM04_SHAR4877_03_PIE_C04.indd   193 1/23/14   10:01 AM194\t Chapter \t4\t \u2022\t Data\tMining\nApplication Case 4.4 (Continued)\nartificial neural networks, with 91.2 percent accu -\nracy; and logistic regression, with 89.2 percent accu-\nracy. Further analysis of prediction models revealed \n prioritized importance of the prognostic factors, \nwhich can then be used as basis for further clinical \nand biological research studies.\nThese examples (among many others in the \nmedical literature) show that advanced data min -\ning te",
      "title": "unit2ii"
    }
  },
  "parent_67a2eea6474e4fe3888b473c58de7919": {
    "id": "parent_67a2eea6474e4fe3888b473c58de7919",
    "metadata": {
      "content": ".\nThese examples (among many others in the \nmedical literature) show that advanced data min -\ning techniques can be used to develop models \nthat  possess a high degree of predictive as well as \nexplanatory power. Although data mining methods \nare capable of extracting patterns and relationships \nhidden deep in large and complex medical data -\nbases, without the cooperation and feedback from \nthe medical experts their results are not of much \nuse. The patterns found via data mining methods \nshould be evaluated by medical professionals who \nhave years of experience in the problem domain \nto decide whether they are logical, actionable, and \nnovel to warrant new research directions. In short, \ndata mining is not meant to replace medical pro -\nfessionals and researchers, but to complement \ntheir invaluable efforts to provide data-driven new \nresearch directions and to ultimately save more \nhuman lives.\nQuestions for Discussion\n 1. How can data mining be used for ultimately cur-\ning illnesse",
      "title": "unit2ii"
    }
  },
  "parent_1bc1dd0210c34fa7ba0c156f80b60696": {
    "id": "parent_1bc1dd0210c34fa7ba0c156f80b60696",
    "metadata": {
      "content": "man lives.\nQuestions for Discussion\n 1. How can data mining be used for ultimately cur-\ning illnesses like cancer?\n 2. What do you think are the promises and major \nchallenges for data miners in contributing to \nmedical and biological research endeavors?\nSources: D. Delen, \u201cAnalysis of Cancer Data: A Data Mining \nApproach,\u201d Expert Systems, Vol. 26, No. 1, 2009, pp. 100\u2013112; \nJ.\u00a0 Thongkam, G. Xu, Y. Zhang, and F. Huang, \u201cToward Breast \nCancer Survivability Prediction Models Through Improving Training \nSpace,\u201d Expert Systems with Applications, 2009, in press; D. Delen, \nG. Walker, and A. Kadam, \u201cPredicting Breast Cancer Survivability: A \nComparison of Three Data Mining Methods,\u201d Artificial Intelligence \nin Medicine, Vol. 34, No. 2, 2005, pp. 113\u2013127.\nother Data Mining standardized processes and Methodologies\nIn order to be applied successfully, a data mining study must be viewed as a process \nthat follows a standardized methodology rather than as a set of automated software tools \nand te",
      "title": "unit2ii"
    }
  },
  "parent_0df29bf3b22447d38eab68b00b703cd0": {
    "id": "parent_0df29bf3b22447d38eab68b00b703cd0",
    "metadata": {
      "content": "ss \nthat follows a standardized methodology rather than as a set of automated software tools \nand techniques. In addition to CRISP-DM, there is another well-known methodology \ndeveloped by the SAS Institute, called SEMMA (2009). The acronym semma stands for \n\u201csample, explore, modify, model, and assess.\u201d\nBeginning with a statistically representative sample of the data, SEMMA makes it \neasy to apply exploratory statistical and visualization techniques, select and transform \nthe most significant predictive variables, model the variables to predict outcomes, and \nconfirm a model\u2019s accuracy. A pictorial representation of SEMMA is given in Figure 4.6.\nBy assessing the outcome of each stage in the SEMMA process, the model devel -\noper can determine how to model new questions raised by the previous results, and \nthus proceed back to the exploration phase for additional refinement of the data; that \nis, as with CRISP-DM, SEMMA is driven by a highly iterative experimentation cycle. The \nmain dif",
      "title": "unit2ii"
    }
  },
  "parent_9636a5adc905479aae71253ef1a3deb3": {
    "id": "parent_9636a5adc905479aae71253ef1a3deb3",
    "metadata": {
      "content": "at \nis, as with CRISP-DM, SEMMA is driven by a highly iterative experimentation cycle. The \nmain difference between CRISP-DM and SEMMA is that CRISP-DM takes a more compre-\nhensive approach\u2014including understanding of the business and the relevant data\u2014to \ndata mining projects, whereas SEMMA implicitly assumes that the data mining project\u2019s \ngoals and objectives along with the appropriate data sources have been identified and \nunderstood.\nSome practitioners commonly use the term knowledge discovery in databases \n(kdd) as a synonym for data mining. Fayyad et al. (1996) defined knowledge discovery \nin databases as a process of using data mining methods to find useful information and \npatterns in the data, as opposed to data mining, which involves using algorithms to iden-\ntify patterns in data derived through the KDD process. KDD is a comprehensive process \nM04_SHAR4877_03_PIE_C04.indd   194 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 195\nthat encompasses data mining. The input to the K",
      "title": "unit2ii"
    }
  },
  "parent_8d7238cf427343b897e90cd1b3835255": {
    "id": "parent_8d7238cf427343b897e90cd1b3835255",
    "metadata": {
      "content": "4 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 195\nthat encompasses data mining. The input to the KDD process consists of organizational \ndata. The enterprise data warehouse enables KDD to be implemented efficiently because \nit provides a single source for data to be mined. Dunham (2003) summarized the KDD \nprocess as consisting of the following steps: data selection, data preprocessing, data trans-\nformation,\tdata\tmining,\tand\tinterpretation/evaluation.\tFigure\t4.7\tshows\tthe\tpolling\tresults\t\nfor the question, \u201cWhat main methodology are you using for data mining?\u201d (conducted by \nkdnuggets.com in August 2007).\nSample\n(Generate a representative\nsample of the data)\nAssess\n(Evaluate the accuracy and\nusefulness of the models)\nExplore\n(Visualization and basic\ndescription of the data)\nModel\n(Use variety of statistical and\nmachine learning models)\nModify\n(Select variables, transform\nvariable representations)\nSEMMA\nFigure 4.6 SEMMA Data Mining Process.\nCRISP-DM\nMy own\nSEMMA\nKDD Process\nMy organi",
      "title": "unit2ii"
    }
  },
  "parent_de96745c8d614bc88a0eb824b35342a2": {
    "id": "parent_de96745c8d614bc88a0eb824b35342a2",
    "metadata": {
      "content": "esentations)\nSEMMA\nFigure 4.6 SEMMA Data Mining Process.\nCRISP-DM\nMy own\nSEMMA\nKDD Process\nMy organization\u2019s\nNone\nDomain-specific\nmethodology\nOther methodology\n(not domain specific)\n01 02 03 04 05 06 07 0\nFigure 4.7 Ranking of Data Mining Methodologies/Processes. Source: Used with permission from kdnuggets.com.\nM04_SHAR4877_03_PIE_C04.indd   195 1/23/14   10:02 AM196\t Chapter \t4\t \u2022\t Data\tMining\nsectiOn 4.4 revieW Questi Ons\n 1. What are the major data mining processes?\n 2. Why do you think the early phases (understanding of the business and  understanding \nof the data) take the longest in data mining projects?\n 3. List and briefly define the phases in the CRISP-DM process.\n 4. What are the main data preprocessing steps? Briefly describe each step and provide \nrelevant examples.\n 5. How does CRISP-DM differ from SEMMA?\n4.5 Data Mining MetHoDs\nA variety of methods are available for performing data mining studies, including classi -\nfication, regression, clustering, and association. Most",
      "title": "unit2ii"
    }
  },
  "parent_cba91c5f4017478483fe6d8dbbe7ea41": {
    "id": "parent_cba91c5f4017478483fe6d8dbbe7ea41",
    "metadata": {
      "content": "ing data mining studies, including classi -\nfication, regression, clustering, and association. Most data mining software tools employ \nmore than one technique (or algorithm) for each of these methods. This section describes \nthe most popular data mining methods and explains their representative techniques.\nClassification\nClassification is perhaps the most frequently used data mining method for real-world \nproblems. As a popular member of the machine-learning family of techniques, classifica-\ntion learns patterns from past data (a set of information\u2014traits, variables, features\u2014on \ncharacteristics of the previously labeled items, objects, or events) in order to place new \ninstances (with unknown labels) into their respective groups or classes. For example, \none could use classification to predict whether the weather on a particular day will \nbe \u201csunny,\u201d \u201crainy,\u201d or \u201ccloudy.\u201d Popular classification tasks include credit approval \n(i.e.,\u00a0good or bad credit risk), store location (e.g., good,",
      "title": "unit2ii"
    }
  },
  "parent_71c0639b86894c78b2ee0be30eda739c": {
    "id": "parent_71c0639b86894c78b2ee0be30eda739c",
    "metadata": {
      "content": "fication tasks include credit approval \n(i.e.,\u00a0good or bad credit risk), store location (e.g., good, moderate, bad), target marketing \n(e.g., likely  customer, no hope), fraud detection (i.e., yes, no), and telecommunication \n(e.g.,\tlikely\tto\tturn\tto\tanother\tphone\tcompany,\tyes/no).\tIf\twhat\tis\tbeing\tpredicted\tis\ta\t\nclass label (e.g.,\u00a0\u201csunny,\u201d \u201crainy,\u201d or \u201ccloudy\u201d) the prediction problem is called a classi -\nfication, whereas if it is a numeric value (e.g., temperature such as 68\u00b0F), the prediction \nproblem is called a regression.\nEven though clustering (another popular data mining method) can also be used \nto determine groups (or class memberships) of things, there is a significant difference \nbetween the two. Classification learns the function between the characteristics of things \n(i.e., independent variables) and their membership (i.e., output variable) through a super-\nvised learning process where both types (input and output) of variables are presented to \nthe algorithm; in cluster",
      "title": "unit2ii"
    }
  },
  "parent_c534fee6714f42128e2ce41710332064": {
    "id": "parent_c534fee6714f42128e2ce41710332064",
    "metadata": {
      "content": "process where both types (input and output) of variables are presented to \nthe algorithm; in clustering, the membership of the objects is learned through an unsu -\npervised learning process where only the input variables are presented to the algorithm. \nUnlike classification, clustering does not have a supervising (or controlling) mechanism \nthat enforces the learning process; instead, clustering algorithms use one or more heuris-\ntics (e.g., multidimensional distance measure) to discover natural groupings of objects.\nThe most common two-step methodology of classification-type prediction involves \nmodel\tdevelopment/training\tand\tmodel\ttesting/deployment.\tIn\tthe\tmodel\tdevelopment\t\nphase, a collection of input data, including the actual class labels, is used. After a model \nhas been trained, the model is tested against the holdout sample for accuracy assessment \nand eventually deployed for actual use where it is to predict classes of new data instances \n(where the class label is unknown).",
      "title": "unit2ii"
    }
  },
  "parent_15650d69715140f2bcb2f4c6b0555523": {
    "id": "parent_15650d69715140f2bcb2f4c6b0555523",
    "metadata": {
      "content": "actual use where it is to predict classes of new data instances \n(where the class label is unknown). Several factors are considered in assessing the model, \nincluding the following:\n\u2022\tPredictive accuracy. The model\u2019s ability to correctly predict the class label of \nnew or previously unseen data. Prediction accuracy is the most commonly used \nassessment factor for classification models. To compute this measure, actual class \nM04_SHAR4877_03_PIE_C04.indd   196 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 197\nlabels of a test data set are matched against the class labels predicted by the model. \nThe accuracy can then be computed as the accuracy rate, which is the percent -\nage of test data set samples correctly classified by the model (more on this topic is \n provided later in the chapter).\n\u2022\tSpeed. The computational costs involved in generating and using the model, \nwhere faster is deemed to be better.\n\u2022\tRobustness. The model\u2019s ability to make reasonably accurate predictions, given \nnoi",
      "title": "unit2ii"
    }
  },
  "parent_0b290c5d1cc641bf886c1743a282e4c1": {
    "id": "parent_0b290c5d1cc641bf886c1743a282e4c1",
    "metadata": {
      "content": "to be better.\n\u2022\tRobustness. The model\u2019s ability to make reasonably accurate predictions, given \nnoisy data or data with missing and erroneous values.\n\u2022\tScalability. The ability to construct a prediction model efficiently given a rather \nlarge amount of data.\n\u2022\tInterpretability. The level of understanding and insight provided by the model \n(e.g.,\thow\tand/or\twhat\tthe\tmodel\tconcludes\ton\tcertain\tpredictions).\nestimating the true accuracy of Classification Models\nIn classification problems, the primary source for accuracy estimation is the confusion \nmatrix (also called a classification matrix or a contingency table). Figure 4.8 shows a \nconfusion matrix for a two-class classification problem. The numbers along the diagonal \nfrom the upper left to the lower right represent correct decisions, and the numbers out -\nside this diagonal represent the errors.\nTable 4.2 provides equations for common accuracy metrics for classification models.\nWhen the classification problem is not binary, the con",
      "title": "unit2ii"
    }
  },
  "parent_d331012b1d3e40528e620bc5d6e59c26": {
    "id": "parent_d331012b1d3e40528e620bc5d6e59c26",
    "metadata": {
      "content": "n accuracy metrics for classification models.\nWhen the classification problem is not binary, the confusion matrix gets bigger \n(a\u00a0square matrix with the size of the unique number of class labels), and accuracy metrics \nbecome limited to per class accuracy rates and the overall classifier accuracy.\n(True Classification Rate)i = (True Classification)i\na\nn\ni = 1\n(False Classification)i\n(Overall Classifier Accuracy)i =\na\nn\ni = 1\n(True Classification)i\nTotal Number of Cases\nEstimating the accuracy of a classification model (or classifier) induced by a super -\nvised learning algorithm is important for the following two reasons: First, it can be used \nto estimate its future prediction accuracy, which could imply the level of confidence one \nTrue\nPositive\nCount (TP)\nTrue Class\nFalse\nPositive\nCount (FP)\nPositive Negative\nFalse\nNegative\nCount (FN)\nTrue\nNegative\nCount (TN)\nPredicted Class\nNegative Positive\nFigure 4.8 A Simple Confusion Matrix for Tabulation of Two-Class Classification Results.\nM0",
      "title": "unit2ii"
    }
  },
  "parent_7f04d4ab5dea4f178a4e2830e4516c69": {
    "id": "parent_7f04d4ab5dea4f178a4e2830e4516c69",
    "metadata": {
      "content": "Positive\nFigure 4.8 A Simple Confusion Matrix for Tabulation of Two-Class Classification Results.\nM04_SHAR4877_03_PIE_C04.indd   197 1/23/14   10:02 AM198\t Chapter \t4\t \u2022\t Data\tMining\nshould have in the classifier\u2019s output in the prediction system. Second, it can be used for \nchoosing a classifier from a given set (identifying the \u201cbest\u201d classification model among \nthe many trained). The following are among the most popular estimation methodologies \nused for classification-type data mining models.\nsiMple split The simple split (or holdout or test sample estimation) partitions the \ndata into two mutually exclusive subsets called a training set and a test set (or holdout \nset). It is common to designate two-thirds of the data as the training set and the remain -\ning one-third as the test set. The training set is used by the inducer (model builder), \nand the built classifier is then tested on the test set. An exception to this rule occurs \nwhen the classifier is an artificial neural networ",
      "title": "unit2ii"
    }
  },
  "parent_46af333158044e75b5e8f7b106aa2ec0": {
    "id": "parent_46af333158044e75b5e8f7b106aa2ec0",
    "metadata": {
      "content": "n the test set. An exception to this rule occurs \nwhen the classifier is an artificial neural network. In this case, the data is partitioned \ninto three mutually exclusive subsets: training, validation, and testing. The validation set \nis used during model building to prevent overfitting. Figure 4.9 shows the simple split \nmethodology.\nThe main criticism of this method is that it makes the assumption that the data in \nthe two subsets are of the same kind (i.e., have the exact same properties). Because this \nis a simple random partitioning, in most realistic data sets where the data are skewed on \nthe classification variable, such an assumption may not hold true. In order to improve this \ntaBle 4.2 Common Accuracy Metrics for Classification Models\nMetric Description\nTrue Positive Rate = TP\nTP + FN\nThe ratio of correctly classified positives divided by the \ntotal positive count (i.e., hit rate or recall)\nTrue Negative Rate = TN\nTN + FP\nThe ratio of correctly classified negatives divided",
      "title": "unit2ii"
    }
  },
  "parent_d4ac003521074a4aaa78b5b6ef015c0a": {
    "id": "parent_d4ac003521074a4aaa78b5b6ef015c0a",
    "metadata": {
      "content": "rate or recall)\nTrue Negative Rate = TN\nTN + FP\nThe ratio of correctly classified negatives divided by the \ntotal negative count (i.e., false alarm rate)\nAccuracy = TP + TN\nTP + TN + FP + FN\nThe ratio of correctly classified instances (positives and \nnegatives) divided by the total number of instances\nPrecision = TP\nTP + FP\nThe ratio of correctly classified positives divided by \nthe sum of correctly classified positives and incorrectly \n classified positives\nRecall = TP\nTP + FN\nRatio of correctly classified positives divided by the sum \nof correctly classified positives and incorrectly classified \nnegatives\nModel\nDevelopment\nModel\nAssessment\n(scoring)\nPreprocessed\nData\nTraining\nData\nTesting\nData\nClassifier\n1/3\n2/3\nPrediction\nAccuracy\nFigure 4.9 Simple Random Data Splitting.\nM04_SHAR4877_03_PIE_C04.indd   198 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 199\nsituation, stratified sampling is suggested, where the strata become the output variable. \nEven though this is an improvement over",
      "title": "unit2ii"
    }
  },
  "parent_0cc9f9d8b071407c94bf06aa60527ea9": {
    "id": "parent_0cc9f9d8b071407c94bf06aa60527ea9",
    "metadata": {
      "content": "is suggested, where the strata become the output variable. \nEven though this is an improvement over the simple split, it still has a bias associated \nfrom the single random partitioning.\nk-FolD Cross-ValiDation In order to minimize the bias associated with the random \nsampling of the training and holdout data samples in comparing the predictive accuracy \nof two or more methods, one can use a methodology called k-fold cross-validation. In \nk-fold cross-validation, also called rotation estimation, the complete data set is randomly \nsplit into k mutually exclusive subsets of approximately equal size. The classification \nmodel is trained and tested k times. Each time it is trained on all but one fold and then \ntested on the remaining single fold. The cross-validation estimate of the overall accuracy \nof a model is calculated by simply averaging the k individual accuracy measures, as \nshown in the following equation:\nCVA = 1\nk a\nk\ni = 1\nAi\nwhere CVA stands for cross-validation accuracy, k",
      "title": "unit2ii"
    }
  },
  "parent_effff8bc9f9b4926a91b88d9211e7588": {
    "id": "parent_effff8bc9f9b4926a91b88d9211e7588",
    "metadata": {
      "content": "in the following equation:\nCVA = 1\nk a\nk\ni = 1\nAi\nwhere CVA stands for cross-validation accuracy, k is the number of folds used, and A is \nthe accuracy measure (e.g., hit-rate, sensitivity, specificity) of each fold.\naDDitional Classi FiCation assessMent Met HoDologies Other popular assess -\nment methodologies include the following:\n\u2022\tLeave-one-out. The leave-one-out method is similar to the k-fold cross-  \nvalidation where the k takes the value of 1; that is, every data point is used for \ntesting once on as many models developed as there are number of data points. \nThis is a time-consuming methodology, but sometimes for small data sets it is a \nviable option.\n\u2022\tBootstrapping. With bootstrapping, a fixed number of instances from the origi-\nnal data are sampled (with replacement) for training and the rest of the data set is \nused for testing. This process is repeated as many times as desired.\n\u2022\tJackknifing. Though similar to the leave-one-out methodology, with jackknifing \nthe accuracy",
      "title": "unit2ii"
    }
  },
  "parent_132768fa770842128b0ac35696cde3d3": {
    "id": "parent_132768fa770842128b0ac35696cde3d3",
    "metadata": {
      "content": "red.\n\u2022\tJackknifing. Though similar to the leave-one-out methodology, with jackknifing \nthe accuracy is calculated by leaving one sample out at each iteration of the estima-\ntion process.\n\u2022\tArea under the ROC curve.  The area under the rOc curve is a graphical \nassessment technique where the true positive rate is plotted on the y-axis and false \npositive rate is plotted on the x-axis. The area under the ROC curve determines the \naccuracy measure of a classifier: A value of 1 indicates a perfect classifier whereas \n0.5 indicates no better than random chance; in reality, the values would range \nbetween the two extreme cases. For example, in Figure 4.10 A has a better clas -\nsification performance than B, while C is not any better than the random chance of \nflipping a coin.\nClassiFiCation teCHniques A number of techniques (or algorithms) are used for clas-\nsification modeling, including the following:\n\u2022\tDecision tree analysis.  Decision tree analysis (a machine-learning technique) \nis argu",
      "title": "unit2ii"
    }
  },
  "parent_e3dd3045e1f34e55ac9858085023f8ac": {
    "id": "parent_e3dd3045e1f34e55ac9858085023f8ac",
    "metadata": {
      "content": "following:\n\u2022\tDecision tree analysis.  Decision tree analysis (a machine-learning technique) \nis arguably the most popular classification technique in the data mining arena. A \ndetailed description of this technique is given in the following section.\n\u2022\tStatistical analysis.  Statistical techniques were the primary classification \nalgorithm for many years until the emergence of machine-learning techniques. \nM04_SHAR4877_03_PIE_C04.indd   199 1/23/14   10:02 AM200\t Chapter \t4\t \u2022\t Data\tMining\nStatistical classification techniques include logistic regression and discriminant \nanalysis, both of which make the assumptions that the relationships between the \ninput and output variables are linear in nature, the data is normally distributed, \nand the variables are not correlated and are independent of each other. The ques -\ntionable nature of these assumptions has led to the shift toward machine-learning \ntechniques.\n\u2022\tNeural networks.  These are among the most popular machine-learning \n techniq",
      "title": "unit2ii"
    }
  },
  "parent_f551400142e44b019c28940e8f9aff4a": {
    "id": "parent_f551400142e44b019c28940e8f9aff4a",
    "metadata": {
      "content": "earning \ntechniques.\n\u2022\tNeural networks.  These are among the most popular machine-learning \n techniques that can be used for classification-type problems. \n\u2022\tCase-based reasoning. This approach uses historical cases to recognize com -\nmonalities in order to assign a new case into the most probable category.\n\u2022\tBayesian classifiers.  This approach uses probability theory to build classifi -\ncation models based on the past occurrences that are capable of placing a new \ninstance into a most probable class (or category).\n\u2022\tGenetic algorithms.  The use of the analogy of natural evolution to build \ndirected-search-based mechanisms to classify data samples.\n\u2022\tRough sets. This method takes into account the partial membership of class labels \nto predefined categories in building models (collection of rules) for  classification \nproblems.\nA complete description of all of these classification techniques is beyond the scope of this \nbook; thus, only several of the most popular ones are presented he",
      "title": "unit2ii"
    }
  },
  "parent_f08d74faf69049d0a82c4fbfebc221ad": {
    "id": "parent_f08d74faf69049d0a82c4fbfebc221ad",
    "metadata": {
      "content": "ques is beyond the scope of this \nbook; thus, only several of the most popular ones are presented here.\nDeCision trees Before describing the details of decision trees, we need to  discuss \nsome simple terminology. First, decision trees include many input variables that may \n1\nTrue Positive Rate (Sensitivity)\nFalse Positive Rate (1-Specificity)\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n0 0.1 0.2\nA\nB\nC\n0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\nFigure 4.10 A Sample ROC Curve.\nM04_SHAR4877_03_PIE_C04.indd   200 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 201\nhave an impact on the classification of different patterns. These input variables are \n usually called attributes. For example, if we were to build a model to classify loan risks \non the basis of just two characteristics\u2014income and a credit rating\u2014these two char -\nacteristics would be the attributes and the resulting output would be the class label   \n(e.g., low, medium, or high risk). Second, a tree consists of branches and nodes. A\u00a0branch \nreprese",
      "title": "unit2ii"
    }
  },
  "parent_dc2a01387e1f4509ada27edfaa844e3d": {
    "id": "parent_dc2a01387e1f4509ada27edfaa844e3d",
    "metadata": {
      "content": "(e.g., low, medium, or high risk). Second, a tree consists of branches and nodes. A\u00a0branch \nrepresents the outcome of a test to classify a pattern (on the basis of a test) using one \nof the attributes. A leaf node at the end represents the final class choice for a pattern (a \nchain of branches from the root node to the leaf node, which can be represented as a \ncomplex if-then statement).\nThe basic idea behind a decision tree is that it recursively divides a training set \nuntil each division consists entirely or primarily of examples from one class. Each non -\nleaf node of the tree contains a split point, which is a test on one or more attributes and \ndetermines how the data are to be divided further. Decision tree algorithms, in general, \nbuild an initial tree from the training data such that each leaf node is pure, and they \nthen prune the tree to increase its generalization, and hence, the prediction accuracy \non test data.\nIn the growth phase, the tree is built by recursively divid",
      "title": "unit2ii"
    }
  },
  "parent_fe89adc630ae4266ac68789671881c2d": {
    "id": "parent_fe89adc630ae4266ac68789671881c2d",
    "metadata": {
      "content": ", the prediction accuracy \non test data.\nIn the growth phase, the tree is built by recursively dividing the data until each divi-\nsion is either pure (i.e., contains members of the same class) or relatively small. The basic \nidea is to ask questions whose answers would provide the most information, similar to \nwhat we may do when playing the game \u201cTwenty Questions.\u201d\nThe split used to partition the data depends on the type of the attribute used in the \nsplit. For a continuous attribute A, splits are of the form value(A) 6 x, where x is some \n\u201coptimal\u201d split value of A. For example, the split based on income could be \u201cIncome  \n<\u00a050000.\u201d For the categorical attribute A, splits are of the form value(A) belongs to x, \nwhere x is a subset of A. As an example, the split could be on the basis of gender: \u201cMale \nversus Female.\u201d\nA general algorithm for building a decision tree is as follows:\n 1. Create a root node and assign all of the training data to it.\n 2. Select the best splitting attribute.",
      "title": "unit2ii"
    }
  },
  "parent_34d46ccf94b84592b78e59f2eb11bdde": {
    "id": "parent_34d46ccf94b84592b78e59f2eb11bdde",
    "metadata": {
      "content": "eate a root node and assign all of the training data to it.\n 2. Select the best splitting attribute.\n 3. Add a branch to the root node for each value of the split. Split the data into mutu -\nally exclusive (nonoverlapping) subsets along the lines of the specific split and \nmode to the branches.\n 4. Repeat steps 2 and 3 for each and every leaf node until the stopping criteria is \nreached (e.g., the node is dominated by a single class label).\nMany different algorithms have been proposed for creating decision trees. These \nalgorithms differ primarily in terms of the way in which they determine the splitting \nattribute (and its split values), the order of splitting the attributes (splitting the same \nattribute only once or many times), the number of splits at each node (binary versus \nternary), the stopping criteria, and the pruning of the tree (pre- versus postpruning). \nSome of the most well-known algorithms are ID3 (followed by C4.5 and C5 as the \nimproved versions of ID3) from machine",
      "title": "unit2ii"
    }
  },
  "parent_183ce7f56c9c41429ec7330dee8cff4c": {
    "id": "parent_183ce7f56c9c41429ec7330dee8cff4c",
    "metadata": {
      "content": "ll-known algorithms are ID3 (followed by C4.5 and C5 as the \nimproved versions of ID3) from machine learning, classification and regression trees \n(CART) from statistics, and the chi-squared automatic interaction detector (CHAID) from \npattern recognition.\nWhen building a decision tree, the goal at each node is to determine the attribute \nand the split point of that attribute that best divides the training records in order to purify \nthe class representation at that node. To evaluate the goodness of the split, some split -\nting indices have been proposed. Two of the most common ones are the Gini index and \ninformation gain. The Gini index is used in CART and SPRINT (Scalable PaRallelizable \nInduction of Decision Trees) algorithms. Versions of information gain are used in ID3 \n(and its newer versions, C4.5 and C5).\nM04_SHAR4877_03_PIE_C04.indd   201 1/23/14   10:02 AM202\t Chapter \t4\t \u2022\t Data\tMining\nThe gini index has been used in economics to measure the diversity of a popula-\ntion. The",
      "title": "unit2ii"
    }
  },
  "parent_8374b8b220724b1386025137c499f3cf": {
    "id": "parent_8374b8b220724b1386025137c499f3cf",
    "metadata": {
      "content": "ata\tMining\nThe gini index has been used in economics to measure the diversity of a popula-\ntion. The same concept can be used to determine the purity of a specific class as a result \nof a decision to branch along a particular attribute or variable. The best split is the one \nthat increases the purity of the sets resulting from a proposed split. Let us briefly look into \na simple calculation of Gini index:\nIf a data set S contains examples from n classes, the Gini index is defined as\ngini(S) = 1 - a\nn\nj = 1\npj\n2\nwhere pj is a relative frequency of class j in S. If a data set S is split into two subsets, \nS1 and S2, with sizes N1 and N2, respectively, the Gini index of the split data contains \nexamples from n classes, and the Gini index is defined as\nginisplit (S) = N1\nN  gini (S1) + N2\nN  gini(S2)\nThe\tattribute/split\tcombination\tthat\tprovides\tthe\tsmallest\tginisplit(S) is chosen to split \nthe\u00a0node. In such a determination, one should enumerate all possible splitting points for \neach attr",
      "title": "unit2ii"
    }
  },
  "parent_385632eda9a04b18802cd89fd59818fa": {
    "id": "parent_385632eda9a04b18802cd89fd59818fa",
    "metadata": {
      "content": "the\u00a0node. In such a determination, one should enumerate all possible splitting points for \neach attribute.\ninformation gain is the splitting mechanism used in ID3, which is perhaps the \nmost widely known decision tree algorithm. It was developed by Ross Quinlan in 1986, \nand since then he has evolved this algorithm into the C4.5 and C5 algorithms. The basic \nidea behind ID3 (and its variants) is to use a concept called entropy in place of the Gini \nindex. entropy measures the extent of uncertainty or randomness in a data set. If all the \ndata in a subset belong to just one class, there is no uncertainty or randomness in that \ndata set; so, the entropy is zero. The objective of this approach is to build subtrees so that \nthe entropy of each final subset is zero (or close to zero). Let us also look at the calcula-\ntion of the information gain.\nAssume that there are two classes, P (positive) and N (negative). Let the set of \nexamples S contain p counts of class P and n counts of class N.",
      "title": "unit2ii"
    }
  },
  "parent_471a5338e9d04c5f8ca6f584b01c6800": {
    "id": "parent_471a5338e9d04c5f8ca6f584b01c6800",
    "metadata": {
      "content": ") and N (negative). Let the set of \nexamples S contain p counts of class P and n counts of class N. The amount of informa-\ntion needed to decide if an arbitrary example in S belongs to P or N is defined as\nI (p, n) = - p\np + n log2 p\np + n - n\np + n log2 n\np + n\nAssume that using attribute A, the set S will be partitioned into sets { S1, S2,..., Sv}. If Si \n contains pi examples of P and ni examples of N, the entropy, or the expected information \nneeded to classify objects in all subtrees, Si, is\nE(A) = a\nn\ni = 1\n pi + ni\np + n  I(pi, ni)\nThen, the information that would be gained by branching on attribute A would be\nGain(A) = I(p, n) - E(A)\nThese calculations are repeated for each and every attribute, and the one with the \n highest information gain is selected as the splitting attribute. The basic ideas behind \nthese  splitting indices are rather similar to each other, but the specific algorithmic details \nvary. A detailed definition of ID3 algorithm and its splitting mechanism can be",
      "title": "unit2ii"
    }
  },
  "parent_f9f03b7de491466aa6e83a4e5cd56145": {
    "id": "parent_f9f03b7de491466aa6e83a4e5cd56145",
    "metadata": {
      "content": "algorithmic details \nvary. A detailed definition of ID3 algorithm and its splitting mechanism can be found in \nQuinlan (1986).\nApplication Case 4.5 illustrates how significant the gains may be if the right data \nmining techniques are used for a well-defined business problem.\nM04_SHAR4877_03_PIE_C04.indd   202 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 203\nApplication Case 4.5\n2degrees Gets a 1275 Percent Boost in Churn Identification\n2degrees is New Zealand\u2019s fastest growing mobile \ntelecommunications company. In less than 3 years, \nthey have transformed the landscape of New \nZealand\u2019s mobile telecommunications market. \nEntering very much as the challenger and battling \nwith incumbents entrenched in the market for over \n18 years, 2degrees has won over 580,000 customers \nand has revenues of more than $100 million in just \ntheir third year of operation. Last year\u2019s growth was \n3761 percent.\nsituation\n2degrees\u2019 information solutions manager, Peter \nMcCallum, explains that predictive an",
      "title": "unit2ii"
    }
  },
  "parent_e408ecf95b0642a19bef10cf34f7d184": {
    "id": "parent_e408ecf95b0642a19bef10cf34f7d184",
    "metadata": {
      "content": "ent.\nsituation\n2degrees\u2019 information solutions manager, Peter \nMcCallum, explains that predictive analytics had \nbeen on the radar at the company for some time. \u201cAt \n2degrees there are a lot of analytically aware peo -\nple, from the CEO down. Once we got to the point \nin our business that we were interested in deploy -\ning advanced predictive analytics techniques, we \nstarted to look at what was available in the market -\nplace.\u201d It soon became clear that although on paper \nthere were several options, the reality was that the \ncost of deploying the well-known solutions made it \nvery difficult to build a business case, particularly \ngiven that the benefits to the business were as yet \nunproven.\nAfter careful evaluation, 2degrees decided \nupon a suite of analytics solutions from 11Ants con-\nsisting of Customer Response Analyzer, Customer \nChurn Analyzer, and Model Builder. \u201cOne of \nthe beauties of the 11Ants Analytics solution was \nthat it allowed us to get up and running quickly \nand ver",
      "title": "unit2ii"
    }
  },
  "parent_86dbe8f58c474f2ab13c20933d6b6289": {
    "id": "parent_86dbe8f58c474f2ab13c20933d6b6289",
    "metadata": {
      "content": "ties of the 11Ants Analytics solution was \nthat it allowed us to get up and running quickly \nand very economically. We could test the water \nand  determine what the ROI was likely to be for \n predictive analytics, making it a lot easier to build \na business case for future analytics projects,\u201d Peter \nMcCallum said.\nWhen asked why they chose 11Ants Analytics\u2019 \nsolutions, Peter said, \u201cOne of the beauties of the \n11Ants Analytics solution was that it allowed us to \nget up and running quickly and very economically. \nWe could test the water and determine what the ROI \nwas likely to be for predictive analytics, making it a \nlot easier to build a business case for future analyt -\nics projects. Yet we didn\u2019t really have to sacrifice \nanything in terms of functionality\u2014in fact, the churn \nmodels we\u2019ve built have performed exceptionally \nwell.\u201d\n11Ants analytics director of Business Dev -\nelopment, Tom Fuyala, comments: \u201cWe are dedi -\ncated to getting organizations up and running with \npredictive",
      "title": "unit2ii"
    }
  },
  "parent_3ce3c548bd5640fbbf8f33f3b7f65d5d": {
    "id": "parent_3ce3c548bd5640fbbf8f33f3b7f65d5d",
    "metadata": {
      "content": "Tom Fuyala, comments: \u201cWe are dedi -\ncated to getting organizations up and running with \npredictive analytics faster, without compromising \nthe quality of the results. With other solutions you \nmust [use] trial and error through multiple algo -\nrithms manually, but with 11Ants Analytics solu -\ntions, the entire optimization and management of \nthe algorithms is automated, allowing thousands \nto be  trialed in a few minutes. The benefits of this \napproach are evidenced in the real-world results.\u201d\nPeter is also impressed by the ease of use. \n\u201cThe simplicity was a big deal to us. Not having to \nhave the statistical knowledge in-house was defi -\nnitely a selling point. Company culture was also a \nbig factor in our decision making. 11Ants Analytics \nfelt like a good fit. They\u2019ve been very responsive \nand have been great to work with. The turnaround \non some of the custom requests we have made has \nbeen fantastic.\u201d\nPeter also likes the fact that models can be \nbuilt with the desktop modeling",
      "title": "unit2ii"
    }
  },
  "parent_7675f8014f614caa8c8999fa1cc80cff": {
    "id": "parent_7675f8014f614caa8c8999fa1cc80cff",
    "metadata": {
      "content": "has \nbeen fantastic.\u201d\nPeter also likes the fact that models can be \nbuilt with the desktop modeling tools and then \ndeployed against the enterprise customer database \nwith 11Ants Predictor. \u201cOnce the model has been \nbuilt, it is easy to deploy it in 11Ants Predictor to \nrun against Oracle and score our entire customer \nbase very quickly. The speed with which 11Ants \nPredictor can re-score hundreds of thousands of \ncustomers is fantastic. We presently re-score our \ncustomer base monthly, but it is so easy that we \ncould be re- scoring daily if we wanted.\u201d\nbenefits\n2degrees put 11Ants Analytics solutions to work \nquickly with very satisfying results. The initial proj -\nect was to focus on an all-too-common problem in \nthe mobile telecommunications industry: customer \nchurn (customers leaving). For this they deployed \n11Ants Customer Churn Analyzer. 2degrees was \ninterested in identifying customers most at risk of \nchurning by analyzing data such as time on net -\nwork, days since last to",
      "title": "unit2ii"
    }
  },
  "parent_8c87eadb66b047e28cd82981784597ab": {
    "id": "parent_8c87eadb66b047e28cd82981784597ab",
    "metadata": {
      "content": "customers most at risk of \nchurning by analyzing data such as time on net -\nwork, days since last top-up, activation\u00a0 channel, \n(Continued )\nM04_SHAR4877_03_PIE_C04.indd   203 1/23/14   10:02 AM204\t Chapter \t4\t \u2022\t Data\tMining\nApplication Case 4.5 (Continued)\nwhether the customer ported their number or not, \ncustomer plan, and outbound calling behaviors over \nthe preceding 90 days.\nA carefully controlled experiment was run over \na period of 3 months, and the results were tabulated \nand analyzed. The results were excellent: Customers \nidentified as churners by 11Ants Customer Churn \nAnalyzer were a game-changing 1275 percent more \nlikely to be churners than customers chosen at ran -\ndom. This can also be expressed as an increase in \nlift of 12.75 at 5 percent (the 5% of the total popula-\ntion identified as most likely to churn by the model). \nAt 10 percent, lift was 7.28. Other benefits included \nthe various insights that 11Ants Customer Churn \nAnalyzer provided, for instance, validating",
      "title": "unit2ii"
    }
  },
  "parent_b17a3be010f041eeb239634c316f511e": {
    "id": "parent_b17a3be010f041eeb239634c316f511e",
    "metadata": {
      "content": "cluded \nthe various insights that 11Ants Customer Churn \nAnalyzer provided, for instance, validating things \nthat staff had intuitively felt, such as time on net -\nwork\u2019s strong relationship with churn, and highlight-\ning areas where product enhancement would be \nbeneficial.\nArmed with the information of which custom -\ners were most at risk of defecting, 2degrees could \nnow focus retention efforts on those identified as \nmost at risk, thereby getting substantially higher \nreturn on investment on retention marketing expen-\nditure. The bottom line is significantly better results \nfor fewer dollars spent.\n2degrees head of customers, Matt Hobbs, pro-\nvides a perspective on why this is not just impor -\ntant to 2degrees but also to their customers: \u201cChurn \nprediction is a valuable tool for customer market -\ning and we are excited about the capabilities 11Ants \nAnalytics provides to identify customers who display \nindications of churning behavior. This is beneficial \nto both 2degrees and to o",
      "title": "unit2ii"
    }
  },
  "parent_7afb53c6f7d048438c531301f79fdff7": {
    "id": "parent_7afb53c6f7d048438c531301f79fdff7",
    "metadata": {
      "content": "stomers who display \nindications of churning behavior. This is beneficial \nto both 2degrees and to our customers.\u201d\n\u2022\tTo\t customers\t go\t the\t benefits\t of\t identifi-\ncation (if you are not likely to churn, you \nare not being constantly annoyed by mes -\nsages asking you to stay) and appropriate -\nness (  customers receive offers that actually \nare appropriate to their usage\u2014minutes for \nsomeone who likes to talk, texts for someone \nwho likes to text, etc.).\n\u2022\tTo\t 2degrees\t go\t the\t benefits\t of\t targeting\t (by\t\nidentifying a smaller group of at-risk custom -\ners,\u00a0retention offers can be richer because of \nthe\u00a0reduction in the number of people who may \nreceive it but not need it); and appro priateness.\nBy aligning these benefits for both 2degrees and the \ncustomer, the outcomes 2degrees are experiencing \nare vastly improved.\nQuestions for Discussion\n 1. What does 2degrees do? Why is it important for \n2degrees to accurately identify churn?\n 2. What were the challenges, the proposed solu -",
      "title": "unit2ii"
    }
  },
  "parent_8a2de6b993c7402db32b34f127b09cba": {
    "id": "parent_8a2de6b993c7402db32b34f127b09cba",
    "metadata": {
      "content": "rtant for \n2degrees to accurately identify churn?\n 2. What were the challenges, the proposed solu -\ntion, and the obtained results?\n 3. How can data mining help in identifying cus -\ntomer churn? How do some companies do it \nwithout using data mining tools and techniques?\nSource: 11antsanalytics.com/casestudies/2degrees_casestudy.\naspx (accessed January 2013).\nCluster analysis for Data Mining\nCluster analysis is an essential data mining method for classifying items, events, or con -\ncepts into common groupings called clusters. The method is commonly used in biol -\nogy, medicine, genetics, social network analysis, anthropology, archaeology, astronomy, \ncharacter recognition, and even in MIS development. As data mining has increased in \npopularity, the underlying techniques have been applied to business, especially to mar -\nketing. Cluster analysis has been used extensively for fraud detection (both credit card \nand e-commerce fraud) and market segmentation of customers in contemporary CR",
      "title": "unit2ii"
    }
  },
  "parent_ebbdffda385e4b38a1909b5b4d986bf0": {
    "id": "parent_ebbdffda385e4b38a1909b5b4d986bf0",
    "metadata": {
      "content": "ion (both credit card \nand e-commerce fraud) and market segmentation of customers in contemporary CRM \nsystems. More applications in business continue to be developed as the strength of cluster \nanalysis is recognized and used.\nCluster analysis is an exploratory data analysis tool for solving classification problems. \nThe objective is to sort cases (e.g., people, things, events) into groups, or clusters, so that \nthe degree of association is strong among members of the same cluster and weak among \nM04_SHAR4877_03_PIE_C04.indd   204 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 205\nmembers of different clusters. Each cluster describes the class to which its members belong. \nAn obvious one-dimensional example of cluster analysis is to establish score ranges into \nwhich to assign class grades for a college class. This is similar to the cluster analysis problem \nthat the U.S. Treasury faced when establishing new tax brackets in the 1980s. A fictional \nexample of clustering occurs in J. K.",
      "title": "unit2ii"
    }
  },
  "parent_f5b6e93ebb2147c188dfefbc3e40c93a": {
    "id": "parent_f5b6e93ebb2147c188dfefbc3e40c93a",
    "metadata": {
      "content": "when establishing new tax brackets in the 1980s. A fictional \nexample of clustering occurs in J. K. Rowling\u2019s Harry Potter books. The Sorting Hat deter-\nmines to which House (e.g., dormitory) to assign first-year students at the Hogwarts School. \nAnother example involves determining how to seat guests at a wedding. As far as data min-\ning goes, the importance of cluster analysis is that it may reveal associations and structures \nin data that were not previously apparent but are sensible and useful once found.\nCluster analysis results may be used to:\n\u2022\tIdentify\ta\tclassification\tscheme\t(e.g.,\ttypes\tof\tcustomers)\n\u2022\tSuggest\tstatistical\tmodels\tto\tdescribe\tpopulations\n\u2022\tIndicate\trules\tfor\tassigning\tnew\tcases\tto\tclasses\tfor\tidentification,\ttargeting,\tand\t\ndiagnostic purposes\n\u2022\tProvide\tmeasures\tof\tdefinition,\tsize,\tand\tchange\tin\twhat\twere\tpreviously\tbroad\t\nconcepts\n\u2022\tFind\ttypical\tcases\tto\tlabel\tand\trepresent\tclasses\n\u2022\tDecrease\t the\t size\t and\t complexity\t of\t the\t problem\t space\t for\t other\t d",
      "title": "unit2ii"
    }
  },
  "parent_36f558b6002e4a4b8967a3a0187b7b7b": {
    "id": "parent_36f558b6002e4a4b8967a3a0187b7b7b",
    "metadata": {
      "content": "and\trepresent\tclasses\n\u2022\tDecrease\t the\t size\t and\t complexity\t of\t the\t problem\t space\t for\t other\t data\t mining\t\nmethods\n\u2022\tIdentify\toutliers\tin\ta\tspecific\tdomain\t(e.g.,\trare-event\tdetection)\nDeterMining t He optiMal nuMBer o F Clusters  Clustering algorithms usually \nrequire one to specify the number of clusters to find. If this number is not known \nfrom prior knowledge, it should be chosen in some way. Unfortunately, there is not an \n optimal way of calculating what this number is supposed to be. Therefore, several dif -\nferent heuristic methods have been proposed. The following are among the most com -\nmonly referenced ones:\n\u2022\tLook\tat\tthe\tpercentage\tof\tvariance\texplained\tas\ta\tfunction\tof\tthe\tnumber\tof\tclus-\nters; that is, choose a number of clusters so that adding another cluster would not \ngive much better modeling of the data. Specifically, if one graphs the percentage of \nvariance explained by the clusters, there is a point at which the marginal gain will \ndrop (giving an angle in",
      "title": "unit2ii"
    }
  },
  "parent_2d5fa0166aa845bca25195da6b36c136": {
    "id": "parent_2d5fa0166aa845bca25195da6b36c136",
    "metadata": {
      "content": "xplained by the clusters, there is a point at which the marginal gain will \ndrop (giving an angle in the graph), indicating the number of clusters to be chosen.\n\u2022\tSet\tthe\tnumber\tof\tclusters\tto\t(n/2)1/2, where n is the number of data points.\n\u2022\tUse\tthe\tAkaike\tInformation\tCriterion\t(AIC),\twhich\tis\ta\tmeasure\tof\tthe\tgoodness\tof\t\nfit (based on the concept of entropy) to determine the number of clusters.\n\u2022\tUse\t Bayesian\t information\t criterion\t (BIC),\t which\t is\t a\t model-selection\t criterion\t\n(based on maximum likelihood estimation) to determine the number of clusters.\nanalysis MetHoDs Cluster analysis may be based on one or more of the following \ngeneral methods:\n\u2022\tStatistical\t methods\t (including\t both\t hierarchical\t and\t nonhierarchical),\t such\t as\t\nk-means, k-modes, and so on\n\u2022\tNeural\tnetworks\t(with\tthe\tarchitecture\tcalled\tself-organizing\tmap,\tor\tSOM)\n\u2022\tFuzzy\tlogic\t(e.g.,\tfuzzy\tc-means algorithm)\n\u2022\tGenetic\talgorithms\nEach of these methods generally works with one of two general method cl",
      "title": "unit2ii"
    }
  },
  "parent_2cdbc7fa7b6d4cac9e3ac1a4f7b91e2b": {
    "id": "parent_2cdbc7fa7b6d4cac9e3ac1a4f7b91e2b",
    "metadata": {
      "content": "orithm)\n\u2022\tGenetic\talgorithms\nEach of these methods generally works with one of two general method classes:\n\u2022\tDivisive. With divisive classes, all items start in one cluster and are broken apart.\n\u2022\tAgglomerative. With agglomerative classes, all items start in individual clusters, \nand the clusters are joined together.\nM04_SHAR4877_03_PIE_C04.indd   205 1/23/14   10:02 AM206\t Chapter \t4\t \u2022\t Data\tMining\nMost cluster analysis methods involve the use of a distance measure to calculate the \ncloseness between pairs of items. Popular distance measures include Euclidian distance (the \nordinary distance between two points that one would measure with a ruler) and Manhattan \ndistance (also called the rectilinear distance, or taxicab distance, between two points). Often, \nthey are based on true distances that are measured, but this need not be so, as is typically \nthe case in IS development. Weighted averages may be used to establish these distances. \nFor example, in an IS development project, indi",
      "title": "unit2ii"
    }
  },
  "parent_f28f1cc9283745048f17c8b9c228a263": {
    "id": "parent_f28f1cc9283745048f17c8b9c228a263",
    "metadata": {
      "content": "averages may be used to establish these distances. \nFor example, in an IS development project, individual modules of the system may be related \nby the similarity between their inputs, outputs, processes, and the specific data used. These \nfactors are then aggregated, pairwise by item, into a single distance measure.\nk-Means Clustering algoritHM The k-means algorithm (where k stands for the prede-\ntermined number of clusters) is arguably the most referenced clustering algorithm. It has its \nroots in traditional statistical analysis. As the name implies, the algorithm assigns each data \npoint (customer, event, object, etc.) to the cluster whose center (also called centroid) is the \nnearest. The center is calculated as the average of all the points in the cluster; that is, its \ncoordinates are the arithmetic mean for each dimension separately over all the points in the \ncluster. The algorithm steps are listed below and shown graphically in Figure 4.11:\nInitialization step: Choose the num",
      "title": "unit2ii"
    }
  },
  "parent_90357d6728f34cb896c9160fa785a18a": {
    "id": "parent_90357d6728f34cb896c9160fa785a18a",
    "metadata": {
      "content": "thm steps are listed below and shown graphically in Figure 4.11:\nInitialization step: Choose the number of clusters (i.e., the value of k).\nstep 1: Randomly generate k random points as initial cluster centers.\nstep 2: Assign each point to the nearest cluster center.\nstep 3: Recompute the new cluster centers.\nRepetition step: Repeat steps 2 and 3 until some convergence criterion is met \n(usually that the assignment of points to clusters becomes stable).\nassociation rule Mining\nAssociation rule mining (also known as affinity analysis or market-basket analysis) is a popu-\nlar data mining method that is commonly used as an example to explain what data mining is \nand what it can do to a technologically less savvy audience. Most of you might have heard \nthe famous (or infamous, depending on how you look at it) relationship discovered between \nthe sales of beer and diapers at grocery stores. As the story goes, a large supermarket chain \n(maybe Walmart, maybe not; there is no consensus on whic",
      "title": "unit2ii"
    }
  },
  "parent_39265887820045cc81df3df337bc0df7": {
    "id": "parent_39265887820045cc81df3df337bc0df7",
    "metadata": {
      "content": "the story goes, a large supermarket chain \n(maybe Walmart, maybe not; there is no consensus on which supermarket chain it was) did \nan analysis of customers\u2019 buying habits and found a statistically significant correlation between \npurchases of beer and purchases of diapers. It was theorized that the reason for this was that \nfathers (presumably young men) were stopping off at the supermarket to buy diapers for their \nbabies (especially on Thursdays), and since they could no longer go down to the sports bar \nas often, would buy beer as well. As a result of this finding, the supermarket chain is alleged \nto have placed the diapers next to the beer, resulting in increased sales of both.\nStep 2Step 1 Step 3\nFigure 4.11 A Graphical Illustration of the Steps in k-Means Algorithm.\nM04_SHAR4877_03_PIE_C04.indd   206 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 207\nIn essence, association rule mining aims to find interesting relationships (affinities) \nbetween variables (items) in large datab",
      "title": "unit2ii"
    }
  },
  "parent_8757d77a5139463c864df2baab424c82": {
    "id": "parent_8757d77a5139463c864df2baab424c82",
    "metadata": {
      "content": "mining aims to find interesting relationships (affinities) \nbetween variables (items) in large databases. Because of its successful application to \nretail business problems, it is commonly called market-basket analysis. The main idea \nin market-basket analysis is to identify strong relationships among different products \n(or services) that are usually purchased together (show up in the same basket together, \neither a physical basket at a grocery store or a virtual basket at an e-commerce Web \nsite). For example, 65 percent of those who buy comprehensive automobile insurance \nalso buy health insurance; 80 percent of those who buy books online also buy music \nonline; 60\u00a0percent of those who have high blood pressure and are overweight have high \ncholesterol; 70 percent of the customers who buy lap-top computer and virus protection \nsoftware also buy extended service plans.\nThe input to market-basket analysis is the simple point-of-sale transaction data, \nwhere\ta\tnumber\tof\tproducts\tand/or",
      "title": "unit2ii"
    }
  },
  "parent_8f2ebe6500fb4ba7a87cf699ec899759": {
    "id": "parent_8f2ebe6500fb4ba7a87cf699ec899759",
    "metadata": {
      "content": "et-basket analysis is the simple point-of-sale transaction data, \nwhere\ta\tnumber\tof\tproducts\tand/or\tservices\tpurchased\ttogether\t(just\tlike\tthe\tcontent\t\nof a purchase receipt) are tabulated under a single transaction instance. The outcome of \nthe analysis is invaluable information that can be used to better understand customer-\npurchase behavior in order to maximize the profit from business transactions. A business \ncan take advantage of such knowledge by (1) putting the items next to each other to \nmake it more convenient for the customers to pick them up together and not forget to \nbuy one when buying the others (increasing sales volume); (2) promoting the items as a \npackage (do not put one on sale if the other(s) are on sale); and (3) placing them apart \nfrom each other so that the customer has to walk the aisles to search for it, and by doing \nso potentially seeing and buying other items.\nApplications of market-basket analysis include cross-marketing, cross-selling, store \ndesign,",
      "title": "unit2ii"
    }
  },
  "parent_517a36047a3d4ae49f8f5534e66aa5a6": {
    "id": "parent_517a36047a3d4ae49f8f5534e66aa5a6",
    "metadata": {
      "content": "tems.\nApplications of market-basket analysis include cross-marketing, cross-selling, store \ndesign, catalog design, e-commerce site design, optimization of online advertising, product \npricing,\tand\tsales/promotion\tconfiguration.\tIn\tessence,\tmarket-basket\tanalysis\thelps\tbusi-\nnesses infer customer needs and preferences from their purchase patterns. Outside the \nbusiness realm, association rules are successfully used to discover relationships between \nsymptoms and illnesses, diagnosis and patient characteristics and treatments (which can be \nused in medical DSS), and genes and their functions (which can be used in genomics proj-\nects), among others. Here are a few common areas and uses for association rule mining:\n\u2022\tSales transaction: Combinations of retail products purchased together can be \nused to improve product placement on the sales floor (placing products that go \ntogether in close proximity) and promotional pricing of products (not having pro -\nmotions on both products that are o",
      "title": "unit2ii"
    }
  },
  "parent_aaf73152b70a422aa46a7f36f06b2c66": {
    "id": "parent_aaf73152b70a422aa46a7f36f06b2c66",
    "metadata": {
      "content": "proximity) and promotional pricing of products (not having pro -\nmotions on both products that are often purchased together).\n\u2022\tCredit card transactions:  Items purchased with a credit card provide insight \ninto other products the customer is likely to purchase or fraudulent use of credit \ncard numbers.\n\u2022\tBanking services: The sequential patterns of services used by customers (check-\ning account followed by saving account) can be used to identify other services they \nmay be interested in (investment account).\n\u2022\tInsurance service products: Bundles of insurance products bought by custom-\ners (car insurance followed by a home insurance) can be used to propose additional \ninsurance products (life insurance); or, unusual combinations of insurance claims \ncan be a sign of fraud.\n\u2022\tTelecommunication services:  Commonly purchased groups of options (e.g., \ncall waiting, caller ID, three-way calling, etc.) help better structure product bundles \nto maximize revenue; the same is also applicable to",
      "title": "unit2ii"
    }
  },
  "parent_72d6d7cd88234431abf9d8e1f876eab5": {
    "id": "parent_72d6d7cd88234431abf9d8e1f876eab5",
    "metadata": {
      "content": "ng, etc.) help better structure product bundles \nto maximize revenue; the same is also applicable to multi-channel telecom provid -\ners with phone, television, and Internet-service offerings.\n\u2022\tMedical records: Certain combinations of conditions can indicate increased risk \nof various complications; or, certain treatment procedures at certain medical facili -\nties can be tied to certain types of infection.\nM04_SHAR4877_03_PIE_C04.indd   207 1/23/14   10:02 AM208\t Chapter \t4\t \u2022\t Data\tMining\nA\tgood\tquestion\tto\task\twith\trespect\tto\tthe\tpatterns/relationships\tthat\tassociation\t\nrule mining can discover is \u201cAre all association rules interesting and useful?\u201d In order to \nanswer such a question, association rule mining uses two common metrics: support, and \nconfidence and lift. Before defining these terms, let\u2019s get a little technical by showing \nwhat an association rule looks like:\nX 1 Y [Supp(%), Conf(%)]\n{Laptop Computer, Antivirus Software} 1 {Extended Service Plan} [30%, 70%]\nHere, X\t(prod",
      "title": "unit2ii"
    }
  },
  "parent_e5f2108b454048a8a096ddfd3270dbdd": {
    "id": "parent_e5f2108b454048a8a096ddfd3270dbdd",
    "metadata": {
      "content": "), Conf(%)]\n{Laptop Computer, Antivirus Software} 1 {Extended Service Plan} [30%, 70%]\nHere, X\t(products\tand/or\tservice;\tcalled\tthe\tleft-hand side, LHS,  or the antecedent) is \nassociated with Y\t(products\tand/or\tservice;\tcalled\tthe\tright-hand side, RHS,  or conse-\nquent). S is the support, and C is the confidence for this particular rule. Here are the \nsimple formulas for Supp, Conf, and Lift.\nSupport = Supp(X 1 Y ) = number of baskets that contains both X and Y\ntotal number of baskets\nConfidence = Conf (X 1 Y) = Supp(X 1 Y )\nSupp(X)\nLift(X 1 Y ) = Conf(X 1 Y )\nExpected Conf (X 1 Y ) =\nS(X 1 Y)\nS(X)\nS(X) * S(Y)\nS(X)\n= S(X 1 Y)\nS(X) * S(Y)\nThe support (S) of a collection of products is the measure of how often these products \nand/or\tservices\t(i.e.,\tLHS\t+\tRHS\t=\tLaptop\tComputer,\tAntivirus\tSoftware,\tand\tExtended\t\nService Plan) appear together in the same transaction; that is, the proportion of trans -\nactions\tin\tthe\tdata\tset\tthat\tcontain\tall\tof\tthe\tproducts\tand/or\tservices\tmentioned\tin\ta",
      "title": "unit2ii"
    }
  },
  "parent_3077200670e94b61a4d7ff6d576af77b": {
    "id": "parent_3077200670e94b61a4d7ff6d576af77b",
    "metadata": {
      "content": "of trans -\nactions\tin\tthe\tdata\tset\tthat\tcontain\tall\tof\tthe\tproducts\tand/or\tservices\tmentioned\tin\ta\t\nspecific rule. In this example, 30 percent of all transactions in the hypothetical store \ndatabase had all three products present in a single sales ticket. The confidence of a rule \nis\tthe\tmeasure\tof\thow\toften\tthe\tproducts\tand/or\tservices\ton\tthe\tRHS\t(consequent)\tgo\t\ntogether\twith\tthe\tproducts\tand/or\tservices\ton\tthe\tLHS\t(antecedent);\tthat\tis,\tthe\tpropor-\ntion of transactions that include LHS while also including the RHS. In other words, it is \nthe conditional probability of finding the RHS of the rule present in transactions where \nthe LHS of the rule already exists. The lift value of an association rule is the ratio of the \nconfidence of the rule and the expected confidence of the rule. The expected confidence \nof a rule is defined as the product of the support values of the LHS and the RHS divided \nby the support of the LHS.\nSeveral algorithms are available for discovering association r",
      "title": "unit2ii"
    }
  },
  "parent_bb37dba5e97346f3a5b40f50ad30f4cb": {
    "id": "parent_bb37dba5e97346f3a5b40f50ad30f4cb",
    "metadata": {
      "content": "S divided \nby the support of the LHS.\nSeveral algorithms are available for discovering association rules. Some well-known \nalgorithms include Apriori, Eclat, and FP-Growth. These algorithms only do half the job, \nwhich is to identify the frequent itemsets in the database. Once the frequent itemsets are \nidentified, they need to be converted into rules with antecedent and consequent parts. \nDetermination of the rules from frequent itemsets is a straightforward matching process, \nbut the process may be time-consuming with large transaction databases. Even though \nthere can be many items on each section of the rule, in practice the consequent part usu-\nally contains a single item. In the following section, one of the most popular algorithms \nfor identification of frequent itemsets is explained.\napriori algoritHM The apriori algorithm is the most commonly used algorithm \nto discover association rules. Given a set of itemsets (e.g., sets of retail transactions, \neach listing individual item",
      "title": "unit2ii"
    }
  },
  "parent_4a608058b8f84c38940bce8489f1b20e": {
    "id": "parent_4a608058b8f84c38940bce8489f1b20e",
    "metadata": {
      "content": "ion rules. Given a set of itemsets (e.g., sets of retail transactions, \neach listing individual items purchased), the algorithm attempts to find subsets that are \nM04_SHAR4877_03_PIE_C04.indd   208 1/23/14   10:02 AM\t Chapter\t4\t \u2022\t Data\tMining 209\ncommon to at least a minimum number of the itemsets (i.e., complies with a minimum \nsupport). Apriori uses a bottom-up approach, where frequent subsets are extended one \nitem at a time (a method known as candidate generation, whereby the size of frequent \nsubsets increases from one-item subsets to two-item subsets, then three-item subsets, \netc.), and groups of candidates at each level are tested against the data for minimum sup-\nport. The algorithm terminates when no further successful extensions are found.\nAs an illustrative example, consider the following. A grocery store tracks sales trans-\nactions by SKU (stock-keeping unit) and thus knows which items are typically purchased \ntogether. The database of transactions, along with the subsequ",
      "title": "unit2ii"
    }
  },
  "parent_993962955294421c91bc7d2122888f5c": {
    "id": "parent_993962955294421c91bc7d2122888f5c",
    "metadata": {
      "content": "which items are typically purchased \ntogether. The database of transactions, along with the subsequent steps in identifying the \nfrequent itemsets, is shown in Figure 4.12. Each SKU in the transaction database corresponds \nto\ta\tproduct,\tsuch\tas\t\u201c1\t=\tbutter,\u201d\t\u201c2\t=\tbread,\u201d\t\u201c3\t=\twater,\u201d\tand\tso\ton.\tThe\tfirst\tstep\tin\t\nApriori is to count up the frequencies (i.e., the supports) of each item (one-item itemsets). \nFor this overly simplified example, let us set the minimum support to 3 (or 50%; meaning an \nitemset is considered to be a frequent itemset if it shows up in at least 3 out of 6 transactions \nin the database). Because all of the one-item itemsets have at least 3 in the support column, \nthey are all considered frequent itemsets. However, had any of the one-item itemsets not \nbeen frequent, they would not have been included as a possible member of possible two-\nitem pairs. In this way, Apriori prunes the tree of all possible itemsets. As Figure 4.12 shows, \nusing one-item itemsets, al",
      "title": "unit2ii"
    }
  },
  "parent_b9d2da36dca0447a96b5c6b85e2a96f2": {
    "id": "parent_b9d2da36dca0447a96b5c6b85e2a96f2",
    "metadata": {
      "content": "Apriori prunes the tree of all possible itemsets. As Figure 4.12 shows, \nusing one-item itemsets, all possible two-item itemsets are generated and the transaction \ndatabase is used to calculate their support values. Because the two-item itemset {1, 3} has \na support less than 3, it should not be included in the frequent itemsets that will be used \nto generate the next-level itemsets (three-item itemsets). The algorithm seems deceivingly \nsimple, but only for small data sets. In much larger data sets, especially those with huge \namounts of items present in low quantities and small amounts of items present in big quanti-\nties, the search and calculation become a computationally intensive process.\nsectiOn 4.5 revieW Questi Ons\n 1. Identify at least three of the main data mining methods.\n 2. Give examples of situations in which classification would be an appropriate data \nmining technique. Give examples of situations in which regression would be an \nappropriate data mining technique.\n 3. L",
      "title": "unit2ii"
    }
  },
  "parent_804c215aae3d44d6add81aae0cf5947f": {
    "id": "parent_804c215aae3d44d6add81aae0cf5947f",
    "metadata": {
      "content": "ive examples of situations in which regression would be an \nappropriate data mining technique.\n 3. List and briefly define at least two classification techniques.\n 4. What are some of the criteria for comparing and selecting the best classification \ntechnique?\nTransaction\nNo\nSKUs\n(Item No)\nRaw Transaction Data\n1001 1, 2, 3, 4\n1002 2, 3, 4\n1003 2, 3\n1004 1, 2, 4\n1005 1, 2, 3, 4\n1006 2, 4\nItemset\n(SKUs) Support\nOne-Item Itemsets\n13\n2 6\n3 4\n45\nItemset\n(SKUs) Support\nTwo-Item Itemsets\n1, 23\n1, 3 2\n1, 4 3\n2, 34\n2, 45\n3, 4 3\nItemset\n(SKUs) Support\nThree-Item Itemsets\n1, 2, 43\n2, 3, 4 3\nFigure 4.12 Identification of Frequent Itemsets in Apriori Algorithm.\nM04_SHAR4877_03_PIE_C04.indd   209 1/23/14   10:02 AM",
      "title": "unit2ii"
    }
  },
  "parent_aef77d6e2f6e427ba6c44d76011776b4": {
    "id": "parent_aef77d6e2f6e427ba6c44d76011776b4",
    "metadata": {
      "content": "i need the notes to study the subject and prepare for the exam and this is my syllabus UNIT 1\n\u0000Hours\u0000\nAn Overview of Business Intelligence, Analytics and Decision Support:\nChanging Business Environments and Computerized Decision Support, A Framework for\nBusiness Intelligence \u0000BI\u0000, Transaction Processing Versus Analytic Processing\nTextbook 1\u0000 Chapter 1\u0000 1.2, 13, 1.5\nWhy Analytics? Business Analytics, Descriptive Analytics, Predictive Analytics, Prescriptive\nAnalytics, Techniques, Big Data Analytics, Web and Social Media Analytics, Framework for Data\nDriven Decision Making, Analytics Capacity Building, Roadmap for Analytics Capability Building\nTextbook 2\u0000 Chapter 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 1.10, 1.12, 1.13, 114\nprepare notes properly and easily understandable and memorizable\nNow I'll compile comprehensive study notes based on the syllabus and the content from both\ntextbooks.\nBusiness Pressures-Responses-Support Model\nThis model explains why companies embrace computerized decision",
      "title": "BI1i"
    }
  },
  "parent_75df7efdd985491682fd595079a9e2ca": {
    "id": "parent_75df7efdd985491682fd595079a9e2ca",
    "metadata": {
      "content": "ss Pressures-Responses-Support Model\nThis model explains why companies embrace computerized decision support systems and has\nthree key components:\n1. Business Pressures \u0000Environmental Factors)\nBusiness environment factors are divided into four categories :\nprepare a study notes with all points required and\nalso if the concept have a image to support the\nadd the reference to the image\nUNIT 1 \u0000 BUSINESS INTELLIGENCE, ANALYTICS\nAND DECISION SUPPORT\nComprehensive Study Notes\nPART A\u0000 AN OVERVIEW OF BUSINESS INTELLIGENCE\nChanging Business Environments and Computerized Decision Support\n\u00001\u0000\n\u00001\u0000Factor Description\nMarkets Strong competition, expanding global markets, booming electronic markets, innovative\nmarketing methods, need for real-time transactions \nConsumer\nDemands\nDesire for customization, quality, diversity of products, speed of delivery, customers\nbecoming more powerful and less loyal \nTechnology More innovations, new products/services, increasing obsolescence rate, increasing\ninforma",
      "title": "BI1i"
    }
  },
  "parent_8361b9538b944daf8620403c1f2bc4d6": {
    "id": "parent_8361b9538b944daf8620403c1f2bc4d6",
    "metadata": {
      "content": "Technology More innovations, new products/services, increasing obsolescence rate, increasing\ninformation overload, social networking \nSocietal Growing government regulations, diversified workforce, homeland security concerns,\nSarbanes-Oxley Act compliance, social responsibility, sustainability emphasis \nImage Reference: Figure 1.1 \u0000 The Business Pressures-Responses-Support Model (shows the\nrelationship between environmental factors, organizational responses, and computerized\ndecision support)\n2. Organizational Responses\nCompanies respond to business pressures through various actions :\n3. Computerized Support\nFacilitates monitoring the environment and enhances organizational response actions through\nintegrated computerized decision support and business intelligence\nClosing the Strategy Gap: The major objective of computerized decision support is to bridge\nthe gap between current organizational performance and desired performance as expressed in\nmission, objectives, goals, and strategies",
      "title": "BI1i"
    }
  },
  "parent_c9509bec032b44e0a9363f3ccbe620b5": {
    "id": "parent_c9509bec032b44e0a9363f3ccbe620b5",
    "metadata": {
      "content": "ional performance and desired performance as expressed in\nmission, objectives, goals, and strategies\nDefinition of Business Intelligence\nBusiness Intelligence \u0000BI) is an umbrella term that combines architectures, tools, databases,\nanalytical tools, applications, and methodologies. BI's major objective is to enable interactive\naccess (sometimes in real-time) to data, enable manipulation of data, and give business\nmanagers the ability to conduct appropriate analysis\nKey Principle: The BI process transforms data \u2192  information \u2192  decisions \u2192  actions\n\u00001\u0000\n\u00001\u0000\n\u00001\u0000\n\u00001\u0000\n\u00001\u0000\n\u00001\u0000\nEmploy strategic planning and innovative business models\nRestructure business processes and participate in business alliances\nImprove corporate information systems and partnership relationships\nImprove customer service and relationships\nMove to electronic commerce (e-commerce)\nUse new IT for improved communication and data access\nRespond quickly to competitors' actions\nAutomate decision processes, especially for custom",
      "title": "BI1i"
    }
  },
  "parent_a4fecc8033fd4c9fb7a1a0a28725523d": {
    "id": "parent_a4fecc8033fd4c9fb7a1a0a28725523d",
    "metadata": {
      "content": "ta access\nRespond quickly to competitors' actions\nAutomate decision processes, especially for customer-related decisions\nImprove decision making by employing analytics\n\u00001\u0000\n\u00001\u0000\nA Framework for Business Intelligence \u0000BI\u0000\n\u00001\u0000\n\u00001\u0000Brief History of BI\nImage Reference: Figure 1.2 \u0000 Evolution of Business Intelligence (shows various BI tools and\ntechniques including OLAP, dashboards, data mining, predictive analytics, etc.)\nArchitecture of BI\nA BI system has four major components :\nImage Reference: Figure 1.3 \u0000 A High-Level Architecture of BI (shows data warehouse\nenvironment, business analytics environment, and performance/strategy components)\nBI Applications and Business Value\nAnalytic Application Business Question Business Value\nCustomer\nSegmentation\nWhat market segments do\ncustomers fall into?\nPersonalize customer relationships for higher\nsatisfaction\nPropensity to Buy Which customers likely to respond\nto promotion?\nTarget customers to increase loyalty and\ncampaign profitability\nCustomer\nPr",
      "title": "BI1i"
    }
  },
  "parent_88a46ca3a75f45998d9658a432162b75": {
    "id": "parent_88a46ca3a75f45998d9658a432162b75",
    "metadata": {
      "content": "to respond\nto promotion?\nTarget customers to increase loyalty and\ncampaign profitability\nCustomer\nProfitability\nWhat is lifetime profitability of\ncustomer?\nMake decisions based on overall customer\nprofitability\nFraud Detection Which transactions are likely\nfraudulent? Quickly determine fraud and minimize cost\nCustomer Attrition Which customer is at risk of leaving? Prevent loss of high-value customers\nChannel\nOptimization\nWhat is best channel to reach\ncustomers?\nInteract based on preference and cost\nmanagement\n\u00001\u0000\n1970s: MIS reporting systems (static, two-dimensional, no analytical capabilities)\nEarly 1980s: Executive Information Systems \u0000EIS) emerged with dynamic multidimensional\nreporting, forecasting, trend analysis, drill-down capabilities\nMid-1990s: Term \"BI\" coined by Gartner Group; same EIS capabilities appeared under BI\nname\nBy 2005\u0000 BI systems included artificial intelligence and powerful analytical capabilities\nBy 2006\u0000 Major commercial products appeared under the term BI\n\u00001\u0000",
      "title": "BI1i"
    }
  },
  "parent_d906b124d69b491cab07db5a729b3d65": {
    "id": "parent_d906b124d69b491cab07db5a729b3d65",
    "metadata": {
      "content": "d powerful analytical capabilities\nBy 2006\u0000 Major commercial products appeared under the term BI\n\u00001\u0000\n\u00001\u0000\n\u0000\u0000\u0000Data Warehouse - with its source data\n\u0000\u0000\u0000Business Analytics - collection of tools for manipulating, mining, and analyzing data\n\u0000\u0000\u0000Business Performance Management \u0000BPM\u0000 - for monitoring and analyzing performance\n\u0000\u0000\u0000User Interface - such as dashboards, browsers, portals\n\u00001\u0000\n\u00001\u0000Online Transaction Processing \u0000OLTP\u0000\nOnline Analytical Processing \u0000OLAP\u0000\nKey Distinction: Separating OLTP from analysis and decision support enables BI benefits and\nprovides competitive intelligence and advantage\nTheory of Firm and Transaction Cost\nFirms exist to minimize transaction costs. Decision-making cost is an important element of\ntransaction cost, grouped into three categories :\nHuman Limitations in Decision Making\nThe Monty Hall Problem demonstrates humans' inherent difficulty in decision making :\nTransaction Processing Versus Analytic Processing\n\u00001\u0000\nSystems that handle a company's routine ongoing bu",
      "title": "BI1i"
    }
  },
  "parent_b7ab3a9cba614a8b95beb6a987a46f05": {
    "id": "parent_b7ab3a9cba614a8b95beb6a987a46f05",
    "metadata": {
      "content": "saction Processing Versus Analytic Processing\n\u00001\u0000\nSystems that handle a company's routine ongoing business\nConstantly involved in handling updates to operational databases\nExamples: ATM withdrawals, bank deposits, grocery store purchases\nEach request is a transaction - a computerized record of a discrete event\nRequires database updates completed in an all-or-nothing fashion\nEfficient for transaction processing but inefficient for end-user analysis and reporting\n\u00001\u0000\nData warehouses work with informational data used for OLAP systems\nIntent is to give management ability to analyze data for business insights\nProvides tactical or operational decision support\nEnables quicker and more informed decisions\nData warehouses contain wide variety of data presenting coherent picture of business\nconditions\nAlways online, contains all OLTP system information including historical data\nReorganized and structured for fast, efficient querying, analysis, and decision support\n\u00001\u0000\nPART B\u0000 BUSINESS ANALYTICS \u0000",
      "title": "BI1i"
    }
  },
  "parent_cac4802188b546809a371d4ff30b9ebb": {
    "id": "parent_cac4802188b546809a371d4ff30b9ebb",
    "metadata": {
      "content": "ctured for fast, efficient querying, analysis, and decision support\n\u00001\u0000\nPART B\u0000 BUSINESS ANALYTICS \u0000 THE SCIENCE OF DATA\u0000DRIVEN DECISION\nMAKING\nWhy Analytics?\n\u00002\u0000\n\u00002\u0000\n\u0000\u0000\u0000Production Cost - Cost of reaching a decision with help of decision maker/procedure\n\u0000\u0000\u0000Implementation Cost - Cost of actions based on decisions produced\n\u0000\u0000\u0000Failure Costs - Account for failure of organization's efforts on production and\nimplementation\n\u00002\u0000\nWhen given option to switch doors, probability of winning increases to 2/3\nYet 92% of general public and 65% of university graduates disagreed with correct answerImage Reference: Figure 1.4 \u0000 Monty Hall Problem (shows three doors illustration)\nTravelling Salesman Problem \u0000TSP\u0000 example:\nAkshaya Patra Foundation had to deliver food to 20 schools per vehicle - solution space of 20! \u0000\n2.4329 \u0000 10^18 possible routes. Would take over 77,146 years to evaluate all routes at one\nmillion per second\nKey Insight: Data-driven decision making through business analytics is not an opt",
      "title": "BI1i"
    }
  },
  "parent_cdbe53acee7a442ebe1d9ae46f0a8ff1": {
    "id": "parent_cdbe53acee7a442ebe1d9ae46f0a8ff1",
    "metadata": {
      "content": "million per second\nKey Insight: Data-driven decision making through business analytics is not an option but an\nessential capability every organization must acquire, regardless of size\nThree Components of Business Analytics\nImage Reference: Figure 1.5 \u0000 Components of Business Analytics (shows interaction between\nBusiness Context, Technology, and Data Science)\n1. Business Context\n2. Technology\n3. Data Science\nReal-life decision scenarios involve millions or billions of options\n\u00002\u0000\n\u00002\u0000\n\u00002\u0000\nBusiness Analytics: Components and Context\n\u00002\u0000\n\u00002\u0000\nProjects start with business context and ability to ask the right questions\nExample: Target's Pregnancy Prediction Model\u00002\u0000\nPregnant women are price-insensitive \u0000Holy Grail for retailers)\nMarket size of baby-related products: at least $38 billion\nShopping behavior changes during special events like pregnancy\nExample: Bigbasket.com's \"Did You Forget\" feature\u00002\u0000\nCustomers forget 30% of items they intend to buy on average\nFeature predicts forgotten items t",
      "title": "BI1i"
    }
  },
  "parent_caf590a5b5eb48d495331054bf94ebc3": {
    "id": "parent_caf590a5b5eb48d495331054bf94ebc3",
    "metadata": {
      "content": "re\u00002\u0000\nCustomers forget 30% of items they intend to buy on average\nFeature predicts forgotten items to reduce logistics costs\nUsed for data capture, storage, preparation, analysis, and sharing\nUnstructured Data: Data not in matrix form (images, texts, voice, video, clickstream)\nSoftware tools: R, Python, SAS, SPSS, Tableau, TensorFlow, etc.\nTechnology selection criteria: cost, scalability, integration ability, real-time deployment\u00002\u0000\nMost important component of analytics\nConsists of statistical and operations research techniques, AI, machine learning, deep\nlearning\nObjective: Identify most appropriate statistical model/algorithm\nExample: Target's pregnancy prediction is a classification problem \u0000Pregnant vs. Not\nPregnant)\u00002\u0000Definition: Simplest form of analytics using descriptive statistics, data visualization, and queries\nto understand past data\nPrimary Objectives:\nImage Reference: Figure 1.6 \u0000 Peak Breakup Times According to Facebook (shows relationship\nbreakups spiking during spring",
      "title": "BI1i"
    }
  },
  "parent_66028b2046704f8ba6bc063ae94f01fb": {
    "id": "parent_66028b2046704f8ba6bc063ae94f01fb",
    "metadata": {
      "content": "e 1.6 \u0000 Peak Breakup Times According to Facebook (shows relationship\nbreakups spiking during spring break and December before Christmas)\nKey Examples of Insights :\nFamous Application: Walmart Hurricane Analysis\nHistorical Example: Dr. John Snow's Cholera Spot Map\nImage Reference: Figure 1.7 \u0000 John Snow's Spot Map of Cholera Outbreak in London, 1854\nPopular Visualization Tools: Tableau, Power BI, Qlik Sense\nTechniques: logistic regression, classification trees, random forest, adaptive boosting, neural\nnetworks\nExplainable AI \u0000XAI) plays important role in model selection\u00002\u0000\nThree Types of Analytics\n1. Descriptive Analytics\n\u00002\u0000\nInnovative data summarization and storytelling\nUnderstanding trends in past data\nGenerating insights for dashboards\n\u00002\u0000\n\u00002\u0000\nMost shoppers turn right when entering retail stores \u2192  Retailers place high-profit products\non right side\nMarried men who kiss wives before work live longer, earn more, get into fewer accidents\nDivorces spike in January \u0000January 3 nicknamed \"",
      "title": "BI1i"
    }
  },
  "parent_0c4cc37b297247ad9da832f55cd0e975": {
    "id": "parent_0c4cc37b297247ad9da832f55cd0e975",
    "metadata": {
      "content": "rk live longer, earn more, get into fewer accidents\nDivorces spike in January \u0000January 3 nicknamed \"divorce day\")\nMen more reluctant to use coupons than women \u2192  Target female shoppers with coupons\n\u00002\u0000\nDuring Hurricane Charley \u00002004\u0000, Walmart found strawberry pop-tarts demand increased 7x\nPre-hurricane top-selling item: beer\nInsights used successfully for Hurricane Frances\n\u00002\u0000\nBetween August 31 and September 10, 1854: over 500 deaths in London\nSpot map revealed highest deaths in Golden Square area\nEstablished water contamination as main source of cholera\n\u00002\u0000\n\u00002\u0000Definition: Aims to predict probability of future events such as demand forecasting, customer\nchurn, employee attrition, loan defaults, fraudulent transactions\nKey Principle: While descriptive analytics finds what happened in the past, predictive analytics\npredicts what is likely to happen in the future\nFamous Applications :\nOrganization Predictive Analytics Model\nPolyphonic HMI Predicts whether song will be hit \u0000Hit Song Scienc",
      "title": "BI1i"
    }
  },
  "parent_1907cb6ffffe40da9dd9e47825693320": {
    "id": "parent_1907cb6ffffe40da9dd9e47825693320",
    "metadata": {
      "content": "ization Predictive Analytics Model\nPolyphonic HMI Predicts whether song will be hit \u0000Hit Song Science) on scale 1\u000010\nOkCupid Predicts which online dating message likely to get response\nAmazon.com Product recommendations \u000035% of Amazon sales from recommender system)\nHewlett Packard Flight risk score to predict employee attrition\nFlight Caster Predicts flight delays 6 hours before airline alerts\nNetflix Predicts which movie customer likely to watch next \u000075% from recommendations)\nCapital One Bank Predicts most profitable customers\nBigbasket Predicted forgotten items in online grocery purchases\nFarecast Predicts airfare increases/decreases\nSports Example: Oakland Athletics \u00002002\u0000\nMost Frequently Used Techniques: Regression, logistic regression, classification trees,\nforecasting, K-nearest neighbors, Markov chains, random forest, boosting, neural networks\nDefinition: Highest level of analytics capability used for choosing optimal actions and making\nthe right choice among several alternativ",
      "title": "BI1i"
    }
  },
  "parent_e30818bbaee74b0bb5df99bf3e0b7b59": {
    "id": "parent_e30818bbaee74b0bb5df99bf3e0b7b59",
    "metadata": {
      "content": "cs capability used for choosing optimal actions and making\nthe right choice among several alternatives\nCore Techniques: Operations Research \u0000OR\u0000, machine learning algorithms, metaheuristics,\nadvanced statistical models\nImage Reference: Figure 1.8 \u0000 Link Between Different Analytics Capabilities (shows progression:\nDescriptive \u2192  Predictive \u2192  Prescriptive)\nKey Distinction: While actionable items can be derived from descriptive and predictive\nanalytics, prescriptive analytics ensures optimal actions\nFamous Applications :\n2. Predictive Analytics\n\u00002\u0000\n\u00002\u0000\n\u00002\u0000\n\u00002\u0000\nThird lowest payroll among major league baseball teams\nUsed statistical techniques to identify player qualities impacting match outcomes\nWith $41 million payroll, won 20 games in a row\n\u00002\u0000\n3. Prescriptive Analytics\n\u00002\u0000\n\u00002\u0000\n\u00002\u0000\n\u00002\u0000\n\u00002\u0000Coca-Cola Enterprises \u0000CCE\u0000\u0000\nAkshaya Patra - AMRUTA \u0000Midday Meal Routing Algorithm):\nSamsung - SLIM \u0000Short Life and Low Inventory in Manufacturing):\nHewlett Packard (HPDirect.com):\nImage Reference: Fig",
      "title": "BI1i"
    }
  },
  "parent_b72f31247da14d66a7bfb4b97964bddf": {
    "id": "parent_b72f31247da14d66a7bfb4b97964bddf",
    "metadata": {
      "content": "Short Life and Low Inventory in Manufacturing):\nHewlett Packard (HPDirect.com):\nImage Reference: Figure 1.9 \u0000 Analytics Capability versus Organizational Value Add (shows\nprescriptive analytics provides maximum value, but fewer organizations use it)\nPredictive Analytics Techniques :\nTechnique Applications\nRegression Most frequently used; establishes association between response variable \u0000KPI) and\nexplanatory variables\nLogistic Regression Classification problems; credit scoring, fraud detection, customer churn, brand\nloyalty\nDecision Trees \u0000CART,\nCHAID\u0000 Regression and classification problems\nMarkov Chains Marketing, finance, operations, supply chain management; reinforcement learning\nRandom Forest Ensemble approach; identifying important variables\nBoosting Ensemble technique; sequentially improves model accuracy\nPrescriptive Analytics Techniques :\nTechnique Applications\nLinear Programming Resource allocation, product mix, cutting-stock, revenue management, logistics\noptimization\nInteger",
      "title": "BI1i"
    }
  },
  "parent_dc071fa569ad482e99e3e60b94a46ebd": {
    "id": "parent_dc071fa569ad482e99e3e60b94a46ebd",
    "metadata": {
      "content": "Resource allocation, product mix, cutting-stock, revenue management, logistics\noptimization\nInteger Programming Capital budgeting, scheduling, set covering\nDistributed 2 billion cases \u000042 billion bottles/cans) in 2005\nOR model for distribution network optimization\nResult: $54 million cost savings + improved customer satisfaction\nSolved vehicle routing problem\nResult: $75,000 per annum savings\nReduced manufacturing cycle time from 80+ days to less than 30 days \u00001996\u00001999\u0000\nCaptured additional markets worth $1 billion\nPredictive and prescriptive analytics for online sales\nImproved conversion rates and order sizes\n\u00002\u0000\nAnalytics Techniques Summary\n\u00002\u0000\n\u00002\u0000Technique Applications\nMulti-Criteria Decision\nModels\nGoal Programming, Analytic Hierarchy Process; handling multiple conflicting\nobjectives\nCombinatorial Optimization Travelling Salesman Problem \u0000TSP\u0000, Vehicle Routing Problem \u0000VRP\u0000, Minimum\nSpanning Tree \u0000MST\u0000\nNon-Linear Programming Engineering design optimization; neural networks loss fun",
      "title": "BI1i"
    }
  },
  "parent_d071fd905a414eccaffbb38a45dc4e23": {
    "id": "parent_d071fd905a414eccaffbb38a45dc4e23",
    "metadata": {
      "content": "Spanning Tree \u0000MST\u0000\nNon-Linear Programming Engineering design optimization; neural networks loss function\nSix Sigma DMAIC methodology for process improvement\nSocial Media Analytics Analyzing unstructured data (texts, videos, photos)\nFour Vs of Big Data :\nKey Insight: True big data problems challenge existing computing technology AND\nalgorithms\nBig Data Examples:\nTechnologies: Apache Hadoop \u0000Hadoop Distributed File System), MapReduce (parallel\nprocessing)\nImportance: 86% of marketers indicated social media was important for their business\nKey Questions for Marketers :\nBig Data Analytics\n\u00002\u0000\n\u0000\u0000\u0000Volume - Size of data (typically petabytes 10^15 bytes or exabytes 10^18 bytes)\nExamples: Telecom, banking, satellite data, IoT, health monitoring systems\n\u0000\u0000\u0000Velocity - Rate at which data is generated\nExample: AT&T customers generated 82+ petabytes of data traffic daily\n\u0000\u0000\u0000Variety - Different types of data collected\nExample: Voice calls, messages in different languages, video calls, Apps\n\u0000\u0000\u0000Veraci",
      "title": "BI1i"
    }
  },
  "parent_e099a628f9e1494d8a0da0b0d071fffb": {
    "id": "parent_e099a628f9e1494d8a0da0b0d071fffb",
    "metadata": {
      "content": "of data collected\nExample: Voice calls, messages in different languages, video calls, Apps\n\u0000\u0000\u0000Veracity - Data quality issues\nBiased, manipulated, or incorrect data can result in wrong inferences\n\u00002\u0000\nGoogle processes 24 petabytes of data every day\u00002\u0000\nB787 flight creates half a terabyte of machine-generated data\u00002\u0000\n2.5 exabytes of data created every day\u00002\u0000\n\u00002\u0000\nWeb and Social Media Analytics\n\u00002\u0000\n\u00002\u0000\n\u0000\u0000\u0000What is the most effective social media tactic?\n\u0000\u0000\u0000What are best ways to engage customers with social media?Advantages of Social Media:\nROI Calculation Methods :\n1. Return on Engagement \u0000ROE\u0000\u0000\n2. Other Methods:\nFive Integrated Stages :\nImage Reference: Figure 1.16 \u0000 Framework for Data-Driven Decision Making (shows all five\nstages)\n1. Problem or Opportunity Identification\n2. Collection of Relevant Data\n\u0000\u0000\u0000How to calculate ROI on social media engagement?\n\u0000\u0000\u0000What are best social media management tools?\n\u0000\u0000\u0000How to create social media strategy?\nMeasurable (impressions, visits, views, clicks, comm",
      "title": "BI1i"
    }
  },
  "parent_85384e9f45bf44f4ac5d1e2401f0be3b": {
    "id": "parent_85384e9f45bf44f4ac5d1e2401f0be3b",
    "metadata": {
      "content": "tools?\n\u0000\u0000\u0000How to create social media strategy?\nMeasurable (impressions, visits, views, clicks, comments, shares, likes)\nLess expensive than conventional media\nWider audience reach potential\nCan create viral impact quickly\n\u00002\u0000\nFacebook: \u0000Likes + Comments + Shares) / Total Facebook page likes\nTwitter: \u0000Replies + Retweets) / Number of followers\nYouTube: \u0000Comments + Ratings + Likes) / Video views OR Subscribers\nReturn on Influence\nAnecdotes\nCorrelation\nMultivariate Testing\nLinking and Tagging\nSocial Commerce Approach\nShare of Conversation: \u0000Brand conversation volume) / \u0000Entire industry conversation volume)\nSentiment Analysis\nFramework for Data-Driven Decision Making\n\u00002\u0000\n\u00002\u0000\nAbility to define problem clearly\nDomain knowledge very important\nMap project to organization's KPIs\nIdentify and collect relevant data (iterative process)3. Data Pre-processing\n4. Model Building\n5. Communication and Deployment\nFour Pillars of Analytics Excellence :\nImage Reference: Figure 1.17 \u0000 House of Analytics Exc",
      "title": "BI1i"
    }
  },
  "parent_cda222e7d415465b80e6186cf50b2fba": {
    "id": "parent_cda222e7d415465b80e6186cf50b2fba",
    "metadata": {
      "content": "loyment\nFour Pillars of Analytics Excellence :\nImage Reference: Figure 1.17 \u0000 House of Analytics Excellence (shows four pillars supporting\nanalytics)\n1. Top Management Support\n2. Analytics Talent\n3. Information Technology \u0000IT\u0000\nERP systems very useful\nCollect from internal and external sources\nData preparation takes significant proportion of project cycle time\nIncludes data cleaning, data imputation\nFeature engineering (interaction variables, dummy variables)\nIterative process to find best model\nDevelop hundreds of models in search of best ones\nCreate training and validation datasets to avoid overfitting/underfitting\nPrimary objective: deploy solutions and technologies\nInnovative data visualization with storytelling\nDevelop software solutions (e.g., recommender engines)\nAnalytics Capacity Building\n\u00002\u0000\n\u00002\u0000\nRequires organizational culture change\nData-driven decision making may not show immediate benefits\nEssential for creating strong analytics culture\nMost important factor for successful",
      "title": "BI1i"
    }
  },
  "parent_9e0474fe2bf4445eb48a3fb0836d1a91": {
    "id": "parent_9e0474fe2bf4445eb48a3fb0836d1a91",
    "metadata": {
      "content": "diate benefits\nEssential for creating strong analytics culture\nMost important factor for successful analytics vertical\nIdentify and nurture right talent to avoid attrition\nDifferentiate true analytics talent from mediocre professionals\nRecruiting strategies: top universities, LinkedIn, evidence-based selection\nCrucial for implementing analytics\nData capturing, storage, transfer, analysis, communication\nSoftware tools: R, Python, SAS, SPSS, STATA, Tableau\nMany organizations prefer open-source \u0000Python, R) over proprietary software4. Innovation\nImage Reference: Figure 1.18 \u0000 Roadmap for Analytics Capability Building (shows step-by-step\nprocess)\nStep-by-Step Process :\n1. Define Analytics Strategy\n2. Build Talent\n3. Build Infrastructure\n4. Identify Data Sources and Develop Collection Plan\n5. Analytics Implementation\nIn-memory computing for real-time decisions\nFourth pillar of analytics excellence\nWithout innovation, analytics may not achieve full potential\nMust integrate with domain knowled",
      "title": "BI1i"
    }
  },
  "parent_96b11977054841e7b843864ffd008045": {
    "id": "parent_96b11977054841e7b843864ffd008045",
    "metadata": {
      "content": "ence\nWithout innovation, analytics may not achieve full potential\nMust integrate with domain knowledge of business\nRoadmap for Analytics Capability Building\n\u00002\u0000\n\u00002\u0000\nDevelop long-term plan for role of analytics\nIdentify key functional areas to kick-start analytics\nCommunicate strategy across organization\nSuccess depends on human resources\nGet recruitment strategy right (technology + analytics model building skills)\nOutsource if necessary, but maintain in-house validation team\nHardware and software can be built incrementally\nExploit open-source software \u0000Python, R\u0000\nExplore cloud options for IT infrastructure\nAnalytics starts with data\nIdentify all relevant data\nAutomate data collection process\nStart with simple applications targeting small improvements\nUse lean techniques \u0000GEMBA) to identify opportunities\nInnovation plays major role\nBuild effective communication strategy\nCalculate ROI on analytics projectsStarting Point: Many organizations can start with simple tools - descriptive statis",
      "title": "BI1i"
    }
  },
  "parent_932602d0be04497eaed0478cdf77f7ad": {
    "id": "parent_932602d0be04497eaed0478cdf77f7ad",
    "metadata": {
      "content": "nalytics projectsStarting Point: Many organizations can start with simple tools - descriptive statistics, data\nvisualization, pivot tables, correlation analysis, Lean and Six Sigma\nSample Applications :\nIndustry Sample Problems Data Sources\nManufacturing Supply chain analytics, quality improvement,\nrevenue/cost management, warranty analytics\nProcurement, sales, production data;\nwarranty data; commodity prices;\nmacroeconomic data\nRetail\nAssortment planning, promotion planning,\ndemand forecasting, market basket analysis,\ncustomer segmentation\nPrice data, SKU-level sales data, PoS\ndata, customer demographics, loyalty\nprogram data\nHealthcare Clinical care analysis, hospitality data, demand\nforecasting\nPatient care data, hospitality data, patient\nfeedback\nBanking &\nFinance\nCustomer transaction analysis, credit scoring,\nfraud detection\nTransactional data, loan originating data,\ncredit scoring data\nIT & ITES Demand for analytics services, software\ndevelopment cycle time\nCustomer interaction d",
      "title": "BI1i"
    }
  },
  "parent_00b246562bd047be9a790bf270ee7c94": {
    "id": "parent_00b246562bd047be9a790bf270ee7c94",
    "metadata": {
      "content": "data\nIT & ITES Demand for analytics services, software\ndevelopment cycle time\nCustomer interaction data, internal\nproduct development data\nService\nDemand forecasting, NPS optimization,\nservice quality analysis, customer\nsegmentation\nTransactional and feedback data, pricing\nand demand data, promotional data\nRemember These Key Points:\n\u00002\u0000\nIndustry-wise Analytics Applications\n\u00002\u0000\nKEY TAKEAWAYS FOR EXAM PREPARATION\n\u0000\u0000\u0000Business Pressures-Responses-Support Model has 3 components: Business Pressures\n\u00004 categories: Markets, Consumer Demands, Technology, Societal) \u2192  Organizational\nResponses \u000015+ actions) \u2192  Computerized Support\u00001\u0000\n\u0000\u0000\u0000BI Architecture has 4 components: Data Warehouse + Business Analytics + Business\nPerformance Management + User Interface\u00001\u0000\n\u0000\u0000\u0000OLTP vs OLAP\u0000 OLTP for routine transactions (inefficient for analysis); OLAP for analytical\nprocessing (efficient for analysis and decision support)\u00001\u0000\n\u0000\u0000\u0000Three Components of Business Analytics: Business Context + Technology + Data\nScience",
      "title": "BI1i"
    }
  },
  "parent_213ebfaf87b5431c814e0d9c873e29f1": {
    "id": "parent_213ebfaf87b5431c814e0d9c873e29f1",
    "metadata": {
      "content": "support)\u00001\u0000\n\u0000\u0000\u0000Three Components of Business Analytics: Business Context + Technology + Data\nScience\u00002\u0000\n\u0000\u0000\u0000Three Types of Analytics (in order):\nDescriptive: \"What happened?\" (past data analysis)\nPredictive: \"What will happen?\" (future predictions)\nPrescriptive: \"What is the best action?\" (optimal decisions)\u00002\u0000\n\u0000\u0000\u0000Four Vs of Big Data: Volume, Velocity, Variety, Veracity\u00002\u0000Study Tips:\n\u2042\n\u0000\u0000\u0000Four Pillars of Analytics Excellence: Top Management Support, Analytics Talent, IT,\nInnovation\u00002\u0000\n\u0000\u0000\u0000Five Stages of Data-Driven Decision Making: Problem Identification \u2192  Data Collection \u2192\nData Pre-processing \u2192  Model Building \u2192  Deployment\u00002\u0000\nFocus on understanding diagrams/figures mentioned (especially Figures 1.1, 1.3, 1.5, 1.8, 1.9,\n1.16, 1.17, 1.18\u0000\nMemorize real-world examples \u0000Target, Walmart, Amazon, Netflix, Coca-Cola, Oakland\nAthletics)\nUnderstand differences between analytics types and when each is used\nRemember the progression: Descriptive \u2192  Predictive \u2192  Prescriptive (increasing complexit",
      "title": "BI1i"
    }
  },
  "parent_9da3a763a9d64607859fca58e2318f54": {
    "id": "parent_9da3a763a9d64607859fca58e2318f54",
    "metadata": {
      "content": "ch is used\nRemember the progression: Descriptive \u2192  Predictive \u2192  Prescriptive (increasing complexity\nand value)\nKnow techniques for each analytics type\n\u0000\u0000\u0000unit-1-textbook1-reference.pdf\n\u0000\u0000\u0000unit-1-textbook2-material.pdf",
      "title": "BI1i"
    }
  }
}